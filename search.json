[
  {
    "objectID": "contribute/guidelines_for_bigdataviewer.html",
    "href": "contribute/guidelines_for_bigdataviewer.html",
    "title": "Contributing Guidelines BigDataViewer",
    "section": "",
    "text": "Thank you for considering contributing to the BigDataViewer open source project! By contributing, you are helping to improve and grow the software for everyone in the community. We appreciate your time and effort.\n\n\n\nGovernance\n\nCode of Conduct\n\nGetting Started\n\nPrerequisites & Setting up the Development Environment\n\nMaking Contributions\n\nCreating Issues\nWorking on Issues\nSubmitting Pull Requests\n\nCode Guidelines\nTesting\nDocumentation\nCommunity\nLicense\n\n\n\n\nFounder: Tobias Pietzsch Lead: Tobias Pietzsch Maintainers: Tobias Pietzsch, Stephan Preibisch\nAnd the team role definitions: Founder - Created the project. Does not imply any current participation or responsibility. Lead - Has decision-making authority: timing of releases, inclusion of features, etc. Maintainer - Merges patch submissions. Cuts releases.\n\n\n\nBefore contributing, please review our Code of Conduct. We aim to foster an inclusive and respectful community where everyone feels safe to participate.\n\n\n\n\n\n\nPlease see the general guidlines on how to contribute to an existing plugin or library: https://imagej.net/develop/improving-the-code\n\n\nIf you find a bug, have a feature request, or encounter any issues, please search our BDV issue tracker to see if it has already been reported. If not, feel free to create a new issue and provide as much detail as possible.\n\n\n\nIf you want to work on an existing issue, please follow these steps:\n\nComment on the issue to express your interest in working on it.\nFork the repository and create a new branch for your work.\nMake your changes and commit them with clear commit messages.\nEnsure your code follows our Code Guidelines.\nUpdate the documentation if necessary.\nRun tests to ensure your changes don’t break existing functionality.\n\n\n\n\n\nPush your changes to your forked repository.\nCreate a pull request (PR) from your branch to our main repository’s appropriate branch.\nProvide a detailed description of your changes in the PR.\nReference any related issues using keywords (e.g., “Closes #123”).\nBe ready to address feedback and make necessary changes.\n\n\n\n\n\n\nUse consistent code formatting and style throughout the project.\nFollow naming conventions for variables, functions, and classes.\nEnsure your code is well-documented.\nWrite meaningful commit messages.\n\n\n\n\nExplain how to run tests and provide information about the testing framework used.\n\n\n\nIf your changes introduce new features or modify existing ones, please update the documentation accordingly. This includes code comments, README files, and any additional documentation files.\n\n\n\nJoin in our community discussions on imagesc.zulipchat.com for discussions. For more general questions of broad interest and announcements the image.sc forum can be used advantageously. We welcome your feedback and ideas.\n\n\n\nBy contributing to this project, you agree that your contributions will be licensed under the project’s license BigDataViewer license a BSD 2-Clause “Simplified” License. If you’re not comfortable with this, please consider refrain from contributing."
  },
  {
    "objectID": "contribute/guidelines_for_bigdataviewer.html#table-of-contents",
    "href": "contribute/guidelines_for_bigdataviewer.html#table-of-contents",
    "title": "Contributing Guidelines BigDataViewer",
    "section": "",
    "text": "Governance\n\nCode of Conduct\n\nGetting Started\n\nPrerequisites & Setting up the Development Environment\n\nMaking Contributions\n\nCreating Issues\nWorking on Issues\nSubmitting Pull Requests\n\nCode Guidelines\nTesting\nDocumentation\nCommunity\nLicense"
  },
  {
    "objectID": "contribute/guidelines_for_bigdataviewer.html#governance",
    "href": "contribute/guidelines_for_bigdataviewer.html#governance",
    "title": "Contributing Guidelines BigDataViewer",
    "section": "",
    "text": "Founder: Tobias Pietzsch Lead: Tobias Pietzsch Maintainers: Tobias Pietzsch, Stephan Preibisch\nAnd the team role definitions: Founder - Created the project. Does not imply any current participation or responsibility. Lead - Has decision-making authority: timing of releases, inclusion of features, etc. Maintainer - Merges patch submissions. Cuts releases."
  },
  {
    "objectID": "contribute/guidelines_for_bigdataviewer.html#code-of-conduct",
    "href": "contribute/guidelines_for_bigdataviewer.html#code-of-conduct",
    "title": "Contributing Guidelines BigDataViewer",
    "section": "",
    "text": "Before contributing, please review our Code of Conduct. We aim to foster an inclusive and respectful community where everyone feels safe to participate."
  },
  {
    "objectID": "contribute/guidelines_for_bigdataviewer.html#making-contributions",
    "href": "contribute/guidelines_for_bigdataviewer.html#making-contributions",
    "title": "Contributing Guidelines BigDataViewer",
    "section": "",
    "text": "Please see the general guidlines on how to contribute to an existing plugin or library: https://imagej.net/develop/improving-the-code\n\n\nIf you find a bug, have a feature request, or encounter any issues, please search our BDV issue tracker to see if it has already been reported. If not, feel free to create a new issue and provide as much detail as possible.\n\n\n\nIf you want to work on an existing issue, please follow these steps:\n\nComment on the issue to express your interest in working on it.\nFork the repository and create a new branch for your work.\nMake your changes and commit them with clear commit messages.\nEnsure your code follows our Code Guidelines.\nUpdate the documentation if necessary.\nRun tests to ensure your changes don’t break existing functionality.\n\n\n\n\n\nPush your changes to your forked repository.\nCreate a pull request (PR) from your branch to our main repository’s appropriate branch.\nProvide a detailed description of your changes in the PR.\nReference any related issues using keywords (e.g., “Closes #123”).\nBe ready to address feedback and make necessary changes."
  },
  {
    "objectID": "contribute/guidelines_for_bigdataviewer.html#code-guidelines",
    "href": "contribute/guidelines_for_bigdataviewer.html#code-guidelines",
    "title": "Contributing Guidelines BigDataViewer",
    "section": "",
    "text": "Use consistent code formatting and style throughout the project.\nFollow naming conventions for variables, functions, and classes.\nEnsure your code is well-documented.\nWrite meaningful commit messages."
  },
  {
    "objectID": "contribute/guidelines_for_bigdataviewer.html#testing",
    "href": "contribute/guidelines_for_bigdataviewer.html#testing",
    "title": "Contributing Guidelines BigDataViewer",
    "section": "",
    "text": "Explain how to run tests and provide information about the testing framework used."
  },
  {
    "objectID": "contribute/guidelines_for_bigdataviewer.html#documentation",
    "href": "contribute/guidelines_for_bigdataviewer.html#documentation",
    "title": "Contributing Guidelines BigDataViewer",
    "section": "",
    "text": "If your changes introduce new features or modify existing ones, please update the documentation accordingly. This includes code comments, README files, and any additional documentation files."
  },
  {
    "objectID": "contribute/guidelines_for_bigdataviewer.html#community",
    "href": "contribute/guidelines_for_bigdataviewer.html#community",
    "title": "Contributing Guidelines BigDataViewer",
    "section": "",
    "text": "Join in our community discussions on imagesc.zulipchat.com for discussions. For more general questions of broad interest and announcements the image.sc forum can be used advantageously. We welcome your feedback and ideas."
  },
  {
    "objectID": "contribute/guidelines_for_bigdataviewer.html#license",
    "href": "contribute/guidelines_for_bigdataviewer.html#license",
    "title": "Contributing Guidelines BigDataViewer",
    "section": "",
    "text": "By contributing to this project, you agree that your contributions will be licensed under the project’s license BigDataViewer license a BSD 2-Clause “Simplified” License. If you’re not comfortable with this, please consider refrain from contributing."
  },
  {
    "objectID": "contribute/our_code_of_conduct.html",
    "href": "contribute/our_code_of_conduct.html",
    "title": "Contributor Covenant Code of Conduct",
    "section": "",
    "text": "We as members, contributors, and leaders pledge to make participation in our community a harassment-free experience for everyone, regardless of age, body size, visible or invisible disability, ethnicity, sex characteristics, gender identity and expression, level of experience, education, socio-economic status, nationality, personal appearance, race, caste, color, religion, or sexual identity and orientation.\nWe pledge to act and interact in ways that contribute to an open, welcoming, diverse, inclusive, and healthy community.\n\n\n\nExamples of behavior that contributes to a positive environment for our community include:\n\nDemonstrating empathy and kindness toward other people\nBeing respectful of differing opinions, viewpoints, and experiences\nGiving and gracefully accepting constructive feedback\nAccepting responsibility and apologizing to those affected by our mistakes, and learning from the experience\nFocusing on what is best not just for us as individuals, but for the overall community\n\nExamples of unacceptable behavior include:\n\nThe use of sexualized language or imagery, and sexual attention or advances of any kind\nTrolling, insulting or derogatory comments, and personal or political attacks\nPublic or private harassment\nPublishing others’ private information, such as a physical or email address, without their explicit permission\nOther conduct which could reasonably be considered inappropriate in a professional setting\n\n\n\n\nCommunity leaders are responsible for clarifying and enforcing our standards of acceptable behavior and will take appropriate and fair corrective action in response to any behavior that they deem inappropriate, threatening, offensive, or harmful.\nCommunity leaders have the right and responsibility to remove, edit, or reject comments, commits, code, wiki edits, issues, and other contributions that are not aligned to this Code of Conduct, and will communicate reasons for moderation decisions when appropriate.\n\n\n\nThis Code of Conduct applies within all community spaces, and also applies when an individual is officially representing the community in public spaces. Examples of representing our community include using an official e-mail address, posting via an official social media account, or acting as an appointed representative at an online or offline event.\n\n\n\nInstances of abusive, harassing, or otherwise unacceptable behavior may be reported to the community leaders responsible for enforcement at email : imglibbdv [@] gmail .com. All complaints will be reviewed and investigated promptly and fairly.\nAll community leaders are obligated to respect the privacy and security of the reporter of any incident.\n\n\n\nCommunity leaders will follow these Community Impact Guidelines in determining the consequences for any action they deem in violation of this Code of Conduct:\n\n\nCommunity Impact: Use of inappropriate language or other behavior deemed unprofessional or unwelcome in the community.\nConsequence: A private, written warning from community leaders, providing clarity around the nature of the violation and an explanation of why the behavior was inappropriate. A public apology may be requested.\n\n\n\nCommunity Impact: A violation through a single incident or series of actions.\nConsequence: A warning with consequences for continued behavior. No interaction with the people involved, including unsolicited interaction with those enforcing the Code of Conduct, for a specified period of time. This includes avoiding interactions in community spaces as well as external channels like social media. Violating these terms may lead to a temporary or permanent ban.\n\n\n\nCommunity Impact: A serious violation of community standards, including sustained inappropriate behavior.\nConsequence: A temporary ban from any sort of interaction or public communication with the community for a specified period of time. No public or private interaction with the people involved, including unsolicited interaction with those enforcing the Code of Conduct, is allowed during this period. Violating these terms may lead to a permanent ban.\n\n\n\nCommunity Impact: Demonstrating a pattern of violation of community standards, including sustained inappropriate behavior, harassment of an individual, or aggression toward or disparagement of classes of individuals.\nConsequence: A permanent ban from any sort of public interaction within the community.\n\n\n\n\nThis Code of Conduct is adapted from the Contributor Covenant, version 2.1, available at https://www.contributor-covenant.org/version/2/1/code_of_conduct.html.\nCommunity Impact Guidelines were inspired by Mozilla’s code of conduct enforcement ladder.\nFor answers to common questions about this code of conduct, see the FAQ at https://www.contributor-covenant.org/faq. Translations are available at https://www.contributor-covenant.org/translations."
  },
  {
    "objectID": "contribute/our_code_of_conduct.html#our-pledge",
    "href": "contribute/our_code_of_conduct.html#our-pledge",
    "title": "Contributor Covenant Code of Conduct",
    "section": "",
    "text": "We as members, contributors, and leaders pledge to make participation in our community a harassment-free experience for everyone, regardless of age, body size, visible or invisible disability, ethnicity, sex characteristics, gender identity and expression, level of experience, education, socio-economic status, nationality, personal appearance, race, caste, color, religion, or sexual identity and orientation.\nWe pledge to act and interact in ways that contribute to an open, welcoming, diverse, inclusive, and healthy community."
  },
  {
    "objectID": "contribute/our_code_of_conduct.html#our-standards",
    "href": "contribute/our_code_of_conduct.html#our-standards",
    "title": "Contributor Covenant Code of Conduct",
    "section": "",
    "text": "Examples of behavior that contributes to a positive environment for our community include:\n\nDemonstrating empathy and kindness toward other people\nBeing respectful of differing opinions, viewpoints, and experiences\nGiving and gracefully accepting constructive feedback\nAccepting responsibility and apologizing to those affected by our mistakes, and learning from the experience\nFocusing on what is best not just for us as individuals, but for the overall community\n\nExamples of unacceptable behavior include:\n\nThe use of sexualized language or imagery, and sexual attention or advances of any kind\nTrolling, insulting or derogatory comments, and personal or political attacks\nPublic or private harassment\nPublishing others’ private information, such as a physical or email address, without their explicit permission\nOther conduct which could reasonably be considered inappropriate in a professional setting"
  },
  {
    "objectID": "contribute/our_code_of_conduct.html#enforcement-responsibilities",
    "href": "contribute/our_code_of_conduct.html#enforcement-responsibilities",
    "title": "Contributor Covenant Code of Conduct",
    "section": "",
    "text": "Community leaders are responsible for clarifying and enforcing our standards of acceptable behavior and will take appropriate and fair corrective action in response to any behavior that they deem inappropriate, threatening, offensive, or harmful.\nCommunity leaders have the right and responsibility to remove, edit, or reject comments, commits, code, wiki edits, issues, and other contributions that are not aligned to this Code of Conduct, and will communicate reasons for moderation decisions when appropriate."
  },
  {
    "objectID": "contribute/our_code_of_conduct.html#scope",
    "href": "contribute/our_code_of_conduct.html#scope",
    "title": "Contributor Covenant Code of Conduct",
    "section": "",
    "text": "This Code of Conduct applies within all community spaces, and also applies when an individual is officially representing the community in public spaces. Examples of representing our community include using an official e-mail address, posting via an official social media account, or acting as an appointed representative at an online or offline event."
  },
  {
    "objectID": "contribute/our_code_of_conduct.html#enforcement",
    "href": "contribute/our_code_of_conduct.html#enforcement",
    "title": "Contributor Covenant Code of Conduct",
    "section": "",
    "text": "Instances of abusive, harassing, or otherwise unacceptable behavior may be reported to the community leaders responsible for enforcement at email : imglibbdv [@] gmail .com. All complaints will be reviewed and investigated promptly and fairly.\nAll community leaders are obligated to respect the privacy and security of the reporter of any incident."
  },
  {
    "objectID": "contribute/our_code_of_conduct.html#enforcement-guidelines",
    "href": "contribute/our_code_of_conduct.html#enforcement-guidelines",
    "title": "Contributor Covenant Code of Conduct",
    "section": "",
    "text": "Community leaders will follow these Community Impact Guidelines in determining the consequences for any action they deem in violation of this Code of Conduct:\n\n\nCommunity Impact: Use of inappropriate language or other behavior deemed unprofessional or unwelcome in the community.\nConsequence: A private, written warning from community leaders, providing clarity around the nature of the violation and an explanation of why the behavior was inappropriate. A public apology may be requested.\n\n\n\nCommunity Impact: A violation through a single incident or series of actions.\nConsequence: A warning with consequences for continued behavior. No interaction with the people involved, including unsolicited interaction with those enforcing the Code of Conduct, for a specified period of time. This includes avoiding interactions in community spaces as well as external channels like social media. Violating these terms may lead to a temporary or permanent ban.\n\n\n\nCommunity Impact: A serious violation of community standards, including sustained inappropriate behavior.\nConsequence: A temporary ban from any sort of interaction or public communication with the community for a specified period of time. No public or private interaction with the people involved, including unsolicited interaction with those enforcing the Code of Conduct, is allowed during this period. Violating these terms may lead to a permanent ban.\n\n\n\nCommunity Impact: Demonstrating a pattern of violation of community standards, including sustained inappropriate behavior, harassment of an individual, or aggression toward or disparagement of classes of individuals.\nConsequence: A permanent ban from any sort of public interaction within the community."
  },
  {
    "objectID": "contribute/our_code_of_conduct.html#attribution",
    "href": "contribute/our_code_of_conduct.html#attribution",
    "title": "Contributor Covenant Code of Conduct",
    "section": "",
    "text": "This Code of Conduct is adapted from the Contributor Covenant, version 2.1, available at https://www.contributor-covenant.org/version/2/1/code_of_conduct.html.\nCommunity Impact Guidelines were inspired by Mozilla’s code of conduct enforcement ladder.\nFor answers to common questions about this code of conduct, see the FAQ at https://www.contributor-covenant.org/faq. Translations are available at https://www.contributor-covenant.org/translations."
  },
  {
    "objectID": "bdv/index.html",
    "href": "bdv/index.html",
    "title": "BigDataViewer",
    "section": "",
    "text": "The BigDataViewer is a re-slicing browser for terabyte-sized multi-view image sequences. Conceptually, the visualized data comprises multiple data sources. Each source provides one 3D image (for each time-point in the case of a time-lapse sequence or angle for a multi-angle SPIM dataset).\nBigDataViewer comes with a custom data format that is is optimized for fast random access to very large data sets. This permits browsing to any location within a multi-terabyte recording in a fraction of a second. The file format is based on XML and HDF5. Images are represented as tiled multi-resolution pyramids, and stored in HDF5 chunked multi-dimensional arrays with metadata contained in the XML file. BigDataViewer was developed with multi-view light-sheet microscopy data in mind and integrates well with Fiji’s SPIMage processing pipeline.ImgLib2 is a general-purpose, multidimensional image and data processing library.",
    "crumbs": [
      "BigDataViewer"
    ]
  },
  {
    "objectID": "imglib1/index.html",
    "href": "imglib1/index.html",
    "title": "ImgLib1 (obsolete!)",
    "section": "",
    "text": "{% include warning/deprecated old=“ImgLib1” new=“ImgLib2” %}\n\nCitation\nPlease note that the ImgLib, as well as other plugins available through Fiji, is based on a publication. If you use it successfully for your research please be so kind to cite our work:\n\nS. Preibisch, P. Tomancak, S. Saalfeld (2010) “Into ImgLib – Generic Image Processing in Java”, ImageJ User and Developer Conference 2010 (1):72-76. Webpage PDF\n\n\n\nIntroduction\nIn ImageJ, images can have a number of types (8-bit gray, 8-bit with lookup table, 16-bit, 32-bit floating point, RGB packed into a 32-bit int), and up to 5 dimensions. Internally, every image is stored as an array of channels * slices * frames instances of the class ImageProcessor, which in turn stores the pixel values as arrays of width * height values which have the native types byte, short, etc\nWhen implementing an image processing algorithm, typically this has to be done with every native type separately, for performance reasons, and for the same reason, there is a lot of code repeated between different plugins.\nIn C++, this problem is solved by using templates, e.g. in the ITK library. The idea is to implement the algorithm generically, i.e. independent of data type.\nThe corresponding technique in Java is called generics and is available since Java version 1.5. Due to technical issues, Java cannot optimize specializations of generics fully at compile-time, and generics have other limitations, such as not being able to use basic types (which are used for ImageJ’s pixel values) as parameters.\nIn imglib, these issues have been addressed, in a way compatible with Java.\n\n\nVocabulary\nType: The Type class wraps a value, in the same way that the java.lang Integer, Double, Float, etc. wrap a value. The value is not necessarily a primitive (like int, short, long, char, float, double …) but can be a complex number, base pair, boolean, label, and other non-numerical types.\nOutside Strategy: The OutsideStrategy is a method to handle values when requested at a position beyond the boundaries of the image. Typical outside strategies may be to return a constant value, or to mirror the values of the image.\n\n\nCore ideas of the architecture\nSince basic types cannot be passed as parameters to Java generics, and operators cannot be overloaded, all values must be accessed via Type instances. Type is the base interface for all data types handled by imglib. If you need a new data type to be handled, just make a new class implementing the Type interface. There is a convenient abstract class “TypeImpl” that provides default implementations for some common methods.\nTo access pixel values, imglib provides Cursor classes. The simplest Cursor just iterates over all pixels of the image. This cursor is guaranteed to traverse the pixels in an optimal fashion, regardless of the way the pixels are stored in memory. There are other cursors, implementing the Localizable interface, which report their position. The most specific cursor is the LocalizableByDimCursor, which allows to set the position to a specified one.\nEspecially for large images, which become more and more prevalent, it is interesting to have different storage strategies. Plain ImageJ provides only one storage strategy: every XY slice of a (possibly 5-dimensional) stack is stored as a one-dimensional basic type array which is a linearized version of the 2-dimensional slice (i.e. each pixel is addressed using an index which is calculated as x + y * width).\nIn addition to adapters wrapping ImageJ’s ImagePlus, imglib currently supports two container types: a container wrapping an image as a linearized array of a basic type (available in the mpicbg.imglib.array package) and a container wrapping the image as so-called cells, which are sort of n-dimensional “tiles” (in 3D, would be a cube). The latter container is available in the package mpicbg.imglib.container.cell and has the advantage to be “pageable”, i.e. not the complete image has to be loaded into memory at the same time, allowing for images larger than the available RAM. This is comparable, but more powerful, than ImageJ’s VirtualStack concept.\n\n\nExample\nLet’s look at a simple function multiplying every pixel value with a given constant.\n\nUsing imglib\nNo matter what kind of image (a single image, a stack, a 4D stack, with one color channel or three…), the algorithm is implemented cleanly and clearly:\npublic &lt;T extends NumericType&lt;T&gt;&gt; void mul( Image&lt;T&gt; input, T factor )\n{\n        for ( final T value : input )\n          value.mul( factor );\n}\n\n\nUsing ImageJ\nIn plain ImageJ, the same function looks like the following. Notice how we have to litter the code with special cases, and we have to know before hand the number of channels, slices, and pixels per slice. We even need a helper function to simplify operations a bit!\n final static public void multiply( final ImagePlus input, final double factor )\n {\n         final int nPixels = input.getWidth() * input.getHeight();\n         \n         // iterate through all channels, frames and timepoints (might be just one)\n         for ( int c = 1; c &lt;= input.getNChannels(); ++c )\n                 for ( int z = 1; z &lt;= input.getNSlices(); ++z )\n                         for ( int t = 1; t &lt;= input.getNFrames(); ++t )\n                         {\n                                 input.setPosition( c, z, t );\n                                 final ImageProcessor ip = input.getChannelProcessor();\n                                 \n                                 // RGB images are special\n                                 if ( input.getType() == ImagePlus.COLOR_RGB )\n                                 {\n                                         for ( int i = 0; i &lt; nPixels; ++i )\n                                         {\n                                                 final int rgb = ip.get( i );\n                                                 final int r = doubleTo8Bit( Math.round( ( (\n                                                         rgb &gt;&gt; 16 ) & 0xff ) * factor ) );\n                                                 final int g = doubleTo8Bit( Math.round( ( (\n                                                         rgb &gt;&gt; 8 ) & 0xff ) * factor ) );\n                                                 final int b = doubleTo8Bit( Math.round( (\n                                                         rgb & 0xff ) * factor ) );\n                                                 ip.set( i, ( r &lt;&lt; 16 ) | ( g &lt;&lt; 8 ) | b );\n                                         }\n                                 }\n                                 else\n                                 {\n                                         for ( int i = 0; i &lt; nPixels; ++i )\n                                         {\n                                                 ip.setf( i, ip.getf( i ) * ( float )factor );\n                                         }\n                                 }\n                         }\n }\n \n final static int doubleTo8Bit( final double value ) {\n         return Math.max( 0, Math.min( 255, (int) value ) );\n }\nThe performance is better in the ImgLib version, as there is no need for two type conversions in every iteration: the Type instance implements the native operation mul(), and since the implementation is labeled using the Java keyword final, it will be inlined and optimized pretty quickly by Java’s Just-In-Time compiler. Furthermore it will work on any ComplexType (even for example real numbers) that are available or will be implemented in the future.",
    "crumbs": [
      "ImgLib1 (obsolete!)"
    ]
  },
  {
    "objectID": "imglib1/workshop.html",
    "href": "imglib1/workshop.html",
    "title": "Into ImgLib - Generic Image Processing in Java",
    "section": "",
    "text": "{% include warning/deprecated old=“ImgLib1” new=“ImgLib2” %}\nThe purpose of ImgLib, a Generic Java Image Processing Library, is to provide an abstract framework enabling Java developers to design and implement data processing algorithms without having to consider dimensionality, type of data (e.g. byte, float, complex float), or strategies for data access (e.g. linear arrays, cells, paged cells).\nThis kind of programming has significant advantages over the classical way. An algorithm written once for a certain class of Type will potentially run on any compatible Type, even if it does not exist yet. Same applies for data access strategies and the number of dimensions.\nWe achieve this abstraction by accessing data through Iterators and Type interfaces. Iterators guarantee efficient traversal through pixels depending on whether random coordinate access is required or just all pixels have to be visited once, whether real or integer coordinates are accessed, whether coordinates outside of image boundaries are accessed or not. Type interfaces define the supported operators on pixel values (like basic algebra) and hide the underlying basic type from the algorithmic implementation.\nImglib provides interfaces to ImageJ for importing, exporting and visualizing data.\nAs a consequence of its generic aims, the library allows and requires a different way of designing and implementing algorithms. We will first give an overview of ImgLib and its basic design elements and will then hands-on implement a selection of simple algorithms to mediate the way of programming.",
    "crumbs": [
      "Into ImgLib - Generic Image Processing in Java"
    ]
  },
  {
    "objectID": "imglib1/workshop.html#workshop-material",
    "href": "imglib1/workshop.html#workshop-material",
    "title": "Into ImgLib - Generic Image Processing in Java",
    "section": "Workshop Material",
    "text": "Workshop Material\n\nAn overview of the workshop\nThe corresponding ImgLib publication in the Proceedings of the ImageJ Conference 2010\nCode examples and images including all libraries (16MB, for non-Fiji users)\nCode examples and images without libraries (4MB, for Fiji users)\nCode examples without images and libraries (15KB, for Fiji users)",
    "crumbs": [
      "Into ImgLib - Generic Image Processing in Java"
    ]
  },
  {
    "objectID": "imglib1/workshop.html#references",
    "href": "imglib1/workshop.html#references",
    "title": "Into ImgLib - Generic Image Processing in Java",
    "section": "References",
    "text": "References\n\nImageJ Conference 2010 programme entry\nFiji-devel mailing list discusses imglib development and questions\nMore about ImgLib on the Fiji wiki",
    "crumbs": [
      "Into ImgLib - Generic Image Processing in Java"
    ]
  },
  {
    "objectID": "blog/2024-02-27-n5-tutorial-basic/N5-Basics-Tutorial.html",
    "href": "blog/2024-02-27-n5-tutorial-basic/N5-Basics-Tutorial.html",
    "title": "",
    "section": "",
    "text": "CodeShow All CodeHide All CodeView Source\n\n\n\n\n\n%mavenRepo scijava.public https://maven.scijava.org/content/groups/public\n%maven org.scijava:scijava-common:2.97.0\n%maven net.imglib2:imglib2:6.2.0\n%maven org.janelia.saalfeldlab:n5:3.1.2\n%maven org.janelia.saalfeldlab:n5-imglib2:7.0.0\n%maven org.janelia.saalfeldlab:n5-universe:1.3.1\n\n\nimport java.nio.file.*;\nimport java.util.stream.*;\nimport java.util.concurrent.*;\n\nimport com.google.gson.*;\n\nimport net.imglib2.*;\nimport net.imglib2.img.array.*;\nimport net.imglib2.type.numeric.real.*;\nimport net.imglib2.view.*;\nimport net.imglib2.util.*;\n\nimport org.janelia.saalfeldlab.n5.*;\nimport org.janelia.saalfeldlab.n5.imglib2.*;\nimport org.janelia.saalfeldlab.n5.universe.*;\n\n\npublic static void pathInfo(Path p) {\n    try {\n        System.out.println(String.format(\"%s is %d bytes\", p, Files.size(p))); \n    } catch(IOException e ){}\n}\n\npublic static void printBlocks(String path) throws IOException {\n\n    try (Stream&lt;Path&gt; stream = Files.walk(Paths.get(path))) {\n        stream.filter(Files::isRegularFile)\n            .filter( p -&gt; p.getFileName().toString().matches(\"[0-9]\"))\n                .forEach( x -&gt; { pathInfo(x); });\n    }\n}\n\n\n// N5Factory can make N5Readers and N5Writers\nvar factory = new N5Factory();\n\n// trying to open a reader for a container that does not yet exist will throw an error \n// var n5Reader = factory.openReader(\"my-container.n5\");\n\n// creating a writer creates a container at the given location\n// if it does not already exist\nvar n5Writer = factory.openWriter(\"my-container.n5\");\n\n// now we can make a reader\nvar n5Reader = factory.openReader(\"my-container.n5\");\n\n// test if the container exists\nn5Reader.exists(\"\"); // true\n\n// \"\" and \"/\" both refer to the root of the container\nn5Reader.exists(\"/\"); // true\n\n\nfactory.openWriter(\"my-container.h5\").getClass();   // HDF5 Format N5Writer\nfactory.openWriter(\"my-container.n5\").getClass();   // N5 Format   N5Writer\nfactory.openWriter(\"my-container.zarr\").getClass(); // Zarr Format N5Writer\n\n\nn5Writer.createGroup(\"foo\");\nn5Writer.createGroup(\"foo/bar\");\nn5Writer.createGroup(\"lorum/ipsum/dolor/sit/amet\");\n\nn5Writer.exists(\"lorum/ipsum\");      // true\nn5Writer.exists(\"not/a/real/group\"); // false\n\n\nn5Writer.list(\"\");     // [lorum, foo]\nn5Writer.list(\"foo\");  // [bar]\n\n\nArrays.toString(n5Writer.deepList(\"\"));\n\n[lorum, lorum/ipsum, lorum/ipsum/dolor, lorum/ipsum/dolor/sit, lorum/ipsum/dolor/sit/amet, foo, foo/bar]\n\n\n\npublic static RandomAccessibleInterval&lt;FloatType&gt; demoImage(long... size) {\n\n    final RandomAccessibleInterval&lt;FloatType&gt; img = ArrayImgs.floats(size);\n    float f = 0f;\n    Cursor&lt;FloatType&gt; c = Views.flatIterable(img).cursor();\n    while (c.hasNext())\n        c.next().set(f++);\n\n    return img;\n}\n\n\n// the parameters\nvar img = demoImage(64,64); // the image to write- size 64 x 64\nvar groupPath = \"data\"; \nvar blockSize = new int[]{32,32};\nvar compression = new GzipCompression();\n\n// save the image\nN5Utils.save(img, n5Writer, groupPath, blockSize, compression);\n\n\nvar exec = Executors.newFixedThreadPool(4); // with 4 parallel threads\nN5Utils.save(img, n5Writer, groupPath, blockSize, compression, exec);\n\n\n\nCode\nprintBlocks(\"my-container.n5/data\");\n\n\nmy-container.n5/data/1/1 is 1762 bytes\nmy-container.n5/data/1/0 is 2012 bytes\nmy-container.n5/data/0/1 is 1763 bytes\nmy-container.n5/data/0/0 is 2020 bytes\n\n\n\n// remove the old data\nn5Writer.remove(groupPath);\n\n// rewrite with a different block size\nvar blockSize = new int[]{64,8};\nN5Utils.save(img, n5Writer, groupPath, blockSize, compression);\n\n// how many blocks are there?\nprintBlocks(\"my-container.n5/data\");\n\nmy-container.n5/data/0/1 is 837 bytes\nmy-container.n5/data/0/7 is 847 bytes\nmy-container.n5/data/0/3 is 839 bytes\nmy-container.n5/data/0/6 is 844 bytes\nmy-container.n5/data/0/0 is 968 bytes\nmy-container.n5/data/0/4 is 846 bytes\nmy-container.n5/data/0/2 is 840 bytes\nmy-container.n5/data/0/5 is 847 bytes\n\n\n\n// rewrite without compression\nvar groupPath = \"dataNoCompression\"; \nvar blockSize = new int[]{32,32};\nvar compression = new RawCompression();\nN5Utils.save(img, n5Writer, groupPath, blockSize, compression);\n\n// what size are the blocks?\n\n\n\nCode\nprintBlocks(\"my-container.n5/dataNoCompression\");\n\n\nmy-container.n5/dataNoCompression/1/1 is 4108 bytes\nmy-container.n5/dataNoCompression/1/0 is 4108 bytes\nmy-container.n5/dataNoCompression/0/1 is 4108 bytes\nmy-container.n5/dataNoCompression/0/0 is 4108 bytes\n\n\n\nvar loadedImg = N5Utils.open(n5Writer, groupPath);\nUtil.getTypeFromInterval(loadedImg).getClass();      // FloatType\nArrays.toString(loadedImg.dimensionsAsLongArray());  // [64, 64]\n\n\n// overwrite our previous data\nvar img = ArrayImgs.unsignedBytes(2,2);\nN5Utils.save(img, n5Writer, groupPath, blockSize, compression);\n\n// load the new data, the old data are no longer accessible\nvar loadedImg = N5Utils.open(n5Writer, groupPath);\nArrays.toString(loadedImg.dimensionsAsLongArray());  // [2, 2]\n\n\n// create a group inside the container (think: \"folder\")\nvar groupName = \"put-data-in-me\";\nn5Writer.createGroup(groupName);\n\n// attributes have names and values\n// make an attribute called \"date\" with a String value\nvar attributeName = \"date\";\nn5Writer.setAttribute(groupName, attributeName, \"2024-Jan-01\");\n\n// Ask the N5 API to make a double array from the data attribute\n// it will try and fail, so an exception will be thrown\ntry {\n    var nothing = n5Writer.getAttribute(groupName, attributeName, double[].class);\n} catch( N5Exception e ) {\n    System.out.println(\"Error: could not get attribute as double[]\");\n}\n\n// get the value of the \"date\" attribute as a String\nString date = n5Writer.getAttribute(groupName, attributeName, String.class);\ndate\n\nError: could not get attribute as double[]\n\n\n2024-Jan-01\n\n\n\nn5Writer.setAttribute(groupName, \"a\", 42);\nvar num = n5Writer.getAttribute(groupName, \"a\", double.class); // 42.0\nvar str = n5Writer.getAttribute(groupName, \"a\", String.class); // \"42\"\n\n\n\nCode\nclass FunWithMetadata {\n    String name;\n    int number;\n    double[] data;\n    \n    public FunWithMetadata(String name, int number, double[] data) {\n        this.name = name;\n        this.number = number;\n        this.data = data;\n    }\n    public String toString(){\n        return String.format( \"FunWithMetadata{%s(%d): %s}\", \n            name, number, Arrays.toString(data));\n    }\n};\n\n\n\nvar metadata = new FunWithMetadata(\"Dorothy\", 2, new double[]{2.72, 3.14});\nn5Writer.setAttribute(groupName, \"metadata\", metadata);\n\n// get attribute as an instance of FunWithMetdata\nn5Writer.getAttribute(groupName, \"metadata\",  FunWithMetadata.class);\n\nFunWithMetadata{Dorothy(2): [2.72, 3.14]}\n\n\n\n// get attribute as an instance of JsonElement\nn5Writer.getAttribute(groupName, \"/\", JsonElement.class);\n\n{\"date\":\"2024-Jan-01\",\"a\":42,\"metadata\":{\"name\":\"Dorothy\",\"number\":2,\"data\":[2.72,3.14]}}\n\n\n\n// set attributes\nn5Writer.setAttribute(groupName, \"sender\", \"Alice\");\nn5Writer.setAttribute(groupName, \"receiver\", \"Bob\");\n\n// notice that they're set\nn5Writer.getAttribute(groupName, \"sender\", String.class);   // Alice\nn5Writer.getAttribute(groupName, \"receiver\", String.class); // Bob\n\n// remove \"sender\"\nn5Writer.removeAttribute(groupName, \"sender\");\n\n// remove \"receiver\" and store result in a variable\nvar receiver = n5Writer.removeAttribute(groupName, \"receiver\", String.class); // Bob\n\nn5Writer.getAttribute(groupName, \"sender\", String.class);   // null\nn5Writer.getAttribute(groupName, \"receiver\", String.class); // null\n\n\nArrays.toString(n5Writer.getAttribute(\"data\", \"dimensions\", long[].class));\n\n[64, 64]\n\n\n\nvar arrayMetadata = n5Writer.getDatasetAttributes(\"data\");\narrayMetadata.getDimensions();\narrayMetadata.getBlockSize();\narrayMetadata.getDataType();\narrayMetadata.getCompression();"
  },
  {
    "objectID": "blog/2022-10-30-Adding-Stream-support-to-ImgLib2/2022-10-30-Adding-Stream-support-to-ImgLib2.html",
    "href": "blog/2022-10-30-Adding-Stream-support-to-ImgLib2/2022-10-30-Adding-Stream-support-to-ImgLib2.html",
    "title": "Adding Stream support to ImgLib2",
    "section": "",
    "text": "Examples and a discussion on performance\n\nThis blogpost can also be found at image.sc https://forum.image.sc/t/adding-stream-support-to-imglib2/88078\nThe recently released imglib2-6.3.0 adds support for Java Streams.\n\n\nThe first addition is that every IterableRealInterval&lt;T&gt; (and sub-classes like IterableInterval, Img, …) can now provide (sequential or parallel) streams over its elements.\n\npublic interface IterableRealInterval&lt;T&gt; extends RealInterval, Iterable&lt;T&gt; {\n    ...\n    Stream&lt;T&gt; stream();\n    Stream&lt;T&gt; parallelStream();\n}\n\nThis is entirely equivalent to ‘java.util.Collection’\n\npublic interface Collection&lt;T&gt; extends Iterable&lt;T&gt; {\n    ...\n    Stream&lt;T&gt; stream();\n    Stream&lt;T&gt; parallelStream();\n}\n\nand allows to operate on pixel values.\nEncounter order of the streams is always compatible with cursor(). That is, Views.flatIterable(img).stream() yields elements in flat iteration order.\nStreams can be used, for example, to set all pixels of an Img to some value:\n\nstatic &lt;T extends Type&lt;T&gt;&gt; void fill(Img&lt;T&gt; img, T value) {\n    \n    img.stream().forEach(t-&gt;t.set(value));\n}\n\nto compute the sum of all values in an Img:\n\nstatic double sum(Img&lt;DoubleType&gt; img) {\n\n    return img.stream()\n            .mapToDouble(DoubleType::get)\n            .sum();\n}\n\nor to find the maximum value in an Img:\n\nstatic double max(Img&lt;DoubleType&gt; img) {\n\n        return img.stream()\n                .mapToDouble(DoubleType::get)\n                .max().getAsDouble();\n    }\n\nIn particular the latter two examples, where the terminal operation is some form of reduction, allow for more convenient parallelization than the alternatives. Computing the maximum value in parallel is as simple as\n\nstatic double max(Img&lt;DoubleType&gt; img) {\n\n    return img.parallelStream()\n            .mapToDouble(DoubleType::get)\n            .max().getAsDouble();\n}\n\nDoing the same with LoopBuilder currently requires to parallelize over chunks, collect partial results into mutable holder objects, and implement the reduction of partial results into the final result.\n\n\n\nA stream of only pixel values, without access to their positions is rather limiting. For example, we would often be interested in the location of the image maximum, not only the value. To achieve this, there is a new utility class net.imglib2.stream.Streams, with methods\n\npublic static &lt;T&gt; Stream&lt;RealLocalizableSampler&lt;T&gt;&gt; localizable(IterableRealInterval&lt;T&gt; interval)\npublic static &lt;T&gt; Stream&lt;RealLocalizableSampler&lt;T&gt;&gt; localizing(IterableRealInterval&lt;T&gt; interval)\npublic static &lt;T&gt; Stream&lt;LocalizableSampler&lt;T&gt;&gt; localizable(IterableInterval&lt;T&gt; interval)\npublic static &lt;T&gt; Stream&lt;LocalizableSampler&lt;T&gt;&gt; localizing(IterableInterval&lt;T&gt; interval)\n\nthat allow to create Streams of LocalizableSampler&lt;T&gt; of the pixels of an IterableInterval (and analogous for IterableRealInterval). You can think of LocalizableSampler&lt;T&gt; as a Cursor&lt;T&gt; which cannot be moved, which is more or less what the default implementation does under the hood.\nThe localizable and localizing variants are analogous to cursor() and localizingCursor() The Stream returned by localizable computes element locations only when asked to (with potentially higher per-element cost). The Stream returned by localizing tracks element locations always (in general faster, but potentially unnecessary).\nFor example, to fill image pixels with position-dependent values, we would use localizing, because we require the position of each element.\n\nstatic void fractal() {\n    \n    Img&lt;UnsignedByteType&gt; img = ArrayImgs.unsignedBytes(1000, 1000);\n    Streams.localizing(img)\n            .parallel()\n            .forEach(s -&gt; s.get().set(\n                    mandelbrot(\n                            (s.getDoublePosition(0) - 800) / 500,\n                            (s.getDoublePosition(1) - 500) / 500)\n            ));\n    BdvFunctions.show(img, \"mandelbrot\", Bdv.options().is2D());\n}\n\n\nConversely, to compute the maximum value and its location in an image, we would use localizable, because we only ask for the position of one element (the maximum).\n\nstatic void printMax(Img&lt;IntType&gt; img) {\n\n    Optional&lt;LocalizableSampler&lt;IntType&gt;&gt; optionalMax =\n            Streams.localizable(img)\n                    .parallel()\n                    .map(LocalizableSampler::copy)\n                    .max(Comparator.comparingInt(c -&gt; c.get().get()));\n    LocalizableSampler&lt;IntType&gt; max = optionalMax.get();\n    System.out.println(\"max position = \" + Util.printCoordinates(max));\n    System.out.println(\"max value = \" + max.get().getInteger());\n}\n\n(In both cases, it is fine to chose the respectively other variant with no change in behaviour, and only limited performance impact.)\n\n\n\nThe T elements of the stream are proxies that are re-used, as usual in ImgLib2. Explicit copying operations must be added if stream elements are supposed to be retained (by stateful intermediate or terminal operations).\nFor example, to collect all DoubleType values between 0 and 1 into a list:\n\nList&lt; DoubleType &gt; values = img.stream()\n    .filter( t -&gt; t.get() &gt;= 0.0 && t.get() &lt;= 1.0 )\n    .map( DoubleType::copy ) // &lt;-- this is important!\n    .collect( Collectors.toList() );\n\nThe .map(DoubleType::copy) operation is necessary, otherwise the values list will contain many duplicates of the same (re-used proxy) DoubleType instance. The copy could also be done before the .filter(...) operation, but it’s better to do it as late as possible to avoid unnecessary creation of objects.\nLikewise, the .map(LocalizableSampler::copy) in the printMax() example above is required. There is ongoing work to reduce the necessity of explicit copy operations. For example, in the printMax() example, the .max() operation of the stream could be overridden to only copy when a new maximum candidate is encountered.\nNote, that already the current implementation takes care not to re-use proxies across parallel execution, so threads of a parallelStream() will not interfere.\n\n\n\n\nBoth, pure-value streams and value-and-position streams make use of LocalizableSpliterator&lt;T&gt;. LocalizableSpliterator&lt;T&gt; extends Spliterator and Localizable, similiar to Cursor extending Iterator and Localizable.\nThere are default LocalizableSpliterator&lt;T&gt; (and RealLocalizableSpliterator&lt;T&gt;) implementations based on Cursor&lt;T&gt; (and RealCursor&lt;T&gt;). Therefore, the new streams API works for every IterableRealInterval, without the need to touch existing implementations.\nAdditionally, the standard Img classes have custom LocalizableSpliterator&lt;T&gt;, that leverage knowledge of underlying storage for improved performance.\n\n\n\n\nIt’s complicated…\nOne the one hand, there comes considerable performance overhead in replacing simple loops with stream operations. This has nothing to do with ImgLib2, it is just a “feature” of the underlying machinery. This can be observed for example by benchmarking looping over an int[] array:\n\nint[] values = new int[4_000_000];\n\n@Benchmark\npublic long benchmarkForLoopArray() {\n    long count = 0;\n    for (int value : values) {\n        if (value &gt; 127)\n            ++count;\n    }\n    return count;\n}\n\n@Benchmark\npublic long benchmarkStreamArray() {\n    return IntStream.of(values).filter(value -&gt; value &gt; 127).count();\n}\n\nThe result is\n\nBenchmark                                          Mode  Cnt   Score   Error  Units\nArrayStreamBenchmark.benchmarkForLoopArray         avgt   15   2,563 ± 0,026  ms/op\nArrayStreamBenchmark.benchmarkStreamArray          avgt   15  11,052 ± 0,022  ms/op\n\nThat is, the Stream version is &gt; 4 times slower. Equivalent performance overhead often can be observed in ImgLib2, when replacing Cursor based loops with Stream operations.\nOn the other hand, custom Spliterator implementations sometimes benefit more than cursors from tuning to the underlying storage. (Because iteration is “internal” with the spliterator, while the cursor must return control to the caller after every visited element.) For example, consider the following benchmark method (equivalent code for other variations omitted, see github for full details):\n\n@Benchmark\npublic long benchmarkStream() {\n    long sum = Streams.localizable(img)\n            .mapToLong(s -&gt; s.get().get()\n                    + s.getIntPosition(0)\n                    + s.getIntPosition(1)\n                    + s.getIntPosition(2)\n            ).sum();\n    return sum;\n}\n\nThe result looks like\n\nBenchmark                                                            (imgType)  Mode  Cnt   Score   Error  Units\nLocalizableSamplerStreamBenchmark.benchmarkCursor                     ArrayImg  avgt   15  10,097 ± 0,046  ms/op\nLocalizableSamplerStreamBenchmark.benchmarkLocalizingCursor           ArrayImg  avgt   15   3,846 ± 0,020  ms/op\nLocalizableSamplerStreamBenchmark.benchmarkLocalizingStream           ArrayImg  avgt   15   3,337 ± 0,027  ms/op\nLocalizableSamplerStreamBenchmark.benchmarkLocalizingParallelStream   ArrayImg  avgt   15   0,962 ± 0,583  ms/op\n\nThat is, the performance difference between localizing and non-localizing Cursors is much more pronounced than the difference between Cursor loop and Stream. In fact, the Stream version is even faster than the localizingCursor version. On top of that, it is trivial to parallelize.\nFinally, we did not investigate polymorphism effects so far. It is very much possible that this affects performance and we may have to investigate employing LoopBuilders class-copying mechanism to counter these effects.\nIn summary, I think one should not hesitate to use Streams where it makes sense from a readability and ease-of-use perspective. If performance is a critical concern, it is best to benchmark various approaches, because the behaviour is not easy to predict."
  },
  {
    "objectID": "blog/2022-10-30-Adding-Stream-support-to-ImgLib2/2022-10-30-Adding-Stream-support-to-ImgLib2.html#access-img-pixels-as-a-stream",
    "href": "blog/2022-10-30-Adding-Stream-support-to-ImgLib2/2022-10-30-Adding-Stream-support-to-ImgLib2.html#access-img-pixels-as-a-stream",
    "title": "Adding Stream support to ImgLib2",
    "section": "",
    "text": "The first addition is that every IterableRealInterval&lt;T&gt; (and sub-classes like IterableInterval, Img, …) can now provide (sequential or parallel) streams over its elements.\n\npublic interface IterableRealInterval&lt;T&gt; extends RealInterval, Iterable&lt;T&gt; {\n    ...\n    Stream&lt;T&gt; stream();\n    Stream&lt;T&gt; parallelStream();\n}\n\nThis is entirely equivalent to ‘java.util.Collection’\n\npublic interface Collection&lt;T&gt; extends Iterable&lt;T&gt; {\n    ...\n    Stream&lt;T&gt; stream();\n    Stream&lt;T&gt; parallelStream();\n}\n\nand allows to operate on pixel values.\nEncounter order of the streams is always compatible with cursor(). That is, Views.flatIterable(img).stream() yields elements in flat iteration order.\nStreams can be used, for example, to set all pixels of an Img to some value:\n\nstatic &lt;T extends Type&lt;T&gt;&gt; void fill(Img&lt;T&gt; img, T value) {\n    \n    img.stream().forEach(t-&gt;t.set(value));\n}\n\nto compute the sum of all values in an Img:\n\nstatic double sum(Img&lt;DoubleType&gt; img) {\n\n    return img.stream()\n            .mapToDouble(DoubleType::get)\n            .sum();\n}\n\nor to find the maximum value in an Img:\n\nstatic double max(Img&lt;DoubleType&gt; img) {\n\n        return img.stream()\n                .mapToDouble(DoubleType::get)\n                .max().getAsDouble();\n    }\n\nIn particular the latter two examples, where the terminal operation is some form of reduction, allow for more convenient parallelization than the alternatives. Computing the maximum value in parallel is as simple as\n\nstatic double max(Img&lt;DoubleType&gt; img) {\n\n    return img.parallelStream()\n            .mapToDouble(DoubleType::get)\n            .max().getAsDouble();\n}\n\nDoing the same with LoopBuilder currently requires to parallelize over chunks, collect partial results into mutable holder objects, and implement the reduction of partial results into the final result."
  },
  {
    "objectID": "blog/2022-10-30-Adding-Stream-support-to-ImgLib2/2022-10-30-Adding-Stream-support-to-ImgLib2.html#access-img-values-and-positions-as-a-stream",
    "href": "blog/2022-10-30-Adding-Stream-support-to-ImgLib2/2022-10-30-Adding-Stream-support-to-ImgLib2.html#access-img-values-and-positions-as-a-stream",
    "title": "Adding Stream support to ImgLib2",
    "section": "",
    "text": "A stream of only pixel values, without access to their positions is rather limiting. For example, we would often be interested in the location of the image maximum, not only the value. To achieve this, there is a new utility class net.imglib2.stream.Streams, with methods\n\npublic static &lt;T&gt; Stream&lt;RealLocalizableSampler&lt;T&gt;&gt; localizable(IterableRealInterval&lt;T&gt; interval)\npublic static &lt;T&gt; Stream&lt;RealLocalizableSampler&lt;T&gt;&gt; localizing(IterableRealInterval&lt;T&gt; interval)\npublic static &lt;T&gt; Stream&lt;LocalizableSampler&lt;T&gt;&gt; localizable(IterableInterval&lt;T&gt; interval)\npublic static &lt;T&gt; Stream&lt;LocalizableSampler&lt;T&gt;&gt; localizing(IterableInterval&lt;T&gt; interval)\n\nthat allow to create Streams of LocalizableSampler&lt;T&gt; of the pixels of an IterableInterval (and analogous for IterableRealInterval). You can think of LocalizableSampler&lt;T&gt; as a Cursor&lt;T&gt; which cannot be moved, which is more or less what the default implementation does under the hood.\nThe localizable and localizing variants are analogous to cursor() and localizingCursor() The Stream returned by localizable computes element locations only when asked to (with potentially higher per-element cost). The Stream returned by localizing tracks element locations always (in general faster, but potentially unnecessary).\nFor example, to fill image pixels with position-dependent values, we would use localizing, because we require the position of each element.\n\nstatic void fractal() {\n    \n    Img&lt;UnsignedByteType&gt; img = ArrayImgs.unsignedBytes(1000, 1000);\n    Streams.localizing(img)\n            .parallel()\n            .forEach(s -&gt; s.get().set(\n                    mandelbrot(\n                            (s.getDoublePosition(0) - 800) / 500,\n                            (s.getDoublePosition(1) - 500) / 500)\n            ));\n    BdvFunctions.show(img, \"mandelbrot\", Bdv.options().is2D());\n}\n\n\nConversely, to compute the maximum value and its location in an image, we would use localizable, because we only ask for the position of one element (the maximum).\n\nstatic void printMax(Img&lt;IntType&gt; img) {\n\n    Optional&lt;LocalizableSampler&lt;IntType&gt;&gt; optionalMax =\n            Streams.localizable(img)\n                    .parallel()\n                    .map(LocalizableSampler::copy)\n                    .max(Comparator.comparingInt(c -&gt; c.get().get()));\n    LocalizableSampler&lt;IntType&gt; max = optionalMax.get();\n    System.out.println(\"max position = \" + Util.printCoordinates(max));\n    System.out.println(\"max value = \" + max.get().getInteger());\n}\n\n(In both cases, it is fine to chose the respectively other variant with no change in behaviour, and only limited performance impact.)"
  },
  {
    "objectID": "blog/2022-10-30-Adding-Stream-support-to-ImgLib2/2022-10-30-Adding-Stream-support-to-ImgLib2.html#pitfalls",
    "href": "blog/2022-10-30-Adding-Stream-support-to-ImgLib2/2022-10-30-Adding-Stream-support-to-ImgLib2.html#pitfalls",
    "title": "Adding Stream support to ImgLib2",
    "section": "",
    "text": "The T elements of the stream are proxies that are re-used, as usual in ImgLib2. Explicit copying operations must be added if stream elements are supposed to be retained (by stateful intermediate or terminal operations).\nFor example, to collect all DoubleType values between 0 and 1 into a list:\n\nList&lt; DoubleType &gt; values = img.stream()\n    .filter( t -&gt; t.get() &gt;= 0.0 && t.get() &lt;= 1.0 )\n    .map( DoubleType::copy ) // &lt;-- this is important!\n    .collect( Collectors.toList() );\n\nThe .map(DoubleType::copy) operation is necessary, otherwise the values list will contain many duplicates of the same (re-used proxy) DoubleType instance. The copy could also be done before the .filter(...) operation, but it’s better to do it as late as possible to avoid unnecessary creation of objects.\nLikewise, the .map(LocalizableSampler::copy) in the printMax() example above is required. There is ongoing work to reduce the necessity of explicit copy operations. For example, in the printMax() example, the .max() operation of the stream could be overridden to only copy when a new maximum candidate is encountered.\nNote, that already the current implementation takes care not to re-use proxies across parallel execution, so threads of a parallelStream() will not interfere."
  },
  {
    "objectID": "blog/2022-10-30-Adding-Stream-support-to-ImgLib2/2022-10-30-Adding-Stream-support-to-ImgLib2.html#implementation-details",
    "href": "blog/2022-10-30-Adding-Stream-support-to-ImgLib2/2022-10-30-Adding-Stream-support-to-ImgLib2.html#implementation-details",
    "title": "Adding Stream support to ImgLib2",
    "section": "",
    "text": "Both, pure-value streams and value-and-position streams make use of LocalizableSpliterator&lt;T&gt;. LocalizableSpliterator&lt;T&gt; extends Spliterator and Localizable, similiar to Cursor extending Iterator and Localizable.\nThere are default LocalizableSpliterator&lt;T&gt; (and RealLocalizableSpliterator&lt;T&gt;) implementations based on Cursor&lt;T&gt; (and RealCursor&lt;T&gt;). Therefore, the new streams API works for every IterableRealInterval, without the need to touch existing implementations.\nAdditionally, the standard Img classes have custom LocalizableSpliterator&lt;T&gt;, that leverage knowledge of underlying storage for improved performance."
  },
  {
    "objectID": "blog/2022-10-30-Adding-Stream-support-to-ImgLib2/2022-10-30-Adding-Stream-support-to-ImgLib2.html#performance",
    "href": "blog/2022-10-30-Adding-Stream-support-to-ImgLib2/2022-10-30-Adding-Stream-support-to-ImgLib2.html#performance",
    "title": "Adding Stream support to ImgLib2",
    "section": "",
    "text": "It’s complicated…\nOne the one hand, there comes considerable performance overhead in replacing simple loops with stream operations. This has nothing to do with ImgLib2, it is just a “feature” of the underlying machinery. This can be observed for example by benchmarking looping over an int[] array:\n\nint[] values = new int[4_000_000];\n\n@Benchmark\npublic long benchmarkForLoopArray() {\n    long count = 0;\n    for (int value : values) {\n        if (value &gt; 127)\n            ++count;\n    }\n    return count;\n}\n\n@Benchmark\npublic long benchmarkStreamArray() {\n    return IntStream.of(values).filter(value -&gt; value &gt; 127).count();\n}\n\nThe result is\n\nBenchmark                                          Mode  Cnt   Score   Error  Units\nArrayStreamBenchmark.benchmarkForLoopArray         avgt   15   2,563 ± 0,026  ms/op\nArrayStreamBenchmark.benchmarkStreamArray          avgt   15  11,052 ± 0,022  ms/op\n\nThat is, the Stream version is &gt; 4 times slower. Equivalent performance overhead often can be observed in ImgLib2, when replacing Cursor based loops with Stream operations.\nOn the other hand, custom Spliterator implementations sometimes benefit more than cursors from tuning to the underlying storage. (Because iteration is “internal” with the spliterator, while the cursor must return control to the caller after every visited element.) For example, consider the following benchmark method (equivalent code for other variations omitted, see github for full details):\n\n@Benchmark\npublic long benchmarkStream() {\n    long sum = Streams.localizable(img)\n            .mapToLong(s -&gt; s.get().get()\n                    + s.getIntPosition(0)\n                    + s.getIntPosition(1)\n                    + s.getIntPosition(2)\n            ).sum();\n    return sum;\n}\n\nThe result looks like\n\nBenchmark                                                            (imgType)  Mode  Cnt   Score   Error  Units\nLocalizableSamplerStreamBenchmark.benchmarkCursor                     ArrayImg  avgt   15  10,097 ± 0,046  ms/op\nLocalizableSamplerStreamBenchmark.benchmarkLocalizingCursor           ArrayImg  avgt   15   3,846 ± 0,020  ms/op\nLocalizableSamplerStreamBenchmark.benchmarkLocalizingStream           ArrayImg  avgt   15   3,337 ± 0,027  ms/op\nLocalizableSamplerStreamBenchmark.benchmarkLocalizingParallelStream   ArrayImg  avgt   15   0,962 ± 0,583  ms/op\n\nThat is, the performance difference between localizing and non-localizing Cursors is much more pronounced than the difference between Cursor loop and Stream. In fact, the Stream version is even faster than the localizingCursor version. On top of that, it is trivial to parallelize.\nFinally, we did not investigate polymorphism effects so far. It is very much possible that this affects performance and we may have to investigate employing LoopBuilders class-copying mechanism to counter these effects.\nIn summary, I think one should not hesitate to use Streams where it makes sense from a readability and ease-of-use perspective. If performance is a critical concern, it is best to benchmark various approaches, because the behaviour is not easy to predict."
  },
  {
    "objectID": "blog/2022-06-05-setup-ijava-jupyter-kernel/setup-ijava-jupyter-kernel.html",
    "href": "blog/2022-06-05-setup-ijava-jupyter-kernel/setup-ijava-jupyter-kernel.html",
    "title": "Setup the IJava jupyter kernel",
    "section": "",
    "text": "In this blog, we will show code snippets and examples to make the best use of ImgLib2, BigDataViewer, and friends. ImgLib2 is written to be fast and we will run code that needs to be compiled, so we cannot use any of the various interpreted scripting languages like Python, Groovy, or Javascript. Instead, we will use the JShell tool that you can use directly in a terminal or through Spencer Park’s IJava jupyter kernel. You can also follow these tutorials in your own Java project and use your preferred IDE, but Jupyter notebooks are a great teaching tool. Since jupyter is written in Python and most popular with the Python community, let’s follow their ways and first thing create a virtual environment with conda. The lack of version controlled dependency management for Python projects makes it necessary that practically every project must run in a container or virtual environment because the dependencies of different projects almost inevitably collide. Conda is the most popular of several attempts to address this situation. Conda cannot currently be installed from the default Ubuntu repositories, so much about that, but the installation instructions are tolerable, there is a PPA. Now let’s create an environment for jupyter:\nconda create -n jshell-jupyter python=3\nconda init bash\nconda activate jshell-jupyter\nconda install jupyter\nYou will also need a modern Java and Maven on your system, so if you have not yet done so, install it:\nsudo apt install openjdk-17-jdk maven\nThe original IJava kernel currently does not build with Java 17 or 18, so we use Philipp Hanslovsky’s fork and build and install both the kernel installer and the IJava Jupyter kernel:\ngit clone https://github.com/hanslovsky/Jupyter-kernel-installer-gradle.git\ncd Jupyter-kernel-installer-gradle/\ngit checkout try-upgrade-gradle\n./gradlew publishToMavenLocal\n\ncd ..\ngit clone https://github.com/saalfeldlab/IJava.git\ncd IJava/\n./gradlew installKernel\nNow check if the kernel is installed, this should print something like this\njupyter kernelspec list\n\nAvailable kernels:\n  java       /home/saalfeld/.local/share/jupyter/kernels/java\n  python3    /home/saalfeld/anaconda3/envs/jshell-jupyter/share/jupyter/kernels/python3\nYou can now start the jupyter notebook server\njupyter notebook --kernel=java\nAnd experiment with the examples. Spencer Park’s IJava jupyter kernel makes it very easy to include dependencies. You can include the relevant snippets from a Maven POM into a tagged code block, e.g.\n%%loadFromPOM\n&lt;repository&gt;\n    &lt;id&gt;scijava.public&lt;/id&gt;\n    &lt;url&gt;https://maven.scijava.org/content/groups/public&lt;/url&gt;\n&lt;/repository&gt;\n&lt;dependency&gt;\n    &lt;groupId&gt;sc.fiji&lt;/groupId&gt;\n    &lt;artifactId&gt;bigdataviewer-vistools&lt;/artifactId&gt;\n    &lt;version&gt;1.0.0-beta-29&lt;/version&gt;\n&lt;/dependency&gt;\nor in gradle short notation\n%mavenRepo scijava.public https://maven.scijava.org/content/groups/public\n%maven sc.fiji:bigdataviewer-vistools:1.0.0-beta-29\nIf you prefer to run JShell directly, you can pull in the dependencies from a complete Maven POM with John Pooth’s Maven Jshell plugin\nmvn compile com.github.johnpoth:jshell-maven-plugin:1.3:run\nHappy JShelling!\nP.S.:\nThe original IJava kernel currently does not build with Java 17 or 18, so if you prefer this over the above fork, or if you do not care about the latest greatest language features in Java 17, then the easiest at this time is to use OpenJDK-11. If you don’t have it yet, install it via conda:\nconda install openjdk\nconda install -c conda-forge maven\nHowever, this may take a day of solving environments, so you can also install it globally:\nsudo apt install openjdk-11-jdk maven\nIf you have other versions installed, you can switch between them with the alternatives tool:\nsudo update-alternatives --config java\nsudo update-alternatives --config javac\nNow check out the original IJava and build and install the kernel IJava Jupyter kernel following the installation instructions or:\ngit clone https://github.com/SpencerPark/IJava.git\ncd IJava/\n./gradlew installKernel\njupyter kernelspec list\nDone."
  },
  {
    "objectID": "blog/2022-05-02-juliaset-lambda/2022-05-02-juliaset-lambda.html",
    "href": "blog/2022-05-02-juliaset-lambda/2022-05-02-juliaset-lambda.html",
    "title": "Juliaset Lambda",
    "section": "",
    "text": "Import dependencies. BigDataViewer Vistools is the convenience API that we use to display the results of our experiments and it includes all ImgLib2 related dependencies that we need. We also import the ImgLib2 bridge to ImageJ, because we want to use ImageJ’s API to display ImgLib2 data in this notebook.\n\n%mavenRepo scijava.public https://maven.scijava.org/content/groups/public\n%maven sc.fiji:bigdataviewer-vistools:1.0.0-beta-29\n%maven net.imglib2:imglib2-ij:2.0.0-beta-46\n\nimport bdv.util.*;\nimport io.github.spencerpark.jupyter.kernel.display.common.*;\nimport io.github.spencerpark.jupyter.kernel.display.mime.*;\nimport net.imglib2.img.display.imagej.*;\nimport net.imglib2.view.*;\nimport net.imglib2.*;\nimport net.imglib2.position.FunctionRealRandomAccessible;\nimport net.imglib2.type.numeric.integer.*;\nimport net.imglib2.util.Intervals;\nimport net.imglib2.realtransform.*;\n\n\n\nCode\n// register renderer for ImgLib2 data and arrays\ngetKernelInstance().getRenderer().createRegistration(RandomAccessibleInterval.class)\n        .preferring(MIMEType.IMAGE_PNG)\n        .supporting(MIMEType.IMAGE_JPEG, MIMEType.IMAGE_GIF)\n        .register((rai, context) -&gt; Image.renderImage(\n                ImageJFunctions.wrap(rai, rai.toString()).getBufferedImage(),\n                context));\n\ngetKernelInstance().getRenderer().createRegistration(RandomAccessible.class)\n        .preferring(MIMEType.IMAGE_PNG)\n        .supporting(MIMEType.IMAGE_JPEG, MIMEType.IMAGE_GIF)\n        .register((ra, context) -&gt; Image.renderImage(\n                ImageJFunctions.wrap(\n                        Views.interval(\n                                ra,\n                                new FinalInterval(\n                                        Arrays.copyOf(\n                                                new long[]{512, 512},\n                                                ra.numDimensions()))),\n                        ra.toString()).getBufferedImage(),\n                context));\n\ngetKernelInstance().getRenderer().createRegistration(RealRandomAccessible.class)\n        .preferring(MIMEType.IMAGE_PNG)\n        .supporting(MIMEType.IMAGE_JPEG, MIMEType.IMAGE_GIF)\n        .register((rra, context) -&gt; Image.renderImage(\n                ImageJFunctions.wrap(\n                        Views.interval(\n                                Views.raster(rra),\n                                new FinalInterval(\n                                        Arrays.copyOf(\n                                                new long[]{512, 512},\n                                                rra.numDimensions()))),\n                        rra.toString()).getBufferedImage(),\n                context));\n\n\nWe define the Juliaset as a function in 2D real space using a BiConsumer lambda. The BiConsumer receives two parameters, the first one (x) is the 2D coordinate, the second one (y) is the target of the function whose value will be set in place, here we use an IntType. We also have to provide a Supplier for instances of the target such that multiple threads can each create their own.\n\nvar juliaset = new FunctionRealRandomAccessible&lt;&gt;(\n    2,\n    (x, fx) -&gt; {\n        int i = 0;\n        double v = 0, c = x.getDoublePosition(0), d = x.getDoublePosition(1);\n        for (; i &lt; 255 && v &lt; 4096; ++i) {\n            final double e = c * c - d * d;\n            d = 2 * c * d;\n            c = e + 0.3;\n            d += 0.6;\n            v = Math.sqrt(c * c + d * d);\n            ++i;\n        }\n        fx.set(i);\n    },\n    UnsignedByteType::new);\n\nNow we show this function with BigDataViewer. Use your mouse and keyboard to zoom in until you reach the precision limit of double.\n\nBdvFunctions.show(\n    juliaset,\n    Intervals.createMinMax(-1, -1, 1, 1),\n    \"bla\",\n    BdvOptions.options().is2D()).setDisplayRange(0, 127);\n\nWe can also render a snapshot into this notebook.\n\nvar transform = new ScaleAndTranslation(new double[]{255, 255}, new double[]{255, 255});\nvar transformed = RealViews.affineReal(juliaset, transform);\ntransformed;\n\n\n\n\n\n\n\n\nCool? I think so! Now let’s embed one of the two parameters of the Juliaset as a third dimension. The code is almost the same except that we introduce a a variable a.\n\nvar juliaset3 = new FunctionRealRandomAccessible&lt;&gt;(\n    3,\n    (x, fx) -&gt; {\n        int i = 0;\n        double v = 0, c = x.getDoublePosition(0), d = x.getDoublePosition(1), a = x.getDoublePosition(2);\n        for (; i &lt; 255 && v &lt; 4096; ++i) {\n            final double e = c * c - d * d;\n            d = 2 * c * d;\n            c = e + a;\n            d += 0.6;\n            v = Math.sqrt(c * c + d * d);\n            ++i;\n        }\n        fx.set(i);\n    },\n    IntType::new);\n\nAnd now we show this as a 3D volume in BigDataViewer. You can scroll through the ‘z’-dimension or arbitrarily slice through the 3D volume.\n\nBdvFunctions.show(\n    juliaset3,\n    Intervals.createMinMax(-1, -1, -1, 1, 1, 1),\n    \"Juliaset3\",\n    BdvOptions.options()).setDisplayRange(0, 127);\n\nThis was using a stateless function, i.e. each RealRandomAccess uses the same instance. If you have stateful functions, you want to use a function provider. Spot the difference:\n\nfinal var rnd = new Random();\nvar juliaset3Stripes = new FunctionRealRandomAccessible&lt;&gt;(\n    3,\n    () -&gt;\n    { \n        final int offset = rnd.nextInt(100);\n        return (x, fx) -&gt; {\n            int i = 0;\n            double v = 0, c = x.getDoublePosition(0), d = x.getDoublePosition(1), a = x.getDoublePosition(2);\n            for (; i &lt; 255 && v &lt; 4096; ++i) {\n                final double e = c * c - d * d;\n                d = 2 * c * d;\n                c = e + a;\n                d += 0.6;\n                v = Math.sqrt(c * c + d * d);\n                ++i;\n            }\n            fx.set(i + offset);\n        };\n    },\n    IntType::new);\n\n\nBdvFunctions.show(\n    juliaset3Stripes,\n    Intervals.createMinMax(-1, -1, -1, 1, 1, 1),\n    \"Juliaset3\",\n    BdvOptions.options()).setDisplayRange(0, 127);\n\nWe see here, how BigDataViewer uses multiple threads to render each frame, and each thread creates its own independent RealRandomAccess to ‘access the pixels’ (the generator function generates them on the fly). To visualize this, we add a random number to the pixel values that the generator produces. This state is unique to the generator of each RealRandomAccess and that allows us to see the regions in the output image that are generated by each thread."
  },
  {
    "objectID": "blog/2024-02-14-displacementFields/2024-02-14-displacementFields.html",
    "href": "blog/2024-02-14-displacementFields/2024-02-14-displacementFields.html",
    "title": "Position and displacement field transformations",
    "section": "",
    "text": "This post shows how to create and apply non-linear transformations with ImgLib2, specifically using DisplacementFieldTransforms and PositionFieldTransforms.\nThe last example of this post will show how to use a PositionFieldTransform to create a 2D image from a 1D signal by a transformation of coordinates.\n\n\n\n\n\n\n\nA 2D image created after transformation\nof this 1D function\n\n\n\n\n\n\n\n\n\nThe code folded below sets up dependencies, imports classes, and makes it convenient to show image output as shown in this post.\n\n\nCode\n%mavenRepo scijava.public https://maven.scijava.org/content/groups/public\n\n%maven net.imagej:ij:1.54f\n%maven org.scijava:scijava-common:2.97.0\n%maven net.imglib2:imglib2:6.2.0\n%maven net.imglib2:imglib2-ij:2.0.1\n%maven net.imglib2:imglib2-realtransform:4.0.1\n%maven org.knowm.xchart:xchart:3.5.4\n    \nimport java.util.function.*;\nimport java.util.stream.*;\nimport java.awt.image.BufferedImage;\n\nimport io.github.spencerpark.jupyter.kernel.display.common.*;\nimport io.github.spencerpark.jupyter.kernel.display.mime.*;\n\nimport org.knowm.xchart.*;\nimport org.knowm.xchart.style.Styler.LegendPosition;\nimport org.knowm.xchart.style.markers.SeriesMarkers;\n\nimport ij.*;\nimport net.imglib2.*;\nimport net.imglib2.view.*;\nimport net.imglib2.util.*;\nimport net.imglib2.realtransform.*;\nimport net.imglib2.position.*;\nimport net.imglib2.type.numeric.*;\nimport net.imglib2.type.numeric.real.*;\nimport net.imglib2.type.numeric.integer.*;\nimport net.imglib2.interpolation.randomaccess.*;\nimport net.imglib2.img.display.imagej.*;\nimport net.imglib2.img.imageplus.ImagePlusImgs;\nimport net.imglib2.img.array.ArrayImgs;\n\npublic static &lt;T extends NumericType&lt;T&gt;&gt; BufferedImage toBuffferedImage(RandomAccessibleInterval rai) {\n\n    return ImageJFunctions.wrap((RandomAccessibleInterval&lt;T&gt;)rai, \"\").getBufferedImage();\n}\n\ngetKernelInstance().getRenderer().createRegistration(RandomAccessibleInterval.class)\n        .preferring(MIMEType.IMAGE_PNG)\n        .supporting(MIMEType.IMAGE_JPEG, MIMEType.IMAGE_GIF)\n        .register((rai, context) -&gt; Image.renderImage(toBuffferedImage(rai),context));\n\nvar printWriter = new PrintWriter(System.out,true);\nchar rarrow = '\\u2192';\n\npublic static void printTformPts(RealPoint x, RealPoint y) {\n    \n    printWriter.println(String.format(\"%s %s %s\", x, rarrow, y));\n};\n\n\n\nDisplacement fields\nA displacement field is the most common way to represent and store non-linear transformations. Imagine an image where a vector is stored at every position \\(\\mathbf{x}\\). That vector describes how much and in what direction the position \\(\\mathbf{x}\\) should be translated, or displaced.\n\\[\n\\begin{align}\n\\mathbf{x} &: \\text{a position } \\\\\n\\mathbf{v}( \\mathbf{x} ) &: \\text{the vector at position } \\mathbf{x}\\\\\n\\mathbf{x} + \\mathbf{v}( \\mathbf{x} ) &: \\text{the output of the transformation}\n\\end{align}\n\\]\nFor example, let’s consider an example vector field with the vector \\([50, -25]\\) at every position. This will be equivalent to a simple global translation and is not the recommended way to represent a translation, but will be instructive thanks to its simplicity.\nA FunctionRealRandomAccessible is one way to make a image containing a constant value (ConstantUtils is another way). This image can be passed directly to a DisplacementFieldTransform.\n\nvar displacementVector = new double[]{50, -25};        // the constant vector\n\n// an image that takes the value of displacementVector everywhere\nvar constantVector = new FunctionRealRandomAccessible&lt;&gt;(2,\n        (x, v) -&gt; { v.setPosition(displacementVector); }, // set the vector \n        () -&gt; { return DoubleType.createVector(2); });     // make a 2d vector\n\n// a constant displacement field\nvar dfieldConstant = new DisplacementFieldTransform(constantVector);\n\nApplying the transformation to any point translates that point by the same amount \\([50, -25]\\) , as expected:\n\n// two ways of initializing a point (0.0, 0.0)\nvar x = new RealPoint(0.0, 0.0); // give the coordinates as arguments\nvar y = new RealPoint(2);        // give the number of dimensions as an argument\n\n// transform x, store the result in y\ndfieldConstant.apply(x, y);\n // [0, 0] is transformed to [50, -25]\nprintTformPts(x, y);\n\n// [-50, 25] is transformed to [0, 0]\nx = new RealPoint(-50, 25);\ndfieldConstant.apply(x, y);\nprintTformPts(x, y);\n\n// [pi, 100k] is transformed to [pi + 50, 100k - 25]\nx = new RealPoint(Math.PI, 100000);\ndfieldConstant.apply(x, y);\nprintTformPts(x, y);\n\n(0.0,0.0) → (50.0,-25.0)\n(-50.0,25.0) → (0.0,0.0)\n(3.141592653589793,100000.0) → (53.1415926535898,99975.0)\n\n\nLet’s make a slightly more interesting displacement field with four vectors - one at each corner. Our image will be:\n----------------\n|[1, 1]  [2, 2]|\n|[3, 3]  [4, 4]|\n----------------\ni.e. the vector at position (0,1) is \\([3,3]\\).\nOur data needs to be 3D, where the first dimension holds the two vector components, and the other two hold the spatial dimensions. We can use an ArrayImg to store these data.\n\nvar dfieldData = ArrayImgs.doubles(\n        new double[]{1, 1, 2, 2, 3, 3, 4, 4}, // the data\n        2, 2, 2);  // the dimensions\n\n// the displacement field\nvar dfieldCorners = new DisplacementFieldTransform(dfieldData);\n\nFor example, we expect the transformation to take the point \\([0,1]\\) to \\([3,4] = [0,1] + [3,3]\\), and that is indeed what we see:\n\n// [0,0] is transformed to [1,1] = [0,0] + [1,1]\nvar x = new RealPoint(0.0, 0.0);\nvar y = new RealPoint(2);\ndfieldCorners.apply(x, y);\nprintTformPts(x, y);\n\n// [1,0] is transformed to [3,2] = [1,0] + [2,2]\nvar x = new RealPoint(1.0, 0.0);\ndfieldCorners.apply(x, y);\nprintTformPts(x, y);\n\n// [0,1] is transformed to [3,4] = [0,1] + [3,3]\nvar x = new RealPoint(0.0, 1.0);\ndfieldCorners.apply(x, y);\nprintTformPts(x, y);\n\n// [1,1] is transformed to [5,5] = [1,1] + [4,4]\nvar x = new RealPoint(1.0, 1.0);\ndfieldCorners.apply(x, y);\nprintTformPts(x, y);\n\n(0.0,0.0) → (1.0,1.0)\n(1.0,0.0) → (3.0,2.0)\n(0.0,1.0) → (3.0,4.0)\n(1.0,1.0) → (5.0,5.0)\n\n\nWhat happens if we try to apply the transformation “in between” the discrete values of the array, or out-of-bounds of the array?\n\n// [0.5, 0.5] is transformed to [3.0, 3.0]\nvar x = new RealPoint(0.5, 0.5);\nvar y = new RealPoint(2);\ndfieldCorners.apply(x, y);\nprintTformPts(x, y);\n\n// [-100, -100] is transformed to [-99.0,-99.0]\nvar x = new RealPoint(-100, -100);\ndfieldCorners.apply(x, y);\nprintTformPts(x, y);\n\n(0.5,0.5) → (3.0,3.0)\n(-100.0,-100.0) → (-99.0,-99.0)\n\n\nBy default, linear interpolation determines the displacement within the array but off of grid values. The nearest value on the border of the array determines the displacement outside the array’s bounds. If, instead, we want nearest-neighbor interpolation and all out-of-bounds displacements to be zero, it can be acheived by:\n\n// interpret our 3d image as a 2d image of vectors\nvar vectorsFrom3D = Views.collapseReal(Views.moveAxis(dfieldData, 0, dfieldData.numDimensions() - 1));\n\n// make the displacement field with custom interpolation and boundary extension\nvar dfieldCornersCustom = new DisplacementFieldTransform(\n        Views.interpolate(\n                Views.extendZero(vectorsFrom3D),            // zeros out-of-bounds\n                new NearestNeighborInterpolatorFactory())); // nearest-neighbor interpolation\n\n// [0.4, 0.4] is transformed to [1.4, 1.4]\nvar x = new RealPoint(0.4, 0.4);\nvar y = new RealPoint(2);\ndfieldCornersCustom.apply(x, y);\nprintTformPts(x, y);\n\n// [-100, -100] is transformed to [-100, -100]\nvar x = new RealPoint(-100, -100);\ndfieldCornersCustom.apply(x, y);\nprintTformPts(x, y);\n\n(0.4,0.4) → (1.4,1.4)\n(-100.0,-100.0) → (-100.0,-100.0)\n\n\nAnother common requirement is to specify the spacing and offset of the displacement field’s discrete grid. For example, suppose we want the displacements above to be applied to the field of view \\([-10, 10] \\times [-20, 20]\\) rather than the array coordinates \\([0, 1] \\times [0, 1]\\).\n(-10,-20)  ------------------------------------------------  (10,-20)\n           |[1,1]                                    [2,2]|\n           |                                              |                                          \n           |                                              |\n           |                                              |\n           |            (interpolated values)             |\n           |                                              |\n           |                                              |\n           |                                              |\n           |[3,3]                                    [4,4]|\n(-10, 20)  ------------------------------------------------ (10,20)               \nwhere the values outside the box in parenthesis are the coordinates of the corners.\nThis is possible by passing the desired spacing and offset directly to the DisplacementFieldTransform.\n\n/*\n * the spacing and offset below map the array origin [0,0] to [-10,-20]\n * and the element at array index [1,1] to [10,20]\n */\nvar spacing = new double[]{20, 40};\nvar offset = new double[]{-10, -20};\nvar dfieldCornersSpacingOffset = new DisplacementFieldTransform(dfieldData, spacing, offset);\n\n// [-10,-20] is displaced by the vector [1,1], so goes to [-9,-19]\nvar x = new RealPoint(-10, -20);\nvar y = new RealPoint(2);\ndfieldCornersSpacingOffset.apply(x, y);\nprintTformPts(x, y);\n\n// similarly, [10,20] is displaced by the vector [4,4], so goes to [14,24]\nvar x = new RealPoint(10, 20);\ndfieldCornersSpacingOffset.apply(x, y);\nprintTformPts(x, y);\n\n(-10.0,-20.0) → (-9.0,-19.0)\n(10.0,20.0) → (14.0,24.0)\n\n\n\n\nTransforming images\nDisplacement fields can also be applied to images. First, let’s open an image:\n\nvar img = ImageJFunctions.wrap(IJ.openImage(\"https://mirror.imagej.net/ij/images/boats.gif\"));\nimg\n\n\n\n\n\n\n\n\nNow let’s transform it using our constant valued displacement field. Remember this field has the vector \\([50, -25]\\) everwhere.\nFirst, we’ll define two functions for transforming images:\n\n/*\n * Transform an image of arbitrary size (RandomAccessible) and output an image of size\n * given by resultInterval.\n */ \npublic RandomAccessibleInterval transformImageInterval(\n        RandomAccessible img,\n        RealTransform transform,\n        Interval resultInterval) {\n    \n    // use n-linear interpolation\n    var interpImg = Views.interpolate(img, new NLinearInterpolatorFactory());\n\n    // transform the image\n    var transformedImg = new RealTransformRandomAccessible(interpImg, transform);\n\n    // rasterize and set bounding box\n    return Views.interval(Views.raster(transformedImg), resultInterval);\n}\n\npublic RandomAccessibleInterval transformImage(RandomAccessibleInterval img, RealTransform transform) {\n    \n    // default out-of-bounds extension and output interval\n    return transformImageInterval(Views.extendZero(img), transform, img);\n}\n\ntransformImage(img, dfieldConstant);\n\n\n\n\n\n\n\n\nNotice that the image is shifted down (+y direction) and to the left (-x direction) : the opposite direction of the displacement vector. This is because the “inverse” transformation (from output coordinates to input coordinates) is needed to transform images. Learn why here.\nNow let’s use what we learned above to make a displacement field whose corners are the corners of the image. We do this by setting the spacing of the displacement field’s coordinate grid as we learned above. This means displacement vector stored at at the array coordinate [1,1] to a new position: [imageWidth, imageHeight].\n\n// some vector field\nvar dfieldData = ArrayImgs.doubles( \n        new double[]{-45, -50, 35, -35, -25, 25, 70, 75},  // the vector data\n        2, 2, 2); // the dimensions\n    \n// use the image width and height as the vector fields spacing\nvar dfield = new DisplacementFieldTransform(\n        dfieldData, \n        img.dimension(0),\n        img.dimension(1));\n\n// transform the image\ntransformImage(img, dfield);\n\n\n\n\n\n\n\n\nFinally, let’s make a field of random displacements at one-tenth the resolution of the image and apply it.\n\n// create image of random vectors\nvar randDfieldData = ArrayImgs.doubles(2, (img.dimension(0) / 20), (img.dimension(1) / 20));\nrandDfieldData.forEach(x -&gt; {x.set(15 * (Math.random() - 0.5));});\n    \n// spacing of 20\nvar dfield = new DisplacementFieldTransform(randDfieldData, 20, 20);\n\n// transform the image\ntransformImage(img, dfield);\n\n\n\n\n\n\n\n\n\n\nPosition fields\nA position, or coordinate field is similar to a displacement field in that it is also represented by a field of vectors, but those vectors represent positions directly, rather than displacements of the current position.\n\\[\n\\begin{align}\n\\mathbf{x} &: \\text{a position } \\\\\n\\mathbf{v}( \\mathbf{x} ) &: \\text{the vector at position } \\mathbf{x}\\\\\n\\mathbf{v}( \\mathbf{x} ) &: \\text{the output of the transformation}\n\\end{align}\n\\]\nIf we use a constant vector field to make a PositionFieldTransform the output will always be the same:\n\nvar coordinateVector = new double[]{1, 2};\nvar constantVector = new FunctionRealRandomAccessible&lt;&gt;(\n        2,\n        (x, v) -&gt; {v.setPosition( coordinateVector );},  // set the vector \n        () -&gt; {return DoubleType.createVector(2);});     // make a 2d vector\n\nvar pfieldConstant = new PositionFieldTransform(constantVector);\n\n// [0, 0] is transformed to [1, 2]\nvar x = new RealPoint(0, 0);\nvar y = new RealPoint(2);\npfieldConstant.apply(x, y);\nprintTformPts(x, y);\n\n// [9999, 9999] is also transformed to [1, 2]\nvar x = new RealPoint(9999, 9999);\nvar y = new RealPoint(2);\npfieldConstant.apply(x, y);\nprintTformPts(x, y);\n\n(0.0,0.0) → (1.0,2.0)\n(9999.0,9999.0) → (1.0,2.0)\n\n\nThe Localizables class has some convenience methods for producing images of coordinates. Creating a position field with this image gives the identity. FunctionRandomAccessibles can also be used to generate coordinate images.\nChallenge: Try using Converters to extract the x and y coordinates from the coordinates variable.\n\n// make an image of coordinates. The argument \"2\" specifies the number of dimensions.\nvar coordinates = Localizables.realRandomAccessible(2);\n\n// make an image whose intensities are the x coordinate\nvar xCoordinates = Views.interval(\n        new FunctionRandomAccessible&lt;&gt;(\n                2,\n                (x, v) -&gt; {v.set(x.getIntPosition(0));}, \n                UnsignedByteType::new),\n        new FinalInterval(255, 255));\n\n// make an image whose intensities are the x coordinate\nvar yCoordinates = Views.interval(\n        new FunctionRandomAccessible&lt;&gt;(\n                2,\n                (x, v) -&gt; {v.set(x.getIntPosition(1));}, \n                UnsignedByteType::new),\n        new FinalInterval(255, 255));\n\ndisplay(\"x coordinates\");\ndisplay(xCoordinates );\ndisplay(\" \");\n\ndisplay(\"y coordinates\");\nyCoordinates\n\nx coordinates\n\n\n\n\n\n\n\n\n\n \n\n\ny coordinates\n\n\n\n\n\n\n\n\n\n\n// the identity transformation\nvar identityPfield = new PositionFieldTransform(Localizables.realRandomAccessible(2));\n\n// [0, 0] is transformed to [0, 0]\nvar x = new RealPoint(0, 0);\nvar y = new RealPoint(2);\nidentityPfield.apply(x, y);\nprintTformPts(x, y);\n\n// [9999, 9999] is transformed to [9999, 9999]\nvar x = new RealPoint(9999, 9999);\nidentityPfield.apply(x, y);\nprintTformPts(x, y);\n\n(0.0,0.0) → (0.0,0.0)\n(9999.0,9999.0) → (9999.0,9999.0)\n\n\nFor the above examples, notice that the identityPfield does indeed behaves as the identity transformation.\nLet’s make another position field that stretches and compresses the image in a non-linear way.\n\n/*\n * The details of this vector field are not so important,\n * but notice that it is some non-linear function.\n */ \nvar pFieldVectorField = new FunctionRealRandomAccessible&lt;&gt;(\n        2,\n        (p, v) -&gt; {\n            var cx = img.dimension(0) / 2.0;\n            var cy = img.dimension(1) / 2.0;\n            var ex = Math.exp(-0.020 * (p.getDoublePosition(0) - cx));\n            var ey = Math.exp(-0.020 * (p.getDoublePosition(1) - cy));\n            v.setPosition(10 + 700 / (1 + ex), 0);\n            v.setPosition(500 / ( 1 + ey), 1);\n        },\n        () -&gt; {return DoubleType.createVector(2);});\n    \n// spacing of 10\nvar spacing = new double[]{1, 1};\nvar offset = new double[]{img.dimension(0) / 2.0, img.dimension(1) / 2.0};\nvar pfield = new PositionFieldTransform(pFieldVectorField);\n\n// transform the image\ntransformImage(img, pfield);\n\n\n\n\n\n\n\n\nPosition fields can have different input and output dimensions. The length of the vector (first) dimension of the position field indicates its output dimension. The domain of the field indicates the input dimension. So generally, an N+1 dimensional image has N-dimensional inputs since one dimension is the vector dimension. Let’s consider an example.\n\nvar randPfieldData = ArrayImgs.doubles(2, 20, 30, 40, 50); // make a 5d array\n\nvar pfieldRand = new PositionFieldTransform(randPfieldData);\nSystem.out.println(\"input dimensions:  \" + pfieldRand.numSourceDimensions());\nSystem.out.println(\"output dimensions: \" + pfieldRand.numTargetDimensions());\n\ninput dimensions:  4\noutput dimensions: 2\n\n\nMake a 1D Function and plot it:\n\n// a 1d signal\nvar sin1d = new FunctionRandomAccessible&lt;&gt;(\n        1,\n        (p, v) -&gt; {\n            double t = p.getDoublePosition(0);\n            if (t &gt; 250) v.set(64);\n            else v.setReal(150 + ((t/5) * Math.sin(t/10)));\n        },\n        UnsignedByteType::new);\n\n\n\nCode\n// plot the 1d function\nvar xpts = new double[256];\nvar ypts = new double[256];\n\nvar access = sin1d.randomAccess();\nIntStream.range(0, 256).forEach(\n        i -&gt; {\n            xpts[i] = i;\n            access.fwd(0);\n            ypts[i] = access.get().getRealDouble();\n        });\n\nvar chart = new XYChartBuilder().width(800).height(600).build();\nchart.getStyler().setChartTitleVisible(false);\nchart.getStyler().setLegendVisible(false);\nchart.getStyler().setChartTitleBoxBackgroundColor(java.awt.Color.white);\nchart.getStyler().setChartBackgroundColor(java.awt.Color.white);\n\nvar series = chart.addSeries(\"function\", xpts, ypts);\nseries.setMarker(SeriesMarkers.NONE);\nBitmapEncoder.getBufferedImage(chart)\n\n\n\n\n\n\n\n\n\n\n/* \n * Create the position field (1D -&gt; 2D)\n *\n * The details of this vector field are not so important,\n * but notice:\n *    1) it is some non-linear function.\n *    2) its input p is a 2D; notice \"p.getDoublePosition(i)\"\n *    3) its output v is 1D (scalar)\n */ \nvar pFieldTransition = new PositionFieldTransform( \n    new FunctionRealRandomAccessible&lt;&gt;(\n            2, \n            (p, v) -&gt; {\n                double x = p.getDoublePosition(0) - 300;\n                double y = p.getDoublePosition(1) - 300;\n                double r = Math.sqrt(x*x + y*y);\n                double tht = Math.atan2(x, y);\n                v.setPosition(1.2 * r +  32 * tht, 0); \n            },\n            () -&gt; {return DoubleType.createVector(1);})\n);\n\n// transform the 1D signal, make a 2D image of size 512 x 512\ntransformImageInterval(sin1d, pFieldTransition, new FinalInterval(512, 512));"
  },
  {
    "objectID": "blog.html",
    "href": "blog.html",
    "title": "Blog",
    "section": "",
    "text": "N5 attribute paths\n\n\n\n\n\n\nn5\n\n\nattributes\n\n\nmetadata\n\n\ntutorial\n\n\n\nLearn to get and set arbitrary parts of an attribute hierarchy with the N5 API.\n\n\n\n\n\nApr 2, 2024\n\n\nJohn Bogovic, Caleb Hulbert\n\n\n\n\n\n\n\n\n\n\n\n\nN5 API Basics\n\n\n\n\n\n\nhdf5\n\n\nn5\n\n\nzarr\n\n\nimglib2\n\n\ntutorial\n\n\n\nBasics of the N5 API for Java developers. This tutorial shows how to read and write n-dimensional image data and structured metadata into HDF5, N5, and Zarr containers using the N5 API.\n\n\n\n\n\nFeb 27, 2024\n\n\nJohn Bogovic, Caleb Hulbert\n\n\n\n\n\n\n\n\n\n\n\n\nPosition and displacement field transformations\n\n\n\n\n\n\nimglib2\n\n\ntransform\n\n\ndeformation\n\n\ndisplacement\n\n\n\nCreate and apply non-linear transformations with ImgLib2.\n\n\n\n\n\nFeb 14, 2024\n\n\nJohn Bogovic\n\n\n\n\n\n\n\n\n\n\n\n\nHow to add your project to the Ecosystem page\n\n\n\n\n\n\nquarto\n\n\nweb\n\n\n\n\n\n\n\n\n\nDec 21, 2023\n\n\nNils Norlin\n\n\n\n\n\n\n\n\n\n\n\n\nAdding Stream support to ImgLib2\n\n\n\n\n\n\nimglib2\n\n\nstream-api\n\n\njava\n\n\n\n\n\n\n\n\n\nOct 30, 2022\n\n\nTobias Pietzsch\n\n\n\n\n\n\n\n\n\n\n\n\nHow to work with the N5 API and ImgLib2?\n\n\n\n\n\n\nimglib2\n\n\njava\n\n\nn5\n\n\nhdf5\n\n\nzarr\n\n\njupyter\n\n\nnotebook\n\n\n\nRead and write ImgLib2 data with the N5 API.\n\n\n\n\n\nSep 27, 2022\n\n\nStephan Saalfeld\n\n\n\n\n\n\n\n\n\n\n\n\nHow to display ImgLib2 data in a notebook\n\n\n\n\n\n\nimglib2\n\n\njupyter\n\n\nnotebook\n\n\n\n\n\n\n\n\n\nSep 14, 2022\n\n\nStephan Saalfeld\n\n\n\n\n\n\n\n\n\n\n\n\nUser-configurable Keymaps\n\n\n\n\n\n\nui-behaviour\n\n\nbigdataviewer\n\n\n\n\n\n\n\n\n\nAug 8, 2022\n\n\nTobias Pietzsch\n\n\n\n\n\n\n\n\n\n\n\n\nSetup the IJava jupyter kernel\n\n\n\n\n\n\njupyter\n\n\nijava\n\n\njshell\n\n\njava\n\n\nkernel\n\n\n\nFollow these instructions to setup the IJava jupyter kernel by Spencer Park.\n\n\n\n\n\nJun 5, 2022\n\n\nStephan Saalfeld\n\n\n\n\n\n\n\n\n\n\n\n\nJuliaset Lambda\n\n\n\n\n\n\nimglib2\n\n\nlambda\n\n\nfractal\n\n\njuliaset\n\n\nbigdataviewer\n\n\n\nInteractively render the Juliaset as a lambda function in BigDataViewer.\n\n\n\n\n\nMay 2, 2022\n\n\nStephan Saalfeld\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "imglib2/loopbuilder.html",
    "href": "imglib2/loopbuilder.html",
    "title": "LoopBuilder",
    "section": "",
    "text": "LoopBuilder is part of ImgLib2. It provides a very simple way to implement a pixel wise operation. LoopBuilder can operate on one, two, three, … up to six images. Simplest case is an operation on one image. LoopBuilder will perform the given operation for every pixel of the image.\nExample: Multiply every pixel by a factor of two 2.\nSlightly more complex is the case with two images. LoopBuilder will iterate simultaneously over both given images. The given operation is executed for each pair of corresponding pixels. “Corresponding” means that the pixels are at the same location in both images. Lets use this to copy the content of image. The value of the source pixel must be copied to the corresponding target pixel:\nIt’s the same story for three images. LoopBuilder iterates simultaneously over the three images. The operation is executed each triplet of corresponding pixel. This can be used, for example, to add two images.\nOr for a pixel wise comparison of two images:\nFor LoopBuilder images must be RandomAccessibleIntervals. All images must have the same size / dimensions.\nLoopBuilder works for for 1D, 2D, 3D, 4D and any other number of dimensions. There is no restriction on pixel types, any pixel typs are supported.\n(Img, ArrayImg, PlanarImg, etc. work as well because the implement the RandomAccessibleInterval interface.)",
    "crumbs": [
      "LoopBuilder"
    ]
  },
  {
    "objectID": "imglib2/loopbuilder.html#tips",
    "href": "imglib2/loopbuilder.html#tips",
    "title": "LoopBuilder",
    "section": "Tips",
    "text": "Tips\n\nCoordinates\nLoopBuilder, does not provide a direct way to access the position or coordinates of a pixel in an image. What you can do instead is use Intervals.positions(...). This will return an image where the pixel values are the positions of the pixel itself. Here is an example:\nLoopBuilder.setImages(Intervals.positions(image), image).forEachPixel(\n    (position, pixel) -&gt; {\n        long x = position.getLongPosition(0);\n        long y = position.getLongPosition(1);\n        pixel.setRealDoubel(2 * x * x + 4 * y * y);\n    }\n);\n\n\nFlat Iteration Order\nIn most cases, LoopBuilder will use flat iteration order. Hence the image is processed line by line, slice by slice, frame by frame… . But that’s not guarantied. For example, if all images are CellImg with matching cell sizes, than LoopBuilder will use better suited iteration order. So if your code depends on the flat iteration order, specify .flatIterationOrder() like in the following example. Don’t use multi-threading, as for multi threading iteration order is unspecified.\nint[] counter = { 0 };\nLoopBuilder.setImages(image).flatIterationOrder().forEachPixel(\n    pixel -&gt;  pixel.setInteger(counter[0]++)\n);\n\n\nMore Than 6 Images\nLoopBuilder only works with up to six images. This is not because any technical reason, but because the code would become rather clunky. When you have many images, changes are high, that some of the images are similar. These images have the same pixel type, and somehow belong together.\nLets look at an example again. Let’s calculate the maximum over 8 images. That are to many images for LoopBuilder. But we can combine the 8 images, using Views.collapse(Views.stack(...)). This will fuse the images into one image, where each pixel is a vector of size 8. The vector contains all the pixel values of the 8 corresponding pixels.\n// ... Initialize all images ...\n\n// Combine image1, ..., image8 into a combined image, where each pixel is a vector.\nRandomAccessibleInterval&lt; ? extends GenericComposite&lt; FloatType &gt; &gt; combined =\n    Views.collapse( Views.stack( image1, image2, image3, image4, image5, image6, image7, image8 ) );\n\nLoopBuilder.setImages( combined, resultImage ).forEachPixel( (vector, r) -&gt; {\n    float max = Float.NEGATIVE_INFINITY;\n    for ( int i = 0; i &lt; 8; i++ )\n    {\n        max = Math.max( max, vector.get(i).getRealFloat() );\n    }\n    r.setReal( max );\n} );",
    "crumbs": [
      "LoopBuilder"
    ]
  },
  {
    "objectID": "imglib2/loopbuilder.html#alternatives",
    "href": "imglib2/loopbuilder.html#alternatives",
    "title": "LoopBuilder",
    "section": "Alternatives",
    "text": "Alternatives\nLoopBuilder provides nothing, that is otherwise impossible to achieve. It is just a nice way, to write otherwise complex loops. But you could achieve the same results with ImgLib2 Cursor or RandomAccess. Lets add two images using Cursor:\nCursor&lt;FloatType&gt; cursorA = Views.flatIterable(imageA).cursor();\nCursor&lt;FloatType&gt; cursorB = Views.flatIterable(imageB).cursor();\nCursor&lt;FloatType&gt; cursorSum = Views.flatIterable(imageSum).cursor();\nwhile(sourceCursor.hasNext()) {\n    FloatType a = cursorA.next();\n    FloatType b = cursorB.next();\n    FloatType s = cursorS.next();\n    s.setReal(a.getRealFloat() + b.getRealFloat());\n}\nThe example above is actually still quite simple. And a Cursor is fast for basic image containers like ArrayImg, PlanarImg and sometimes CellImg. But it’s faster to use RandomAccess when you use views like View.extendBorder(...), Views.interval(...), Views.rotate(...) etc. Writing a loop that uses no Cursors at all is much harder. Here is an example that sets all pixels of an image to 1.\nRandomAccess&lt; IntType &gt; ra = image.randomAccess();\nra.setPosition( image.min( 2 ), 2 );\nfor ( long z = image.min( 2 ); z &lt;= image.max( 2 ); z++ )\n{\n    ra.setPosition( image.min( 1 ), 1 );\n    for ( long y = image.min( 1 ); y &lt;= image.max( 1 ); y++ )\n    {\n        ra.setPosition( image.min( 0 ), 0 );\n        for ( long x = image.min( 0 ); x &lt;= image.max( 0 ); x++ )\n        {\n            IntType pixel = ra.get();\n            pixel.setInteger( 1 );\n            ra.fwd( 0 );\n        }\n        ra.fwd( 1 );\n    }\n    ra.fwd( 2 );\n}",
    "crumbs": [
      "LoopBuilder"
    ]
  },
  {
    "objectID": "imglib2/loopbuilder.html#multi-threading",
    "href": "imglib2/loopbuilder.html#multi-threading",
    "title": "LoopBuilder",
    "section": "Multi Threading",
    "text": "Multi Threading\nIf your images are big, than multithreading might speed up the operation. And it’s super easy if you use LoopBuilder. Let’s calculate the sum using multiple threads. The only thing you need to do is write .multiThreaded() before the call to forEachPixel(...).\n// calculate sum, using multiple threads:\nLoopBuilder.setImages(imageA, imageB, imageS).multiThreaded().forEachPixel(\n                                              ///////////////\n    (pixelA, pixelB, pixelS) -&gt; {\n        pixelS.set(pixelA.getRealFloat() + pixelB.getRealFloat());\n    }\n);\nThis should run about four times faster, on a CPU with four CPU cores. (Your image needs two be big enough.) What LoopBuilder internally does, is the following: It splits the images into chunks, and the chunks are than distributed to a pool of threads.\nBut be careful, multi-threading works well as long as your operation is thread-safe. This is the case for simple operations like “pixelS = pixelA + pixelB”. An per pixel operation is NOT thread-safe if it changes a object, field or variable outside the of operation. Let’s take a look at the following example: It calculates the sum over the squared pixel values:\nFloatType squareSum = new FloatType(0);\nLoopBuilder.setImages(image).forEachPixel(\n   pixel -&gt; {\n      squaredSum.setReal(squaredSum.getRealFloat() + Math.pow(pixel.getRealFloat, 2));\n   }\n)\nHere the per pixel operation (line 3-5) changes the squaredSum, which is defined in line 1, outside of the per pixel operation. Only adding .multiThreaded() will cause wrong results. This is because the operation is simultaniously executed by mutliple threads. All the threads simultaniously changing the squaredSum causes chaos. The wrong result is the consequence.\nLuckily LoopBuilder provides a solution to this problem. LoopBuilder devides the image into chunks, and destributes the chunks to a pool of threads. A chunk is always only processed by one thread. That’s why there are no multi-threading problems as long as we have one squaredSum variable per chunk. This can be done using LoopBuilders .forEachChunk(...) method:\n// For each chunk calculate an individual squared sum.\nList&lt;FloatType&gt; listOfSquaredSums = LoopBuilder.setImages(image).multithreaded().forEachChunk( chunk -&gt; {\n   FloatType squaredSum = new FloatType(0);\n   chunk.forEachPixel( pixel -&gt; {\n      squaredSum.setReal(squaredSum.getRealFloat() + Math.pow(pixel.getRealFloat, 2));    \n   } );\n   return squaredSum;\n})\n\n// Calculate the sum about all the individual squared sums.\nFloatType totalSquaredSum = new FloatType(0);\nfor(FloatType squareSum : listOfSquaredSums) {\n   totalSquaredSum.add(squaredSum);\n}\nIn the example above the per pixel operation (in line 5) can access variables and objects that belong to the chunk (in line 3 - 7) without causing any thread safety issues.\nAnother use case for the forEachChunk mappens, happens if your per pixel operation needs some resources. The following examples swaps the content of two images A and B. The temporary variable tmp is used to swap the pixel value. But creating a new FloatType() for each pixel would be very slow, but creating one temporary variable per chunk, is fine:\nLoopBuilder.setImages(imageA, imageB).multiThreaded().forEachChunk( chunk -&gt; {\n    FloatType tmp = new FloatType(); // create require resource\n    chunk.forEach((a, b) -&gt; {\n        tmp.set(a);   // operation using the resource\n        a.set(b);\n        b.set(tmp);\n    });\n    // Optional: free your resource if needed.\n    return null; // Optional: return some results.\n})\nDisclaimer: Please always measure the execution time if you use multi-threading. Sometimes the simgle threaded code is better optimized by the compiler and runs even faster than the multi-threaded code. Also check that you don’t have thread-safety issues, make sure your results are correct. Thread-safety problem are hard to debug!",
    "crumbs": [
      "LoopBuilder"
    ]
  },
  {
    "objectID": "imglib2/loopbuilder.html#performance",
    "href": "imglib2/loopbuilder.html#performance",
    "title": "LoopBuilder",
    "section": "Performance",
    "text": "Performance\nDisclaimer: LoopBuilder achieves good perfomance in Java, but it is slow when used in scripting languages like Groovy or Jython. (This is because LoopBuilder relies on Lambda expression, and using them in scripting languages is rather complicated and slow.)\nLoopBuilder has been heavily benchmarked and designed to give good perfance. This performance advantage compared to for example Cursor loops is most noticible for methods that are used with different image types (For example ArrayImg, PlanarImg, Views.interval(...), etc. ). Because LoopBuilder will execute the loop in a way, that promises good performance for the particular image type. The strategies that are used to provide the best performance are discribed below.\nStill, if you write a piece of very specialized code that always runs on only one image type (maybe ArrayImg). Then writing your own loop using Cursor or RandomAccess might give better performance. But always carefully measure the execution time.\nBenchmark comparing LoopBuilder and Cursor\n\nCursor vs. RandomAccess\nLoopBuilder either uses a loop that uses Cursors. That’s the case if all the images have fast Cursors like ArrayImg, PlanarImg, CellImg and for slices of ArrayImg. But in all other cases RandomAccesses are used. The RandomAccess are moved simultaneously along the image. The methods RandomAccess.fwd(int d) and RandomAccess.move(long offset, int d) are used, which happens to be faster than setPosition(long[] pos).\n\n\nIteration Order\nUsually flat iteration order is used. Currently the only exception happens, when all images are ‘CellImg’ of matching cell size. Than the CellImg specific iteration order will be used.\n\n\nByte Code Copying for JIT-Optimization\nThe loops that are used for image processing are usually very tight. (A few number of operations per cycle) The performance of these tight loops heavily depends on the byte-code optimizations done by Java’s just-in-time-compiler. Sadly the JIT-compiler de-optimizes byte-code that is used with different implementations of the same interface.\nHence writing a loop that performs a simple image processing step, like adding two images, will runs very fast only if used with ArrayImg. But using it with ArrayImg, CellImg and IntervalView will cause the byte-code to be de-optimized and to dramatically reduce performance.\nLoopBuilder circumvents this problem, by loading a new copy of the class running the loop, for every new combination of images (ArrayImgs, CellImgs, etc.) Each copy of the class, has a it’s own copy of the byte-code. And these individual copies of the byte-code are individually optimized byte the JIT-compiler to the particular image classes used. Hence avoiding the de-optimization.",
    "crumbs": [
      "LoopBuilder"
    ]
  },
  {
    "objectID": "imglib2/index.html",
    "href": "imglib2/index.html",
    "title": "ImgLib2",
    "section": "",
    "text": "ImgLib2 is a general-purpose, multidimensional image and data processing library.\nIt provides a unified API to work with discrete and continuous n-dimensional data. This API is interface driven and therefore extensible at will.\nImgLib2 includes implementations of standard numeric and non-numeric data types (8-bit unsigned integer, 32-bit floating point, …) as well as a number of less typical data types (complex 64-bit floating point, 64-bit ARGB, base pairs, …). Data values can be accessed directly or through on-the-fly converters or multi-variate functions.\nFor discrete data (images, n-dimensional arrays), ImgLib2 implements a variety of memory layouts, data generation, loading, and caching strategies, including data linearized into single primitive arrays, series of arrays, n-dimensional arrays of arrays (“cells”), stored in memory, generated or loaded from disk on demand, and cached in memory or on disk. Coordinates and values can be accessed directly or through on-the-fly views that invert or permute axes, generate hyperslices or stack slices top higher dimensional datasets, collapse dimensions into vectors\nFor continuous data (functions, n-dimensional interpolants), ImgLib2 implements a variety of interpolators, geometric transformations, and generator functions. Coordinates and values can be accessed directly or transformed on-the-fly.\nNeed a quick start? Install OpenJDK and maven:\nThen check out BigDataViewer vistools:\nThen start JShell in the BigDataViewer vistools project directory:\nThen try out this code snippet:",
    "crumbs": [
      "ImgLib2"
    ]
  },
  {
    "objectID": "imglib2/index.html#resources",
    "href": "imglib2/index.html#resources",
    "title": "ImgLib2",
    "section": "Resources",
    "text": "Resources\n\nImgLib2 paper\nImgLib2 Documentation\nImgLib2 Examples\nImgLib2 Blog\nImage.sc forum\n{% include javadoc project=‘ImgLib2’ %} javadoc\nHow To Migrate Code From ImgLib To ImgLib2\n“Introduction to ImgLib2” workshop\n“Advanced Programming with ImgLib2” workshop\n“I2K 2020 Introductory ImgLib2” workshop\n“I2K 2020 Advanced ImgLib2” workshop",
    "crumbs": [
      "ImgLib2"
    ]
  },
  {
    "objectID": "imglib2/index.html#source-code",
    "href": "imglib2/index.html#source-code",
    "title": "ImgLib2",
    "section": "Source code",
    "text": "Source code\nYou can find the source {% include github org=‘imglib’ repo=‘imglib2’ %}.\nThere is also a continuous integration system that builds ImgLib2 every time the code changes.",
    "crumbs": [
      "ImgLib2"
    ]
  },
  {
    "objectID": "imglib2/index.html#imglib2-vs.-imglib1",
    "href": "imglib2/index.html#imglib2-vs.-imglib1",
    "title": "ImgLib2",
    "section": "ImgLib2 vs. ImgLib1",
    "text": "ImgLib2 vs. ImgLib1\nImgLib1 is the previous incarnation of the library. We encourage developers to use ImgLib2 instead, and migrate existing ImgLib1 programs to ImgLib2 whenever possible.\nFor an explanation of how ImgLib2 has changed from ImgLib1, see the Changes from ImgLib1 to ImgLib2 page.\nSee the How To Migrate Code From ImgLib To ImgLib2 page for details on how to update your ImgLib1-based code to use ImgLib2.",
    "crumbs": [
      "ImgLib2"
    ]
  },
  {
    "objectID": "imglib2/index.html#api-version-history",
    "href": "imglib2/index.html#api-version-history",
    "title": "ImgLib2",
    "section": "API Version History",
    "text": "API Version History\nA history of API changes is available at: https://abi-laboratory.pro/java/tracker/timeline/imglib2/",
    "crumbs": [
      "ImgLib2"
    ]
  },
  {
    "objectID": "imglib2/index.html#other-links",
    "href": "imglib2/index.html#other-links",
    "title": "ImgLib2",
    "section": "Other links",
    "text": "Other links\n\nImgLib2 development discussion\nImgLib2 performance benchmarks\nImageJ2 uses ImgLib2 as its core data model",
    "crumbs": [
      "ImgLib2"
    ]
  },
  {
    "objectID": "imglib2/index.html#publication",
    "href": "imglib2/index.html#publication",
    "title": "ImgLib2",
    "section": "Publication",
    "text": "Publication\nPietzsch, T., Preibisch, S., Tomančák, P., & Saalfeld, S. (2012). ImgLib2—generic image processing in Java. Bioinformatics, 28(22), 3009-3011.",
    "crumbs": [
      "ImgLib2"
    ]
  },
  {
    "objectID": "imglib2/morphological-operations.html",
    "href": "imglib2/morphological-operations.html",
    "title": "ImgLib2 Morphological Operations",
    "section": "",
    "text": "This page describes the {% include wikipedia title=‘Mathematical morphology’ text=‘mathematical morphology’ %} operations available as part of the ImgLib2 library.",
    "crumbs": [
      "ImgLib2 Morphological Operations"
    ]
  },
  {
    "objectID": "imglib2/morphological-operations.html#implementation",
    "href": "imglib2/morphological-operations.html#implementation",
    "title": "ImgLib2 Morphological Operations",
    "section": "Implementation",
    "text": "Implementation\n\nPackage content and location\nThis ImgLib2 package ships only (yet) the basic morphological operations:\n\nerosion\ndilation\nopening\nclosing\n\nThese 4 operations are implemented for arbitrary dimensionalities (2D, 3D, 4D, etc…). The package reuses standard ImgLib2 interfaces and classes. It also conforms to the public static methods accessors for low level algorithms, as the gauss3 package does. Apart from this, it is strongly inspired by the morphological operation methods in the Image Processing Toolbox of the MATLAB software.\nIt also ships facilities to generate structuring elements, and allows the use of decomposed structuring elements for performance optimization. This part is documented below.\nClasses can be found in the net.imglib2.algorithm.morphology package of the imglib2-algorithm library.\nExamples can be found in the net.imglib2.algorithm.morphology package of the imglib2-tests library.\n\n\nGray morphology and flat structuring elements\nThis set of methods does gray morphology. It applies to source images that can be of any scalar numerical type (8-bit, 12-bit, 16-bit, booleans, floats, signed or unsigned, …), not only black and white images.\nIt actually applies to more than this: The type of the source image only needs to extend Type (the ImgLib2 mother interface for values) and Comparable (the java interface for objects than can be compared to others). This is detailed later.\nHowever, we use the ImgLib2 Shape interface for structuring elements. This restricts structuring elements to flat structuring elements, which do not have a weight, or value, associated to each location. This prevents us from developing a stricto sensu rolling-ball background subtraction algorithm based on this package (but a rolling-disk version is possible).\n\n\nMorphological operations on Comparable type\nMorphological operations are defined on types that have very little requirement. The data does not have to be made of numerical pixels at all. Mathematically, they are defined on partially ordered sets (complete lattices, see for instance {% include wikipedia title=‘Dilation (morphology)#Dilation_on_complete_lattices’ text=‘“Dilation on complete lattices”’%}).\nIn ImgLib2, we require a little bit more than that. The data type you can use with morphological operations needs to be comparable. In practice, it must extends Type and Comparable: T extends Type&lt; T &gt; & Comparable&lt; T &gt;. With this, it is perfectly possible to dilate an image of strings by a 3x3 square strel:\nBefore:\nUpcycle       Sexting       Unfriend      Droolworthy   Noob          Muggle        \nWoot          Po-po         Purple State  Guyliner      Screenager    Crunk         \nObvs          Mankini       Locavore      Bling         Textspeak     Muffin Top    \nInfomania     Grrrl         Truthiness    Bromance      D'oh          Twitterati    \nLa-la Land    Whatevs       Illiterati    OMG           Hater         Jeggings      \nJean-Yves     Mini-Me       Chillax       Frankenfood   Totes         Whovian       \n\nAfter full dilation:\nUpcycle       Upcycle       Upcycle       Unfriend      Unfriend      Noob          Noob          Muggle        \nWoot          Woot          Woot          Unfriend      Unfriend      Screenager    Screenager    Muggle        \nWoot          Woot          Woot          Unfriend      Unfriend      Textspeak     Textspeak     Muggle        \nWoot          Woot          Woot          Truthiness    Truthiness    Twitterati    Twitterati    Twitterati    \nObvs          Whatevs       Whatevs       Whatevs       Truthiness    Twitterati    Twitterati    Twitterati    \nLa-la Land    Whatevs       Whatevs       Whatevs       Truthiness    Whovian       Whovian       Whovian       \nLa-la Land    Whatevs       Whatevs       Whatevs       Totes         Whovian       Whovian       Whovian       \nJean-Yves     Mini-Me       Mini-Me       Mini-Me       Totes         Whovian       Whovian       Whovian       \n\nAfter standard dilation:1\nWoot          Woot          Unfriend      Unfriend      Screenager    Screenager    \nWoot          Woot          Unfriend      Unfriend      Textspeak     Textspeak     \nWoot          Woot          Truthiness    Truthiness    Twitterati    Twitterati    \nWhatevs       Whatevs       Whatevs       Truthiness    Twitterati    Twitterati    \nWhatevs       Whatevs       Whatevs       Truthiness    Whovian       Whovian       \nWhatevs       Whatevs       Whatevs       Totes         Whovian       Whovian",
    "crumbs": [
      "ImgLib2 Morphological Operations"
    ]
  },
  {
    "objectID": "imglib2/morphological-operations.html#usage",
    "href": "imglib2/morphological-operations.html#usage",
    "title": "ImgLib2 Morphological Operations",
    "section": "Usage",
    "text": "Usage\nThe 4 basic operations are accessed through 4 classes:\n\nnet.imglib2.algorithm.morphology.Dilation\nnet.imglib2.algorithm.morphology.Erosion\nnet.imglib2.algorithm.morphology.Opening\nnet.imglib2.algorithm.morphology.Closing\n\nEach of these classes contains only static methods that performs the desired operation. There can be up to 16 flavors of the same operation. They exist to cover all cases, which fall in 4 categories:\n\nYou want to operate on an Img and return a new Img with the results. Then you need to call for instance:\nImg&lt; FloatType &gt; result = Dilation.dilate( img, strel, 1 );\n\nYou want to perform to full dilation or erosion on a source Img. Full version of these operations means the new image will have a size increased or shrunk as if the structuring element would actually dilate or erode the source border:\nImg&lt; FloatType &gt; result = Dilation.dilateFull( img, strel, 1 );\n\nYou want to operate on a source RandomAccessibleInterval, in place (write the results in the source):\nDilation.dilateInPlace( rai, interval, strel, 1 );\n\nYou want to operate on a source RandomAccessible, and write the results in a provided IterableInterval:\nDilation.dilate( source, target, strel, 1 )\n\n\nNow, each of these category are declined in 4 specifics methods:\n\nDepending on the source type:\n\nIf the source type inherits from RealType - which is the case for most numeric types and all the native types - then you can use directly the above methods without any extras.\nBut you may have a source which might be T extends Comparable & Type. Then you have to provided the maximal value or the minimal value or both for this type. Then you have to call the methods whose signature are like: public static &lt; T extends Type&lt; T &gt; & Comparable&lt; T &gt; &gt; Img&lt; T &gt; dilate( final Img&lt; T &gt; source, final Shape strel, final T minVal, final int numThreads )\n\nDepending on whether you have the structuring element as a single Shape or decomposed in a list of Shape, there is a version of all those methods for this case or the other.\n    public static &lt; T extends RealType&lt; T &gt; &gt; Img&lt; T &gt; dilate( final Img&lt; T &gt; source, final Shape strel, final int numThreads )\n    ```\nand\npublic static &lt; T extends RealType&lt; T &gt; &gt; Img&lt; T &gt; dilate( final Img&lt; T &gt; source, final List&lt; Shape &gt; strels, final int numThreads )\n```",
    "crumbs": [
      "ImgLib2 Morphological Operations"
    ]
  },
  {
    "objectID": "imglib2/morphological-operations.html#structuring-elements-and-their-decomposition",
    "href": "imglib2/morphological-operations.html#structuring-elements-and-their-decomposition",
    "title": "ImgLib2 Morphological Operations",
    "section": "Structuring elements and their decomposition",
    "text": "Structuring elements and their decomposition\nMorphological operations are basically neighborhood operations: you iterate in a neighborhood around each location of the source, and the target value at this location depends on the maximal or minimal value you meet then. So typically, the complexity of the algorithm can be written as N × n where N is the number of pixels in the source and n is the number of pixels in the neighborhood. For instance, for a square neighborhood of side l it will be N × l².\nIt turns out some structuring elements can be decomposed to achieve greater performance. For instance, looking for the maximum in a square of side l can be achieved by first looking for the maximum in an horizontal line of length l, writing the results somewhere, then looking for the maximum of the intermediate image in a vertical line of length l. The square structuring element can be decomposed in two orthogonal lines. The benefits in complexity are immediate; with the decomposition, it is now of N × 2 × l. Benefits are greater as the size of the neighborhood increases.\nSeveral structuring elements can be decomposed, sometimes depending on the dimensionality of the problem.\nIn the ImgLib2 morphology package, these decompositions are achieved through the StructuringElements class. For instance:\npublic static final List&lt; Shape &gt; diamond( final int radius, final int dimensionality, final boolean decompose )\nThis method returns a structuring element as a list of shapes, and a boolean flag determines if the returned list correspond to an optimization or not. As seen above, all operations are built to support a list of shapes as structuring element.\nThe following paragraphs document what decompositions are currently implemented for common structuring elements.\n\nRectangular structuring element\n\nDecomposition\nA rectangle can be decomposed in a series of orthogonal lines, in any dimensions, considerably diminishing the number of pixels to iterate.\n\n2D case\nIf the image has M pixels, and that the rectangle is a square of side R, then the non-optimized case should have a processing time proportional to M × R². The optimized case replace iterating over the square by iterating twice over a line of length R. Therefore its processing time should be proportional to 2 × M × R.\nThe performance improvement should therefore be equal to R / 2. A linear fit of the actual curve rather shows that the law is 0.73 × R + 0.37. This extra benefit - I don’t why it’s there.\n{% include img src=‘rectanglestrel2dperformance’ caption=‘Processing time for the dilation of a 100x100 image.’ width=370 %} {% include img src=‘rectanglestrel2dperformancecomparison’ caption=‘Processing time ratio.’ width=362 %}\n\n\n3D case\nHere the standard case takes a time proportional to M × R³, and the optimized case a time proportional to 3 × M × R. Therefore the performance ratio should be R² / 3. A fit shows that this ratio follows 0.63 × R² + 0.57 × R + 0.48.\n{% include img src=‘rectanglestrel3dperformance’ caption=‘Processing time for the dilation of a 40x40x40 image.’ width=362 %} {% include img src=‘rectanglestrel3dperformancecomparison’ caption=‘Processing time ratio.’ width=366 %}\n\n\n\n\nSquare structuring element\n\nDecomposition\nThe square is just a special case of the rectangle, implemented for convenience. It has the same decomposition principle. And similar conclusions can be reached:\n\n2D case\n{% include img src=‘squarestrel2dperformance’ caption=‘Processing time for the dilation of a 100x100 image.’ width=370 %} {% include img src=‘squarestrel2dperformancecomparison’ caption=‘Performance time ratio.’ width=366 %} {% include img src=‘squarestrel2dperformancewmatlab’ caption=‘First image zoomed to highlight MATLAB performance.’ width=366 %}\n\n\n3D case\n{% include img src=‘squarestrel3dperformance’ caption=‘Processing time for the dilation of a 49x49x49 image.’ width=362 %} {% include img src=‘squarestrel3dperformancecomparison’ caption=‘Processing time ratio.’ width=367 %} {% include img src=‘squarestrel3dperformancewmatlab’ caption=‘First image zoomed to highlight MATLAB performance.’ width=364 %}\n\n\n\n\nDiamond structuring element\n\nShape\nA diamond strel has the following shape in 2D, for instance with a radius of 3 (It extends over 7 pixels wide):\n┌───────┐\n│   █   │\n│  ███  │\n│ █████ │\n│███████│\n│ █████ │\n│  ███  │\n│   █   │\n└───────┘\nAnd in 3D:\nZ = 0:    Z = 1:    Z = 2:    Z = 3:    Z = 4:    Z = 5:    Z = 6:    \n┌───────┐ ┌───────┐ ┌───────┐ ┌───────┐ ┌───────┐ ┌───────┐ ┌───────┐ \n│       │ │       │ │       │ │   █   │ │       │ │       │ │       │ \n│       │ │       │ │   █   │ │  ███  │ │   █   │ │       │ │       │ \n│       │ │   █   │ │  ███  │ │ █████ │ │  ███  │ │   █   │ │       │ \n│   █   │ │  ███  │ │ █████ │ │███████│ │ █████ │ │  ███  │ │   █   │ \n│       │ │   █   │ │  ███  │ │ █████ │ │  ███  │ │   █   │ │       │ \n│       │ │       │ │   █   │ │  ███  │ │   █   │ │       │ │       │ \n│       │ │       │ │       │ │   █   │ │       │ │       │ │       │ \n└───────┘ └───────┘ └───────┘ └───────┘ └───────┘ └───────┘ └───────┘ \nIt is the crudest approximation of a sphere.\n\n\nDecomposition\nThe diamond strel can be effectively decomposed in 2D (and 1D) using the logarithmic decomposition in extreme sets, as explained in [^2]. The shape is then decomposed in a minimal series of smaller diamond and diamond tips. The decomposition is exact, giving the same result that of the non-decomposed version.\nIn 3D and higher dimensionalities, the logarithmic decomposition cannot be done, and we rely on a more classical linear decomposition (also well explained in [^2]). Here is a comparison on how the decomposed version performs versus the non-decomposed one.\n\n2D performance\n{% include img src=‘diamondstrel2dperformance’ caption=‘Processing time for the dilation of a 100x100 image.’ width=366 %} {% include img src=‘diamondstrel2dperformancecomparison’ caption=‘Processing time ratio.’ width=362 %}\nIt is worth using a decomposition above a radius of 4.\n\n\n3D performance\n{% include img src=‘diamondstrel3dperformance’ caption=‘Processing time for the dilation of a 40x40x40 image.’ width=364 %} {% include img src=‘diamondstrel3dperformancecomparison’ caption=‘Processing time ratio.’ width=364 %}\nIt is worth using a decomposition in almost any cases.\n\n\nComparison with MATLAB\nMATLAB comes with a very nice morphology package. I actually took inspiration from to it to write the ImgLib2 code. It is tempting to compare the performance of MATLAB vs ImgLib2, even if this kind of comparison is always tricky and clumsy. Anyway, here it is. I just timed the duration required to perform the dilation of a provided source image, including the time required to generate the structuring element. ImgLib2 tests above time the same process. But of course, the time required to generate the source image and to start MATLAB or to launch the Java tests are not included. I took care to include a ‘warm-up’ run to allow the JIT compiler to kick-in in all cases.\n{% include img src=‘diamondstrel2dperformancewmatlab’ caption=‘Processing time for the dilation of a 100x100 image.’ width=366 %} {% include img src=‘diamondstrel3dperformancewmatlab’ caption=‘Processing time for the dilation of a 40x40x40 image.’ width=364 %}\nFor the 2D case (only), MATLAB offers to generate optimized structuring elements, like for this ImgLib2 code. This is why there is two MATLAB curves on the 2D graph. We can see that in all cases, the MATLAB code is faster than the ImgLib2 code (respective to optimized vs optimized and the converse). This may be explained by the fact that MATLAB benefits on my computer (a 2012 MacPro) from the Intel Integrated Performance Primitives (IPP), that strongly improves block processing algorithms. Fortunately, the difference is not too taxing in the optimized case.\nIn 3D, MATLAB does not offer a structuring element decomposition (yet). So the performance curve as the expected cubic shape, though it outperforms ImgLib2 in the non-optimized case. For large radius, the ImgLib2 optimization manages to beat it.\n\n\n\n\nDisk structuring element\n\n2D Decomposition in periodic lines\nIn the 2D case, a disk structuring element can be decomposed in a succession of 4, 6 or 8 periodic lines[^3]. Doing so, the shape of the disk is only an approximate one. The first plot below indicates the percentage of pixels that are a mismatch compared to the “true” disk (by “true” I mean as best as digitizing a disk on a square matrix can be). In practice, this plot is rather uninformative. The second plot gives the effective aspect of the decomposed disks:\n{% include img src=‘diskdecomperror’ caption=‘Error percentage when approximating a disk STREL with a PL decomposition.’ width=355 %} {% include img src=‘diskdecomperrorlook’ caption=‘Aspect of the disk STREL decomposition in periodic lines, with varying radius.’ width=360 %}\nAs for performance, you can see below that it is always best to use any decomposition as soon as the radius is larger than 3. This is a lucky limit, because the periodic line decomposition gives very approximated shapes for small radii.\n{% include img src=‘diskdecompperformance’ caption=‘Processing time for the dilation of a 100x100 image.’ width=369 %} {% include img src=‘diskdecompperformancecomparison’ caption=‘Processing time ratio.’ width=371 %}\n\n\nDecomposition for other dimensionalities\nI am unable to derive an efficient decomposition of the disk STREL for the 3D case. Also, I was unable so far to find an implementation example or clear literature about such a decomposition. The closest I reach was this publication that describes a possible method (proposed in this DSP thread) but it missed the implementation details that could make it practical.",
    "crumbs": [
      "ImgLib2 Morphological Operations"
    ]
  },
  {
    "objectID": "imglib2/morphological-operations.html#references-and-links",
    "href": "imglib2/morphological-operations.html#references-and-links",
    "title": "ImgLib2 Morphological Operations",
    "section": "References and links",
    "text": "References and links\n{% include citation fn=2 doi=“10.1016/1049-9652(92)90055-3” %}\n{% include citation fn=3 doi=“10.1006/cgip.1993.1024” %}",
    "crumbs": [
      "ImgLib2 Morphological Operations"
    ]
  },
  {
    "objectID": "imglib2/morphological-operations.html#footnotes",
    "href": "imglib2/morphological-operations.html#footnotes",
    "title": "ImgLib2 Morphological Operations",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nThese are the 35 words added by the Oxford Online Dictionary during summer 2012. And another one.↩︎",
    "crumbs": [
      "ImgLib2 Morphological Operations"
    ]
  },
  {
    "objectID": "imglib2/documentation.html",
    "href": "imglib2/documentation.html",
    "title": "ImgLib2 Documentation",
    "section": "",
    "text": "Getting Started\nAccessors\nAccessibles",
    "crumbs": [
      "ImgLib2 Documentation"
    ]
  },
  {
    "objectID": "imglib2/benchmarks.html",
    "href": "imglib2/benchmarks.html",
    "title": "ImgLib2 Benchmarks",
    "section": "",
    "text": "{% include notice icon=“info” content=‘This page was last updated 2016 May 3.’ %}\nThis page compares the time performance of image processing operations using raw byte arrays, ImageJ and ImgLib2. The benchmark tests these various methods for a “cheap” per-pixel operation (inverting an 8-bit image) as well as an “expensive” operation (some calls to java.util.Math) at several image resolutions.\nSome of the charts plot results at several iterations, meaning the test was performed repeatedly in a loop. This is important because the just-in-time compiler (JIT) is able to optimize performance increasingly well as the same code is executed more than once. Hence, we show results after both a single iteration, as well as ten iterations.",
    "crumbs": [
      "ImgLib2 Benchmarks"
    ]
  },
  {
    "objectID": "imglib2/benchmarks.html#scenarios",
    "href": "imglib2/benchmarks.html#scenarios",
    "title": "ImgLib2 Benchmarks",
    "section": "Scenarios",
    "text": "Scenarios\nThe data below cover the following scenarios:\n\nCheap operation on 1Mpx image (1000 x 1000), by iteration\nExpensive operation on 1Mpx image (1000 x 1000), by iteration\nCheap operation on 25Mpx image (5000 x 5000), by iteration\nExpensive operation on 25Mpx image (5000 x 5000), by iteration\nCheap operation on various image resolutions, 1st iteration (fresh JVM)\nExpensive operation on various image resolutions, 1st iteration (fresh JVM)\nCheap operation on various image resolutions, 10th iteration\nExpensive operation on various image resolutions, 10th iteration",
    "crumbs": [
      "ImgLib2 Benchmarks"
    ]
  },
  {
    "objectID": "imglib2/benchmarks.html#hardware-and-software-specifications",
    "href": "imglib2/benchmarks.html#hardware-and-software-specifications",
    "title": "ImgLib2 Benchmarks",
    "section": "Hardware and software specifications",
    "text": "Hardware and software specifications\n\nImgLib2 version 2.9.0\nImageJ version 1.50i\nMid 2015 MacBook Pro\nMac OS X 10.11.4\n2.5 GHz Intel Core i7 processor\n16 GB 1600 MHz DDR3 RAM\nOracle Java(TM) SE Runtime Environment (build 1.8.0_77-b03) with Java HotSpot(TM) 64-Bit Server VM (build 25.77-b03, mixed mode)",
    "crumbs": [
      "ImgLib2 Benchmarks"
    ]
  },
  {
    "objectID": "imglib2/benchmarks.html#analysis-of-time-performance",
    "href": "imglib2/benchmarks.html#analysis-of-time-performance",
    "title": "ImgLib2 Benchmarks",
    "section": "Analysis of time performance",
    "text": "Analysis of time performance\nFor cheap operations, time performance is dominated by the overhead of looping itself, meaning several methods are significantly slower. However, this loop overhead is generally very small–and for several methods, such as ImgLib Array, the JIT quickly optimizes it down to raw performance. Hence, in the expensive case, performance converges across all methods.\nLooking at trends as image resolution increases (the “various image resolutions” charts), most methods have less than 1/8th second overhead even for relatively large 25Mpx (5000 x 5000) images. And again, for non-trivial image processing operations, performance is extremely comparable. One oddity is that the JIT appears to optimize performance unevenly across image resolutions. However, the exact details of such discrepancies are not consistent across multiple executions of the benchmark code.\nIn conclusion, we believe there is little reason for concern regarding time performance of any of these libraries. And the advantages of ImgLib2’s type- and container-agnostic algorithm development certainly outweigh any minor differences in time performance—especially since the flexible containers provide a mechanism for optimizing space performance based on the data type.",
    "crumbs": [
      "ImgLib2 Benchmarks"
    ]
  },
  {
    "objectID": "imglib2/benchmarks.html#source-code",
    "href": "imglib2/benchmarks.html#source-code",
    "title": "ImgLib2 Benchmarks",
    "section": "Source code",
    "text": "Source code\nThe main benchmark code can be found at:\n\n{% include github org=‘imglib’ repo=‘imglib2-tests’ branch=‘master’ path=‘src/test/java/tests/PerformanceBenchmark.java’ label=‘PerformanceBenchmark.java’ %}\n\nThe script that runs the benchmark at various image resolutions is:\n\n{% include github org=‘imglib’ repo=‘imglib2-tests’ branch=‘master’ path=‘src/test/scripts/benchmark.sh’ label=‘benchmark.sh’ %}\n\nThe shell script also uses a Python script to transform the CSV output into the pChart data on this page:\n\n{% include github org=‘imglib’ repo=‘imglib2-tests’ branch=‘master’ path=‘src/test/scripts/chart-gen.py’ label=‘chart-gen.py’ %}",
    "crumbs": [
      "ImgLib2 Benchmarks"
    ]
  },
  {
    "objectID": "imglib2/benchmarks.html#cheap-operation-results",
    "href": "imglib2/benchmarks.html#cheap-operation-results",
    "title": "ImgLib2 Benchmarks",
    "section": "Cheap operation results",
    "text": "Cheap operation results",
    "crumbs": [
      "ImgLib2 Benchmarks"
    ]
  },
  {
    "objectID": "imglib2/benchmarks.html#expensive-operation-results",
    "href": "imglib2/benchmarks.html#expensive-operation-results",
    "title": "ImgLib2 Benchmarks",
    "section": "Expensive operation results",
    "text": "Expensive operation results",
    "crumbs": [
      "ImgLib2 Benchmarks"
    ]
  },
  {
    "objectID": "imglib2/workshop-advanced.html",
    "href": "imglib2/workshop-advanced.html",
    "title": "ImgLib2 - Advanced Programming Workshop",
    "section": "",
    "text": "{% capture content %} The workshop materials linked below are outdated. Please get the most recent version from {% include github org=‘imglib’ repo=‘imglib2-advanced-workshop’ label=‘github.com/imglib/imglib2-advanced-workshop’ %}. {% endcapture %} {% include notice icon=“warning” content=content %}\nPlease download the following material for the Workshop “Advanced Programming with ImgLib2” (at the ImageJ User and Developer Conference 2012).\nadvanced-imglib2.zip\nThe zip file contains an Eclipse project with all example code and images. The pdf slides of the workshop presentation are also included in the zip file.\nJust unzip it in your Eclipse workspace. In Eclipse choose {% include bc path=“File|Import…” %} in the main menu. This brings up the following dialog. Choose “Existing Projects into Workspace” and click “Next”. \nBrowse to the location of the unzipped directory. \nClick “Finish”. You’re done.",
    "crumbs": [
      "ImgLib2 - Advanced Programming Workshop"
    ]
  },
  {
    "objectID": "imglib2/developing.html",
    "href": "imglib2/developing.html",
    "title": "Developing ImgLib2",
    "section": "",
    "text": "The ImgLib2 library uses Maven to manage project dependencies. One advantage of this approach is nice integration with various development environments (IDEs).\nBecause people tend to have differing IDE configurations, we do not put project metadata files (e.g., .classpath, .project and .settings for Eclipse) into the git repository. Instead, the IDE can use Maven’s pom.xml file directly to manage your dependencies in a better way.",
    "crumbs": [
      "Developing ImgLib2"
    ]
  },
  {
    "objectID": "imglib2/developing.html#introduction",
    "href": "imglib2/developing.html#introduction",
    "title": "Developing ImgLib2",
    "section": "",
    "text": "The ImgLib2 library uses Maven to manage project dependencies. One advantage of this approach is nice integration with various development environments (IDEs).\nBecause people tend to have differing IDE configurations, we do not put project metadata files (e.g., .classpath, .project and .settings for Eclipse) into the git repository. Instead, the IDE can use Maven’s pom.xml file directly to manage your dependencies in a better way.",
    "crumbs": [
      "Developing ImgLib2"
    ]
  },
  {
    "objectID": "imglib2/developing.html#getting-the-code",
    "href": "imglib2/developing.html#getting-the-code",
    "title": "Developing ImgLib2",
    "section": "Getting the code",
    "text": "Getting the code\nYou can clone the ImgLib2 code using Git with the URL: git://github.com/imglib/imglib2",
    "crumbs": [
      "Developing ImgLib2"
    ]
  },
  {
    "objectID": "imglib2/developing.html#developing-imglib2-with-eclipse",
    "href": "imglib2/developing.html#developing-imglib2-with-eclipse",
    "title": "Developing ImgLib2",
    "section": "Developing ImgLib2 with Eclipse",
    "text": "Developing ImgLib2 with Eclipse\nTo develop ImgLib2 in Eclipse, follow these steps:\n\nInstall the Maven plugin\nChoose {% include bc path=‘File | Import’%} from the Eclipse menu\nSelect “Existing Maven Projects” and click Next\nFor the Root Directory, specify the path where you cloned ImgLib2\nFrom the projects list, leave all items checked\nClick Finish\n\nFor fresh installs, it will initially take some time (a few minutes) for Maven to download all the dependencies for both its own plugins, and for ImgLib2. This is a one-time cost. After that, Maven will check for module updates once a day, which is generally fast.\nOnce you have the ImgLib2 projects within Eclipse, you can reap the benefits of the improved dependency management. For example, if you have the imglib2 and imglib2-algorithms projects open, the imglib2-algorithms project will have an Eclipse project build dependency on imglib2. If you then close the imglib2 project, the dependency within imglib2-algorithms with automatically become a library dependency to imglib2-2.0-SNAPSHOT.jar, rather than the project.",
    "crumbs": [
      "Developing ImgLib2"
    ]
  },
  {
    "objectID": "imglib2/developing.html#developing-imglib2-with-idea",
    "href": "imglib2/developing.html#developing-imglib2-with-idea",
    "title": "Developing ImgLib2",
    "section": "Developing ImgLib2 with IDEA",
    "text": "Developing ImgLib2 with IDEA\nIntelliJ IDEA comes with built-in support for Maven.\nSee Developing ImageJ in IntelliJ IDEA.",
    "crumbs": [
      "Developing ImgLib2"
    ]
  },
  {
    "objectID": "imglib2/developing.html#developing-imglib2-with-netbeans",
    "href": "imglib2/developing.html#developing-imglib2-with-netbeans",
    "title": "Developing ImgLib2",
    "section": "Developing ImgLib2 with NetBeans",
    "text": "Developing ImgLib2 with NetBeans\nNetBeans comes with built-in support for Maven.\nSee Developing ImageJ in NetBeans.",
    "crumbs": [
      "Developing ImgLib2"
    ]
  },
  {
    "objectID": "imglib2/developing.html#developing-imglib2-with-command-line-tools",
    "href": "imglib2/developing.html#developing-imglib2-with-command-line-tools",
    "title": "Developing ImgLib2",
    "section": "Developing ImgLib2 with command line tools",
    "text": "Developing ImgLib2 with command line tools\nYou can use the mvn command line tool to build ImgLib2. Just type “mvn” with no arguments. By default, Maven will compile the code, run unit tests, create a JAR file and install it in your local Maven repository (typically found in ~/.m2/repository). Maven does its work in a subfolder called target which is where you’ll find compiled classes and JAR artifacts.\nFor more on using the Maven command line tool, see Building a Project with Maven on the Maven website.",
    "crumbs": [
      "Developing ImgLib2"
    ]
  },
  {
    "objectID": "imglib2/discussion.html",
    "href": "imglib2/discussion.html",
    "title": "ImgLib2 Discussion",
    "section": "",
    "text": "Tobias and Saalfeld found it a great idea to create this discussion page that, if ever possible, will be filled with the daily conceptual discussions and results. That way, all interested people can contribute and keep track on what we’re trying to tackle next.\n\n\nSummary is that View\\&lt;T\\&gt; would be an interface that can return its target T, the data it is generated from:\npublic interface View&lt;T&gt; {\n    public T getTarget();\n}\nA View is an [...]Accessible that provides possibly transformed access to a subset of this target data.\nSince we could not see any reasonable application for the bare View interface, we will not implement it but use it in informal speech about virtualized access. We will also use Target to refer to the underlying data.\nExamples are IterableIntervalSubset, arbitrary Neighborhoods, RandomAccessibleView (formerly called View), RealRandomAccessibleView, TransformedRandomAccessibleView, StructuredElement, HyperShpere, SuperInterval…\n\n\n\nWe agreed that for Views that give transformed access it is more natural to specify the transform with respect to the underlying data. That is, the transform is applied to a coordinate in the data system to obtain a coordinate in the view system.\nIn matrix notation, a transform would look like y = Tx. Here, it is natural to refer to x as the source vector and to y as the target vector.\nApplied to Views, we will therefore completely reverse our previous opinion and refer to the underlying data as the Source.\nThe View\\&lt;T\\&gt; interface would look like\npublic interface View&lt;T&gt; {\n    public T getSource();\n}\nFor Transforms, we will adapt and simplify the CoordinateTransform and related interfaces from Fiji’s mpicbg submodule. There will be an integer and a real version as for Positionable and Localizable. Transform and RealTransform can specify the number of dimensions of its source and target domain. They look like\npublic interface Transform {\n    public int numSourceDimensions();\n    public int numTargetDimensions();\n    apply(long[] source, long[] target);\n    apply(Localizable source, Positionable target);\n}\n\npublic interface RealTransform {\n    public int numSourceDimensions();\n    public int numTargetDimensions();\n    apply(double[] source, double[] target);\n    apply(RealLocalizable source, RealPositionable target);\n}\nThe apply methods transfer source coordinates into target coordinates.\nThere will be an invertible version for each of these interfaces\npublic interface IvertibleTransform extends Transform {\n    applyInverse(long[] source, long[] target);\n    applyInverse(Positionable source, Localizable target);\n    InvertibleTransform inverse();\n}\n\npublic interface IvertibleRealTransform extends RealTransform {\n    applyInverse(double[] source, source[] target);\n    applyInverse(RealPositionable source, RealLocalizable target);\n    InvertibleRealTransform inverse();\n}\nNote that target is transferred into source in that case.\nWe have extensively discussed the fact that for rendering a mapped image, an inverse transformation is required whereas one prefers to define transformations in the forward manner. Nevertheless, a view (renderer) should use the forward defined instance of a Transform to create its result with changes applied to that transform having a direct effect on the result (no creation of a fresh `inverse’). Other than in mpicbg, we will achieve this by implementing Renderers for forward transformations (those transformations that can be specified in one direction only will be defined as forward transformations). For invertible transformations, the Renderer will use a final Inverter that is a forward transformations that uses the inverse apply methods of an invertible transformation for its apply method.\n\n\n\nWe think that it would be a great idea to be able to run both imglib and imglib2 together. This would relieve us from the need to port all the legacy imglib code into imglib2. Also, a shorter package hierarchy would be nice. With org.imglib2, we would match the Maven convention and the URL is still not registered…\nWhy not just call it org.imglib then? Wouldn’t clash with mpicbg.imglib of imglib1.\nBecause imglib.org is registered by somebody else already. {% include person id=‘axtimwalde’ %} 14:38, 24 March 2011 (CET)",
    "crumbs": [
      "ImgLib2 Discussion"
    ]
  },
  {
    "objectID": "imglib2/discussion.html#section",
    "href": "imglib2/discussion.html#section",
    "title": "ImgLib2 Discussion",
    "section": "",
    "text": "Tobias and Saalfeld found it a great idea to create this discussion page that, if ever possible, will be filled with the daily conceptual discussions and results. That way, all interested people can contribute and keep track on what we’re trying to tackle next.\n\n\nSummary is that View\\&lt;T\\&gt; would be an interface that can return its target T, the data it is generated from:\npublic interface View&lt;T&gt; {\n    public T getTarget();\n}\nA View is an [...]Accessible that provides possibly transformed access to a subset of this target data.\nSince we could not see any reasonable application for the bare View interface, we will not implement it but use it in informal speech about virtualized access. We will also use Target to refer to the underlying data.\nExamples are IterableIntervalSubset, arbitrary Neighborhoods, RandomAccessibleView (formerly called View), RealRandomAccessibleView, TransformedRandomAccessibleView, StructuredElement, HyperShpere, SuperInterval…\n\n\n\nWe agreed that for Views that give transformed access it is more natural to specify the transform with respect to the underlying data. That is, the transform is applied to a coordinate in the data system to obtain a coordinate in the view system.\nIn matrix notation, a transform would look like y = Tx. Here, it is natural to refer to x as the source vector and to y as the target vector.\nApplied to Views, we will therefore completely reverse our previous opinion and refer to the underlying data as the Source.\nThe View\\&lt;T\\&gt; interface would look like\npublic interface View&lt;T&gt; {\n    public T getSource();\n}\nFor Transforms, we will adapt and simplify the CoordinateTransform and related interfaces from Fiji’s mpicbg submodule. There will be an integer and a real version as for Positionable and Localizable. Transform and RealTransform can specify the number of dimensions of its source and target domain. They look like\npublic interface Transform {\n    public int numSourceDimensions();\n    public int numTargetDimensions();\n    apply(long[] source, long[] target);\n    apply(Localizable source, Positionable target);\n}\n\npublic interface RealTransform {\n    public int numSourceDimensions();\n    public int numTargetDimensions();\n    apply(double[] source, double[] target);\n    apply(RealLocalizable source, RealPositionable target);\n}\nThe apply methods transfer source coordinates into target coordinates.\nThere will be an invertible version for each of these interfaces\npublic interface IvertibleTransform extends Transform {\n    applyInverse(long[] source, long[] target);\n    applyInverse(Positionable source, Localizable target);\n    InvertibleTransform inverse();\n}\n\npublic interface IvertibleRealTransform extends RealTransform {\n    applyInverse(double[] source, source[] target);\n    applyInverse(RealPositionable source, RealLocalizable target);\n    InvertibleRealTransform inverse();\n}\nNote that target is transferred into source in that case.\nWe have extensively discussed the fact that for rendering a mapped image, an inverse transformation is required whereas one prefers to define transformations in the forward manner. Nevertheless, a view (renderer) should use the forward defined instance of a Transform to create its result with changes applied to that transform having a direct effect on the result (no creation of a fresh `inverse’). Other than in mpicbg, we will achieve this by implementing Renderers for forward transformations (those transformations that can be specified in one direction only will be defined as forward transformations). For invertible transformations, the Renderer will use a final Inverter that is a forward transformations that uses the inverse apply methods of an invertible transformation for its apply method.\n\n\n\nWe think that it would be a great idea to be able to run both imglib and imglib2 together. This would relieve us from the need to port all the legacy imglib code into imglib2. Also, a shorter package hierarchy would be nice. With org.imglib2, we would match the Maven convention and the URL is still not registered…\nWhy not just call it org.imglib then? Wouldn’t clash with mpicbg.imglib of imglib1.\nBecause imglib.org is registered by somebody else already. {% include person id=‘axtimwalde’ %} 14:38, 24 March 2011 (CET)",
    "crumbs": [
      "ImgLib2 Discussion"
    ]
  },
  {
    "objectID": "imglib2/discussion.html#section-1",
    "href": "imglib2/discussion.html#section-1",
    "title": "ImgLib2 Discussion",
    "section": "2011-03-21",
    "text": "2011-03-21\n\nEfficient access for RandomAccessibleViews\nI’ve been thinking all day about a reasonable concept for concatenation and simplification of Transforms for RandomAccessibleViews. No satisfying result so far, so at least I want to start writing down what it might look like in the end and what the problems are.\n\nSimplifying View Transformations\nThe idea is that a view should always give you a RandomAccess that is as efficient as possible. When views are layered on top of each other it is often possible to combine and simplify their transformations.\nAssume that we have a 90 degree rotated view A of an image I. and a 90 degree rotated view B of that view A. A RandomAccess on B could simply rotate by 90 degree and wrap a RandomAccess on A. The RandomAccess on A would in turn simply rotate by 90 degree and wrap a RandomAccess on I.\nHowever, this would not a good idea for a hierarchy of many views. Instead, when we request a RandomAccess from B then we would like one that directly wraps a RandomAccess on I and rotates coordinates by 180 degree.\n\nTransformable (leek)\nCoincidentally, I was playing around with an idea for ROIs that might be applicable here. You’d like to be able to take a ROI in one space, apply a transform and get a ROI in the transformed space by transforming key internal coordinates. So that lead me to think of making ROIs implement “Transformable” if they wanted to. The some transformation could be applied to a transform itself - have a transform implement transformable so that its internal matrix could get re-jiggered to operate in the new space.\nHere’s the interface that I was planning on implementing:\npackage mpicbg.imglib.transform;\n/**\n * @author leek\n *\n * A class is transformable if it can produce a copy of\n * itself in the transformed space using the supplied transform.\n * \n * Note that a class may require either a Transform or an InvertibleTransform\n * depending on whether the strategy is to transform coordinates in the\n * source space into the destination space or to generate the object in\n * the destination space by sampling invert-transformed points in the\n * source space.\n * \n */\npublic interface Transformable&lt;O,T extends Transform&gt; {\n   /**\n    * Generate a copy of the object in the transformed space.\n    * @param t the transform that maps points in the source space to those\n    *          in the destination space.\n    * @return a copy built to operate similarly in the transformed space.\n    */\n   public O transform(final T t);\n}\nYou’d only want to implement Transformable in cases where the object has internal state which allows the transformed object to operate more efficiently than transformation of the object’s inputs, followed by application of the object’s function. For ROIs, the savings are clear - cost to transform a handful of vertices in a polygon versus cost of back-transforming millions of coordinates into the original space.\nNow it obviously can be made to work for ROIs and it can be made to work to combine two linear transformations (dot product of matrices, right?). But other things are more complex and require more thought. At the end of it, each output is a function of the inputs and the trick is to composite a function that performs the operation. For a transform T1 to be transformable by transform T2, it seems that you need to combine and reduce an equation on the inputs of T1 for each of the outputs of T2. It’s a difficult enough problem that you might not want to make a transform generally transformable - you might want to have compositors with special knowledge regarding which classes can be combined to yield a new one and how it’s done.\n\n\n\nOut-Of-Bounds Handling\nIn imglib2, out-of-bounds access is handled by ExtendedRandomAccessibleInterval If you have a RandomAccessibleInterval you can wrap it into an ExtendedRandomAccessibleInterval which extends to infinity. Like so:\nF interval; // where F extends RandomAccessibleInterval&lt; T &gt;\nOutOfBoundsFactory&lt; T, F &gt; factory = new OutOfBoundsMirrorFactory&lt; T, F &gt;( OutOfBoundsMirrorFactory.Boundary.SINGLE );\nRandomAccessible&lt; T &gt; extended = new ExtendedRandomAccessibleInterval&lt; T &gt;( randomAccessible, factory );\nExtendedRandomAccessibleInterval is also a RandomAccessibleView. It might be inserted at any point in a view hierarchy. Here is an example:\nImg&lt; FloatType &gt; img = LOCI.openLOCIFloatType(...);\nRandomAccessibleView&lt; FloatType &gt; view1 = Views.extend( img );  \nRandomAccessibleIntervalView&lt; FloatType &gt; view2 = Views.superIntervalView( view1, new long[] {-20, -20}, new long[] {157, 157} );       \nRandomAccessibleView&lt; FloatType &gt;         view3 = Views.extend( view2 );    \nRandomAccessibleIntervalView&lt; FloatType &gt; view4 = Views.superIntervalView( view3, new long[] {-100, -100}, new long[] {357, 357} );\nThe original img looks like this:\n\nThis is extended to infinity (using mirroring strategy) resulting in the unbounded RandomAccessible view1. A crop of view1 looks like this:\n\nThen we take a subview view2 (which is again a bounded interval)\n\nWe extend that to get view3 and take a subview view4 which looks like this:\n\nNow assume that we want RandomAccess into view4. If we know in advance interval in which we will use the access, view4 can possibly provide more efficient access. Consider this:\n\nIf we want to access only the green region, the RandomAccess can fall through all the way to the original img without needing out-of-bounds values. We simply wrap a RandomAccess on img with a coordinate translation to the top-left corner of view4\nIf we need to access the red region, we wrap a out-of-bounds RandomAccess on view1 (which wraps a RandomAccess on the img).\nIf we need to access the blue region, we wrap a out-of-bounds RandomAccess on view3 (which wraps a out-of-bounds RandomAccess on view1, which which wraps a RandomAccess on the img).\nA view hierarchy may consist of an arbitrary sequence of views that do coordinate transforms and extending views. Depending on interval we want to access, sometimes the extending views “disappear”. In this case, transforms before and after the extending view can be concatenated and simplified if possible.",
    "crumbs": [
      "ImgLib2 Discussion"
    ]
  },
  {
    "objectID": "imglib2/discussion.html#section-2",
    "href": "imglib2/discussion.html#section-2",
    "title": "ImgLib2 Discussion",
    "section": "2011-03-24",
    "text": "2011-03-24\n\nTransformation Hierarchies\n{% include thumbnail src=‘imglib2-transform.png’ title=‘Simplified visualization of the hierarchy of ImgLib2 transforms that can be reduced by concatenation. Note that the interfaces responsible for concatenation are not implemented by the transform hierarchy. Necessary access to trivial parameters in specialized transforms is implemented just once in abstract classes.’%} We thought that it might at some point be useful to have a generic way of contracting chains of transforms. The idea is to have a hierarchy of transformations, i.e., a Translation is a Rigid transform is an Affine transform, etc. The hierarchy determines which transformations can be concatenated. It would be hard to concatenate transformations from different branches in the tree. For example, it is possible to concatenate a Translation and a Rotation to a Rigid transform. However, it is not clear whether we always want to do that. So we decided that transforms should be concatenable with their descendants in the hierarchy but not the other way around. That is, a Rigid can be concatenated with a Translation (resulting in another Rigid). But a Translation can not be concatenated with a Rigid (because this would not always result in another Translation).\nHaving a generic way of concatenating Rigid with all of its children means that all children must also be a Rigid. That is, we must be able to ask a Translation for its rotation matrix and so on. I was afraid, that this adds too much (implementation) overhead, but Stephan convinced me that this is the best way to go. Actually, it should be possible to make this relatively painless by having an hierarchy of abstract transform classes.\nWe settled on the following scheme for implementing the transformation hierarchy:\nThere are interfaces Concatenable and PreConcatenable\npublic interface Concatenable&lt; A &gt;\n{\n    public Concatenable&lt; A &gt; concatenate( A a );\n\n    public Class&lt; A &gt; getConcatenableClass();\n}\nif T implements Concatenable&lt; A &gt; that means I can concatenate it with an A, usually resulting in another T.\nThe hierarchy of transforms is implemented by a hierarchy of interfaces. However these interfaces do not implement Concatenable. Rigid cannot be Concatenable&lt; Rigid &gt; because this would mean that Translation (which extends Rigid) must be concatenable with Rigid (resulting in another Translation).\nInstead, both the Rigid and Concatenable&lt; Rigid &gt; interfaces are implemented by the RigidTransform class\npublic class RigidTransform implements Rigid, Concatenable&lt; Rigid &gt;\n{\n    @Override\n    public RigidTransform concatenate( Rigid a ) {...}\n\n    @Override\n    public Class&lt; Rigid &gt; getConcatenableClass()\n    {\n        return Rigid.class;\n    }\n}\nSimilarly we have\npublic class TranslationTransform implements Translation, Concatenable&lt; Translation &gt;\n{\n    @Override\n    public TranslationTransform concatenate( Translation a ) {...}\n\n    @Override\n    public Class&lt; Translation &gt; getConcatenableClass()\n    {\n        return Translation.class;\n    }\n}\nNote, that TranslationTransform cannot extend RigidTransform (because otherwise it would inherit Concatenable&lt; Rigid &gt;.)\nWe add an abstract class hierarchy between the interfaces and the transform classes. The abstract classes do not implement Concatenable, so at this level extension is still possible.",
    "crumbs": [
      "ImgLib2 Discussion"
    ]
  },
  {
    "objectID": "imglib2/discussion.html#section-3",
    "href": "imglib2/discussion.html#section-3",
    "title": "ImgLib2 Discussion",
    "section": "2011-03-25",
    "text": "2011-03-25\n\nGet and Set Strategy for different dimensionalities\nIf one wants to work with images that have different dimensionalities (e.g. 2d and 3d), it should be clearly defined how ImgLib handles Positionables, Localizables and location arrays.\ngetPosition calls: ImgLib will always iterate over the dimensionality of the Cursor which is queried for its position, i.e. one can always pass an array with a higher dimensionality and it will only set the lower dimensionality entries.\nsetPosition calls: ImgLib will always iterate over the dimensionality of the array that indicates the new location, i.e. one can pass an array or Localizable with a lower dimensionality and it will only set the new position in those lower dimensions.\nFor example 2d/3d:\nLocalizable2d.localize( array[3] ) - OK\nLocalizable3d.localize( array[2] ) - NOT OK\n  \nPositionable2d.setPostion( array[3] ) - NOT OK\nPositionable3d.setPostion( array[2] ) - OK\nWe discussed this topic again and found that it is always bad practice to actually work with dimension vectors of different sizes. Instead, one should use views that map into a common n-space by either adding or removing a set of dimensions in one or both of the RandomAccessibles. Still, the behavior needs to be specified strictly. With an eye on efficiency and consistency, we revert our previous opinion to\nLocalizable2d.localize( array[3] ) - OK\nLocalizable3d.localize( array[2] ) - NOT OK\n  \nPositionable2d.setPostion( array[3] ) - OK\nPositionable3d.setPostion( array[2] ) - NOT OK\nPositionable2d.setPostion( Localizable3d ) - OK\nPositionable3d.setPostion( Localizable2d ) - NOT OK\nfor the reason that in the latter case, the loop would require Localizable.numDimensions() to be called otherwise. There will be many situations where this cannot be inlined and thus be slower than using a temporary n in the executing class.",
    "crumbs": [
      "ImgLib2 Discussion"
    ]
  },
  {
    "objectID": "imglib2/discussion.html#section-4",
    "href": "imglib2/discussion.html#section-4",
    "title": "ImgLib2 Discussion",
    "section": "2011-05-02",
    "text": "2011-05-02\n\nWe discussed the ExtendedRandomAccessibleInterval:\nTobias and Preibisch discussed today that the name ExtendedRandomAccessibleInterval is somehow irritating and also to long as it will be heavily used for OutOfBounds strategies.\nIt is irritating as it is actually NOT an Interval. Instead one could name it for example OutOfBoundsView, which is also much shorter. It is only used for this purpose and the name is self-explanatory.\nWe also added some convenience methods in the Views class to construct them very easily, see here: How does ImgLib2 handle OutOfBounds?\n\n\nShould Iterator (and so Cursor) have a bck() call?\nWe have been discussing this several times with a two-folded answer:\n\nYes, because iteration order for ImgLib2 Iterators is claimed to be constant. Given that, accessing the previous element (bck()) call is always defined.\nNo, because it would require a substantial extension of the existing interfaces and classes. ImgLib2 Iterator could then implement ListIterator which is a lot of effort to implement.\n\nIn principal, I strongly support introducing it. It makes total sense but it is a change in the core. {% include person id=‘axtimwalde’ %} 17:03, 3 May 2011 (CEST)\nI discussed it again with Tobias yesterday in detail and we came to the conclusion that it does not make too much sense. First of all, any Sampler can be copied at a certain location now, i.e. wait there. And it is also important to consider that going back would have a different logic than going forward as Cursors might crash when moved out. This means one would not be able to access +1, but one has to start at the last pixel of the e.g. Img&lt;T&gt;. That means when iterating back, the test has to be different: First get value, then move.\nSo maybe we just skip it? However, we could have an Interface that provides this functionality:\nbck(); hasPrevious();\njust for the case that somebody wants to implement it for some reason and does not has to do its own interface which would be incompatible with other people who would want to it. Could be named ReverseCursor or so… {% include person id=‘StephanPreibisch’ %} 12:24, 4 May 2011 (CEST)",
    "crumbs": [
      "ImgLib2 Discussion"
    ]
  },
  {
    "objectID": "imglib2/discussion.html#section-5",
    "href": "imglib2/discussion.html#section-5",
    "title": "ImgLib2 Discussion",
    "section": "2011-05-04",
    "text": "2011-05-04\n\nLocalizable and RealLocalizable Interface get()-methods\nI noticed today that those two interfaces still have methods which are called getIntPostion(), getLongPosition() and so on which is different to the new naming scheme that is much better and shorter:\n- numDimensions instead of `getNumDimensions()`\n\n- localize instead of `getLocation()`\netc…\nshould we maybe change it as well to intPosition(), longPosition, etc?\n{% include person id=‘StephanPreibisch’ %} 12:24, 4 May 2011 (CEST)\nTobias pointed out that we should not as it is not clear if it is a getter or setter when passing an array.",
    "crumbs": [
      "ImgLib2 Discussion"
    ]
  },
  {
    "objectID": "imglib2/discussion.html#section-6",
    "href": "imglib2/discussion.html#section-6",
    "title": "ImgLib2 Discussion",
    "section": "2011-05-12",
    "text": "2011-05-12\n\nPositionables\nShould we maybe have fast setPosition-calls for dimension 0?\nIn many algorithms we will need 1-dimensional Img&lt;T&gt;, like Histograms, Gauss and many more. A fast setPositionDim0(position) could be quite some speedup for arrays as\npublic void setPosition( final int pos, final int dim )\n{\n    type.incIndex( ( pos - position[ dim ] ) * container.steps[ dim ] );\n    position[ dim ] = pos;\n}\ncould simply become\npublic void setPositionDim0( final int pos )\n{\n    type.incIndex( pos - position[ 0 ] );\n    position[ 0 ] = pos;\n}\nwhich saves a multiplication for many operations. It can also not be inlined by the JIT compiler as container.steps[ 0 ] cannot be made final, it could potentially always be changed…\nThe same applies for fwd(dim), bck(dim), move(dim), there a -- ++ and += can replace a array lookup…\n{% include person id=‘StephanPreibisch’ %} 12:27, 12 May 2011 (CEST)\nWhat about having a 1D RandomAccess instead as we have done in PlanarImg for Cursor. That could implement the setPosition(long p, int d) method ignoring d. A 1D RandomAccess could, in addition, have the proposed method such that in situations where you know what you’re doing (read: where you can cast), you have a shorter call available. That approach would also relieve us from the need to implement that method in situations where it does not make sense at all, e.g. ShapeImg, that has no 1D. {% include person id=‘axtimwalde’ %} 15:27, 12 May 2011 (CEST)\nI like this way of realizing it, maybe we could also implement it on ImgFactory level. If a Img implements RandomAccessible1D, the factory could also have a special create( long size ) method (in e.g. RandomAccessible1DFactory) which returns for example &lt;I extends ArrayImg&lt;T,?&gt; & RandomAccessible1D&gt;, so no unchecked casts are necessary. {% include person id=‘StephanPreibisch’ %} 16:15, 12 May 2011 (CEST)",
    "crumbs": [
      "ImgLib2 Discussion"
    ]
  },
  {
    "objectID": "imglib2/discussion.html#section-7",
    "href": "imglib2/discussion.html#section-7",
    "title": "ImgLib2 Discussion",
    "section": "2011-11-28",
    "text": "2011-11-28\n\nRealViews\nJohannes pointed out that we will need to be able to handle images of different calibrations, e.g., compute the sum of two images with different pixel sizes.\nI think, what we need to achieve this is something similar to what we have with the (integer) Views now. I will call them “RealViews” for now, and hope that someone comes up with a better name…\nA RealView would implement (in analogy to the integer views)\npublic interface RealTransformedRealRandomAccessible&lt; T &gt; extends RealRandomAccessible&lt; T &gt;\n{\n    /**\n     * @return the source {@link RealRandomAccessible}.\n     */\n    public RealRandomAccessible&lt; T &gt; getSource();\n\n    /**\n     * @return transformation from view coordinates into {@link #getSource()\n     *         source} coordinates.\n     */\n    public RealTransform getTransformToSource();    \n}\nNote, that RealTransform implementations do not yet exist. However the ideas are in place, see Transformation Hierarchies above. The interfaces to be implemented can be found in packages net.imglib2.concatenate and net.imglib2.transform.\nExamples of implementation of the integer version of these interfaces can be found in net.imglib2.transform.integer (These are the ones I did for views).\n\nInterpolated RealRandomAccessible\nAs the source for a RealView we need a RealRandomAccessible. This will be most likely a interpolated image. In net.imglib.interpolation we have InterpolatorFactories implementing nearest-neighbor and n-linear interpolation. What is left to do is write a (trivial) wrapper which turns a RandomAccessible into a RealRandomAccessible using an InterpolatorFactory. It would look more or less exactly like this:\npublic final class InterpolatedRandomAccessible&lt; T &gt; implements RealRandomAccessible&lt; T &gt;\n{\n    private final RandomAccessible&lt; T &gt; source;\n    \n    private final InterpolatorFactory&lt; T, RandomAccessible&lt; T &gt; &gt; factory;\n    \n    public InterpolatedRandomAccessible( final RandomAccessible&lt; T &gt; source, final InterpolatorFactory&lt; T, RandomAccessible&lt; T &gt; &gt; factory )\n    {\n        this.source = source;\n        this.factory = factory;\n    }\n\n    @Override\n    public int numDimensions()\n    {\n        return source.numDimensions();\n    }\n\n    @Override\n    public RealRandomAccess&lt; T &gt; realRandomAccess()\n    {\n        return factory.create( source );\n    } \n}\n\n\n\nUsing RealViews\nSimilar to what is now in Views there would be static methods to construct views, for example construct a RealView given a source RandomAccessible as well as source and target calibration.\nOne would wrap all of the source images into InterpolatedRandomAccessible and use RealViews as required to match the calibration of the target image. Then to carry out some operation, one would iterate through the target image and fetch the (possibly interpolated) values from the corresponding locations in the respective source views.",
    "crumbs": [
      "ImgLib2 Discussion"
    ]
  },
  {
    "objectID": "imglib2/discussion.html#section-8",
    "href": "imglib2/discussion.html#section-8",
    "title": "ImgLib2 Discussion",
    "section": "2012-01-28",
    "text": "2012-01-28\nWe have discussed with Tobias that two additional integer views would be very helpful:\n\nJoining multiple images of the same size and dimensions into one or more dimensions of a single image (composition as opposed to decomposition which is implemented by hyperslice views).\nAdding a new dimension considering an existing dimension as interleaved data.\n\nWhen done properly this has the potential to replace or at least simplify PlanarImg like containers since they could be expressed as a composition of multiple ArrayImg-s. {% include person id=‘axtimwalde’ %} 16:11, 18 January 2012 (CET)",
    "crumbs": [
      "ImgLib2 Discussion"
    ]
  },
  {
    "objectID": "imglib2/discussion.html#section-9",
    "href": "imglib2/discussion.html#section-9",
    "title": "ImgLib2 Discussion",
    "section": "2012-11-21",
    "text": "2012-11-21\nAnother useful integer view comes to mind:\n\nStack two images with all dimensions d &lt; n-1 in the (n-1)th dimension. That would enable to load an image piecewise or to grow a time sequence etc.\n\nThe stack view is a special form of a `composite’ view (do not confuse with dimensional composition as mentioned above—clarify terminology!) that consists of two RandomAccessible&lt;T&gt; or RandomAccessibleInterval&lt;T&gt; that combine their values following some composition rule. Examples:\n\na stack of images\ntwo images overlaid on top of each other\nan image that includes another image at a specified location\n\n…\nFor those that are familiar with it, AWT has the Composite interface to specify the pixel operation for combining two rasters (such as copy, add, multiply, alpha, etc.). TrakEM2 is another good example from the Fiji universe. It represents 3D images that are a stack of 2D images that are composites of transformed 2D images or 2D projections of 3D images.\nFor ImgLib2, we could have the composition principle generalized and provide some special purpose implementations (stacking, AWT raster composition, TrakEM2-alike images).",
    "crumbs": [
      "ImgLib2 Discussion"
    ]
  },
  {
    "objectID": "imglib2/examples.html",
    "href": "imglib2/examples.html",
    "title": "ImgLib2 Examples",
    "section": "",
    "text": "This page shows eight increasingly complex examples of how to program with ImgLib2. The intention of these examples are not to explain ImgLib2 concepts, but rather to give some practical hints how to work with the library and to grasp the principles in a learning-by-doing way.",
    "crumbs": [
      "ImgLib2 Examples"
    ]
  },
  {
    "objectID": "imglib2/examples.html#jupyter-notebook",
    "href": "imglib2/examples.html#jupyter-notebook",
    "title": "ImgLib2 Examples",
    "section": "Jupyter notebook",
    "text": "Jupyter notebook\nThis tutorial is also available in Jupyter notebook form here",
    "crumbs": [
      "ImgLib2 Examples"
    ]
  },
  {
    "objectID": "imglib2/examples.html#introduction-required-files",
    "href": "imglib2/examples.html#introduction-required-files",
    "title": "ImgLib2 Examples",
    "section": "Introduction & required files",
    "text": "Introduction & required files\nAll examples presented on this page are always entire classes including a main method to run them. Simply copying them into your favorite editor (e.g. the Script Editor) and compile & run them. The required Java libraries (jar files) are part of ImageJ2 and can be found in ImageJ2.app/jars/:\n\nimglib2 (the core)\nimglib2-algorithm (algorithms implemented in ImgLib2)\nimglib2-algorithm-gpl (for example 6b and 6c: GPL-licensed algorithms implemented in ImgLib2—ships with Fiji only, not plain ImageJ2, for licensing reasons)\nimglib2-ij (the ImageJ interaction)\nimglib2-realtransform (for example 8)\nscifio (for reading and writing files)\nij (ImageJ core, used for display)\n\nAlternately, you can access the examples from the {% include github org=‘imglib’ repo=‘imglib2-tutorials’ label=‘ImgLib-tutorials Git repository’ %}. After cloning the source code, open the project in your favorite IDE. See Developing ImgLib2 for further details.",
    "crumbs": [
      "ImgLib2 Examples"
    ]
  },
  {
    "objectID": "imglib2/examples.html#example-1---opening-creating-and-displaying-images",
    "href": "imglib2/examples.html#example-1---opening-creating-and-displaying-images",
    "title": "ImgLib2 Examples",
    "section": "Example 1 - Opening, creating and displaying images",
    "text": "Example 1 - Opening, creating and displaying images\nThe first example illustrates the most basic operations of opening, creating, and displaying image content in ImgLib2. It will first focus on entires images (Img&lt;T&gt;), but also show how to display subsets only.\n\nExample 1a - Wrapping ImageJ images\nIf you are already an ImageJ programmer, you might find it the easiest way to simply wrap an ImageJ image into ImgLib2. Here, the data is not copied, so editing the image in ImgLib2 will also modify the ImageJ ImagePlus.\nInternally, we use a compatibility Img to represent the data which is as fast as ImageJ but in the case of higher dimensionality (&gt;2d) is slower than ImgLib2 can do with the ArrayImg. Furthermore you are limited in dimensionality (2d-5d), in the type of data (UnsignedByteType, UnsignedShortType, FloatType and ARGBType) and maximal size of each 2d-plane (max. 46000x46000).\n{% include code org=‘imglib’ repo=‘imglib2-tutorials’ branch=‘master’ path=‘src/main/java/Example1a.java’ line-start=‘34’ %}\n\n\nExample 1b - Opening an ImgLib2 image\nThe typical way to open an image in ImgLib2 is to make use of the SCIFIO importer. Below you see two examples of how to open an image as (a) its own type (e.g. UnsignedByteType) and (b) as float (FloatType). For (a) we assume, however, that the file contains some real valued numbers as defined by the interface RealType. Color images are opened as well and color is represented as its own dimension (like in the ImageJ Hyperstacks).\nNote that for (a) we use an ArrayImg to hold the data. This means the data is held in one single java basic type array which results in optimal performance. The absolute size of image is, however, limited to 2^31-1 (~2 billion) pixels. The type of Img to use is set by passing an ImgOptions configuration when calling the ImgOpener.\nIn (b) we use a CellImg instead. It partitions the image data into n-dimensional cells each holding only a part of the data. Further, SCIFIO takes care of caching cells in and out of memory as needed, greatly reducing the memory requirement to work with very large images.\nThe SCIFIO importer also requires Types that implement NativeType, which means it is able to map the data into a Java basic type array. All available Types until now are implementing NativeType, if you want to work with some self-developed Type it would be easiest to copy the opened Img afterwards. Please also note that until now, the only Img that supports non-native types is the ListImg which stores every pixel as an individual object!\nImportant: it does not matter which type of Img you use to hold the data as we will use Iterators and RandomAccesses to access the image content. It might be, however, important if you work on two Img at the same time using Iterators, see Example2.\n{% include code org=‘imglib’ repo=‘imglib2-tutorials’ branch=‘master’ path=‘src/main/java/Example1b.java’ line-start=‘34’ %}\n\n\nExample 1c - Creating a new ImgLib2 image\nAnother important way to instantiate a new ImgLib2 Img is to create a new one from scratch. This requires you to define its Type as well as the ImgFactory to use. It does additionally need one instance of the Type that it is supposed to hold.\nOnce you have one instance of an Img, it is very easy to create another one using the same Type and ImgFactory, even if it has a different size. Note that the call img.firstElement() returns the first pixel of any Iterable, e.g. an Img.\n{% include code org=‘imglib’ repo=‘imglib2-tutorials’ branch=‘master’ path=‘src/main/java/Example1c.java’ line-start=‘34’ %}\n\n\nExample 1d - Displaying images partly using Views\nBy using the concept of Views it is possible to display only parts of the image, display a rotated view, and many more cool things. Note that you can also concatenate them. Views are much more powerful than shown in this example, they will be increasingly used throughout the examples.\nA View almost behaves similar to an Img, and in fact they share important concepts. Both are RandomAccessible, and Views that are not infinite are also an Interval (i.e. those Views have a defined size) and can therefore be made Iterable (see example 2c). In ImgLib2, all algorithms are implemented for abstract concepts like RandomAccessible, Iterable or Interval. This enables us, as can be seen below, to display a View the exact same way we would also display an Img.\n Shows the original image, the View of an interval, as well as the by 90 degree rotated version of the view. Note that only the original image in kept in memory, both Views are completely virtual.\n{% include code org=‘imglib’ repo=‘imglib2-tutorials’ branch=‘master’ path=‘src/main/java/Example1d.java’ line-start=‘34’ %}",
    "crumbs": [
      "ImgLib2 Examples"
    ]
  },
  {
    "objectID": "imglib2/examples.html#example-2---how-to-use-cursor-randomaccess-and-type",
    "href": "imglib2/examples.html#example-2---how-to-use-cursor-randomaccess-and-type",
    "title": "ImgLib2 Examples",
    "section": "Example 2 - How to use Cursor, RandomAccess and Type",
    "text": "Example 2 - How to use Cursor, RandomAccess and Type\nThe following examples illustrate how to access pixels using Cursor and RandomAccess, their basic properties, and how to modify pixel values using Type.\nAccessing pixels using a Cursor means to iterate all pixels in a way similar to iterating Java collections. However, a Cursor only ensures to visit each pixel exactly once, the order of iteration is not fixed in order to optimize the speed of iteration. This implies that that the order of iteration on two different Img is not necessarily the same, see example 2b! Cursors can be created by any object that implements IterableInterval, such as an Img. Views that are not infinite can be made iterable (see example 2c). Note that in general a Cursor has significantly higher performance than a RandomAccess and should therefore be given preference if possible.\nIn contrast to iterating image data, a RandomAccess can be placed at arbitrary locations. It is possible to set them to a specific n-dimensional coordinate or move them relative to their current position. Note that relative movements are usually more performant. A RandomAccess can be created by any object that implements RandomAccessible, like an Img or a View.\nLocalizable is implemented by Cursor as well as RandomAccess, which means they are able to report their current location. However, for Cursor we differentiate between a LocalizingCursor and a normal Cursor. A LocalizingCursor updates his position on every move, no matter if it is queried or not whereas a normal Cursor computes its location on demand. Using a LocalizingCursor is more efficient if the location is queried for every pixel, a Cursor will be faster when localizing only occasionally.\nThe Sampler interface implemented by Cursor and RandomAccess provides access to the Type instance of the current pixel. Using the Type instance it is possible to read and write its current value. Depending on the capabilities of the Type more operations are available, e.g. +,-,*,/ if it is a NumericType.\nNote that IterableInterval implements the java.lang.Iterable interface, which means it is compatible to specialized Java language constructs:\n// add 5 to every pixel\nfor ( UnsignedByteType type : img )\n    type.add( 5 );\n\nExample 2a - Duplicating an Img using a generic method\nThe goal of this example is to make a copy of an existing Img. For this task it is sufficient to employ Cursors. The order of iteration for both Img’s will be the same as they are instantiated using the same ImgFactory. It is possible to test if two IterableInterval have the same iteration order:\nboolean sameIterationOrder =\n    interval1.iterationOrder().equals( interval2.iterationOrder() );\nThe copy method itself is a generic method, it will work on any kind of Type. In this particular case it works on a FloatType, but would also work on anything else like for example a ComplexDoubleType. The declaration of the generic type is done in the method declaration:\npublic &lt; T extends Type&lt; T &gt; &gt; Img&lt; T &gt; copyImage( ... )\n&lt; T extends Type&lt; T &gt; &gt; basically means that T can be anything that extends Type. These can be final implementations such as FloatType or also intermediate interfaces such as RealType. This, however, also means that in the method body only operations supported by Type will be available. Note that the method returns a T, which also means that in the constructor from which we call method it will also return an Img&lt;FloatType&gt; as we provide it with one.\n{% include code org=‘imglib’ repo=‘imglib2-tutorials’ branch=‘master’ path=‘src/main/java/Example2a.java’ line-start=‘34’ %}\n\n\nExample 2b - Duplicating an Img using a different ImgFactory\nWARNING: The copyImageWrong method in this example makes a mistake on purpose! It intends to show that the iteration order of Cursors is important to consider. The goal is to copy the content of an ArrayImg (i.e. an Img that was created using an ArrayImgFactory) into a CellImg. Using only Cursors for both images will have a wrong result as an ArrayImg and a CellImg have different iteration orders. An ArrayImg is iterated linearly, while a CellImg is iterate cell-by-cell, but linearly within each cell.\n Shows the result if two Cursors are used that have a different iteration order. Here we are wrongly copying an ArrayImg (left) into a CellImg (right).\nThe correct code for the copy-method (in copyImageCorrect) requires the use of a RandomAccess. We use a Cursor to iterate over all pixels of the input and a RandomAccess which we set to the same location the output. Note that the setPosition() call of the RandomAccess directly takes the Cursor as input, which is possible because Cursor implements Localizable. Please also note that we use a LocalizingCursor instead of a normal Cursor because we need the location of the Cursor at every pixel.\n{% include code org=‘imglib’ repo=‘imglib2-tutorials’ branch=‘master’ path=‘src/main/java/Example2b.java’ line-start=‘34’ %}\n\n\nExample 2c - Generic copying of image data\nIn order to write a method that generically copies data requires an implementation for the underlying concepts of RandomAccessible, Iterable and Interval. In that way, it will run on Img, View and any other class implemented for these interfaces (even if they do not exist yet).\nTherefore we design the copy method in a way that the target is an IterableInterval and the source is RandomAccessible. In this way, we simply iterate over the target and copy the corresponding pixels from the source.\nAs the source only needs to be RandomAccessible, it can be basically anything that can return a value at a certain location. This can be as simple as an Img, but also interpolated sparse data, a function, a ray-tracer, a View, ….\nAs the target needs to be an IterableInterval, it is more confined. This, however does not necessarily mean that it can only be an Img or a View that is not infinite. It simply means it has to be something that is iterable and not infinite, which for example also applies to sparse data (e.g. a list of locations and their values).\n{% include code org=‘imglib’ repo=‘imglib2-tutorials’ branch=‘master’ path=‘src/main/java/Example2c.java’ line-start=‘34’ %}",
    "crumbs": [
      "ImgLib2 Examples"
    ]
  },
  {
    "objectID": "imglib2/examples.html#example-3---writing-generic-algorithms",
    "href": "imglib2/examples.html#example-3---writing-generic-algorithms",
    "title": "ImgLib2 Examples",
    "section": "Example 3 - Writing generic algorithms",
    "text": "Example 3 - Writing generic algorithms\nExamples 1 and 2 tried to introduce important tools you need in order to implement algorithms with ImgLib2. This example will show three generic implementations of algorithms computing the min/max, average as well as the center of mass.\nThe core idea is to implement algorithms as generic as possible in order to maximize code-reusability. In general, a good way to start is to think: What are the minimal requirements in order to implement algorithm X? This applies to all of the following three concepts:\n\nType: You should always use the most abstract Type possible, i.e. the one that just offers enough operations to perform your goal. In this way, the algorithm will be able to run on Types you might not even have thought about when implementing it. A good example is the min&max search in example 3a. Instead of implementing it for FloatType or the more abstract RealType, we implement it for the even more abstract Comparable & Type.\nImage data: Every algorithm should only demand those interfaces that it requires, not specific implementations of it like Img. You might require RandomAccessible (infinite), RandomAccessibleInterval (finite), Iterable (values without location), IterableInterval (values and their location) or their corresponding interfaces for real-valued locations RealRandomAccessible, RealRandomAccessibleRealInterval and IterableRealInterval. Note that you can concatenate them if you need more than one property.\nDimensionality: Usually there is no reason to restrict an algorithm to a certain dimensionality (like only for two-dimensional images), at least we could not really come up with an convincing example\n*If the application or plugin your are developing addresses a certain dimensionality (e.g. stitching of panorama photos) it is understandable that you do not want to implement everything n-dimensionally. But try to implement as many as possible of the smaller algorithm you are using as generic, n-dimensional methods. For example, everything that requires only to iterate the data is usually inherently n-dimensional.\n\nFollowing those ideas, your newly implemented algorithm will be applicable to any kind of data and dimensionality it is defined for, not only a very small domain you are currently working with. Also note that quite often this actually makes the implementation simpler.\n\nExample 3a - Min/Max search\nSearching for the minimal and maximal value in a dataset is a very nice example to illustrate generic algorithms. In order to find min/max values, Types only need to be able to compare themselves. Therefore we do not need any numeric values, we only require them to implement the (Java) interface Comparable. Additionally, no random access to the data is required, we simply need to iterate all pixels, also their location is irrelevant. The image data we need only needs to be Iterable.\nBelow we show three small variations of the min/max search. First we show the implementation as described above. Second we illustrate that this also works on a standard Java ArrayList. Third we show how the implementation changes if we do not only want the min/max value, but also their location. This requires to use IterableInterval instead, as Cursor can return their location.\n\nExample 3a - Variation 1\n{% include code org=‘imglib’ repo=‘imglib2-tutorials’ branch=‘master’ path=‘src/main/java/Example3a1.java’ line-start=‘35’ %}\n\n\nExample 3a - Variation 2\nNote that this example works just the same way if the input is not an Img, but for example just a standard Java ArrayList.\n{% include code org=‘imglib’ repo=‘imglib2-tutorials’ branch=‘master’ path=‘src/main/java/Example3a2.java’ line-start=‘34’ %}\n\n\nExample 3a - Variation 3\nIf we want to compute the location of the minimal and maximal pixel value, an Iterator will not be sufficient as we need location information. Instead the location search will demand an IterableInterval as input data which can create Cursors. Apart from that, the algorithm looks quite similar. Note that we do not use a LocalizingCursor but only a Cursor the location happens only when a new maximal or minimal value has been found while iterating the data.\n{% include code org=‘imglib’ repo=‘imglib2-tutorials’ branch=‘master’ path=‘src/main/java/Example3a3.java’ line-start=‘34’ %}\n\n\n\nExample 3b - Computing average\nIn a very similar way one can compute the average intensity for image data. Note that we restrict the Type of data to RealType. In theory, we could use NumericType as it offers the possibility to add up values. However, we cannot ensure that NumericType provided is capable of adding up millions of pixels without overflow. And even if we would ask for a second NumericType that is capable of adding values up, it might still have numerical instabilities. Note that actually every Java native type has those instabilities. Therefore we use the RealSum class that offers correct addition of even very large amounts of pixels. As this implementation is only available for double values, we restrict the method here to RealType.\n{% include code org=‘imglib’ repo=‘imglib2-tutorials’ branch=‘master’ path=‘src/main/java/Example3b.java’ line-start=‘34’ %}",
    "crumbs": [
      "ImgLib2 Examples"
    ]
  },
  {
    "objectID": "imglib2/examples.html#example-4---specialized-iterables",
    "href": "imglib2/examples.html#example-4---specialized-iterables",
    "title": "ImgLib2 Examples",
    "section": "Example 4 - Specialized iterables",
    "text": "Example 4 - Specialized iterables\nExample 4 will focus on how to work with specialized iterables. They are especially useful when performing operations in the local neighborhood of many pixels - like finding local minima/maxima, texture analysis, convolution with non-separable, non-linear filters and many more. One elegant solution is to write a specialized Iterable that will iterate all pixels in the local neighborhood. We implemented two examples:\n\nA HyperSphere that will iterate a n-dimensional sphere with a given radius at a defined location.\nA LocalNeighborhood that will iterate n-dimensionally all pixels adjacent to a certain location, but skip the central pixel (this corresponds to an both neighbors in 1d, an 8-neighborhood in 2d, a 26-neighborhood in 3d, and so on …)\n\n\nExample 4a - Drawing a sphere full of spheres\nIn the first sample we simply draw a sphere full of little spheres. We therefore create a large HyperSphere in the center of a RandomAccessibleInterval. Note that the HyperSphere only needs a RandomAccessible, we need the additional Interval simply to compute the center and the radius of the large sphere. When iterating over all pixels of this large sphere, we create small HyperSpheres at every n’th pixel and fill them with a random intensity.\nThis example illustrates the use of specialized Iterables, and emphasizes the fact that they can be stacked on the underlying RandomAccessible using the location of one as the center of a new one. Note that we always create new instances of HyperSphere. The code reads very nicely but might not offer the best performance. We therefore added update methods to the HyperSphere and its Cursor that could be used instead.\nAnother interesting aspect of this example is the use of the ImagePlusImgFactory, which is the compatibility container for ImageJ. If the required dimensionality and Type is available in ImageJ, it will internally create an ImagePlus and work on it directly. In this case, one can request the ImagePlus and show it directly. It will, however, fail if Type and dimensionality is not supported by ImageJ and throw a ImgLibException.\n Shows the result of example 4a for the (a) two-dimensional, (b) three-dimensional and (c) four-dimensional case. The image series in (c) represents a movie of a three-dimensional rendering. The images of (b) and (c) were rendered using the ImageJ 3d Viewer.\n{% include code org=‘imglib’ repo=‘imglib2-tutorials’ branch=‘master’ path=‘src/main/java/Example4a.java’ line-start=‘34’ %}\n\n\nExample 4b - Finding and displaying local minima\nIn this example we want to find all local minima in an image an display them as small spheres. To not capture too much of the noise in the image data, we first perform an in-place Gaussian smoothing with a sigma of 1, i.e. the data will be overwritten with the result. A complete documentation of the gauss package for ImgLib2 can be found here.\nWe display the results using a binary image. Note that the BitType only requires one bit per pixel and therefore is very memory efficient.\nThe generic method for minima detection has some more interesting properties. The type of the source image data actually does not require to be of Type, it simply needs something that is comparable. The LocalNeighborhood will iterate n-dimensionally all pixels adjacent to a certain location, but skip the central pixel (this corresponds to an both neighbors in 1d, an 8-neighborhood in 2d, a 26-neighborhood in 3d, and so on …). This allows to efficiently detect if a pixel is a local minima or maxima. Note that the Cursor that performs the iteration can have special implementations for specific dimensionalities to speed up the iteration. See below the example for a specialized three-dimensional iteration:\nAccess plan for a 3d neighborhood, starting at the center position marked by (x). The initial position is, in this example, NOT part of iteration, which means the center pixel is not iterated. Note that every step except for the last one can be done with a very simple move command.\nupper z plane (z-1)    center z plane (z=0)    lower z plane(z+1)\n-------------          -------------           -------------\n| 2 | 1 | 8 |          | 11| 10| 9 |           | 20| 19| 18|\n|------------          -------------           -------------\n| 3 | 0 | 7 |          | 12| x | 16|           | 21| 25| 17|\n|------------          -------------           -------------\n| 4 | 5 | 6 |          | 13| 14| 15|           | 22| 23| 24|\n-------------          -------------           -------------\nPlease note as well that if one would increase the radius of the RectangleShape to more than 1 (without at the same time changing the View on source that creates an inset border of exactly this one pixel), this example would fail as we would try to write image data outside of the defined boundary. OutOfBoundsStrategies which define how to handle such cases is discussed in example 5.\n Shows the result of the detection of local minima after the Gaussian blurring. (a) depicts the input image, (b) the blurred version (sigma=1) and (c) all local mimina drawn as circles with radius 1.\n{% include code org=‘imglib’ repo=‘imglib2-tutorials’ branch=‘master’ path=‘src/main/java/Example4b.java’ line-start=‘34’ %}",
    "crumbs": [
      "ImgLib2 Examples"
    ]
  },
  {
    "objectID": "imglib2/examples.html#example-5---out-of-bounds",
    "href": "imglib2/examples.html#example-5---out-of-bounds",
    "title": "ImgLib2 Examples",
    "section": "Example 5 - Out of bounds",
    "text": "Example 5 - Out of bounds\nMany algorithms like convolutions require to access pixels outside of an Interval, i.e. also pixels outside of an image. In ImgLib2 this is handled using Views which convert a RandomAccessibleInterval into an infinite RandomAccessible using an OutOfBoundsStrategy. Those infinite RandomAccessibles are able to return pixel values at any arbitrary location.\nImportant: One should never access pixels outside of the defined Interval as it will in most cases result in unexpected behavior, depending on the kind of underlying RandomAccessible. If it is for example an Img, it will return wrong values or throw an exception.\nWhich OutOfBoundsStrategy to use depends on task you want to perform. For convolutions we suggest the mirror strategy as it introduces the least artifacts. When working on Fourier images, the periodic strategy applies best as it correctly mimics its spatial properties. Random Value strategies might be useful to avoid accidental correlations and constant value strategies are the most performant and might work well for simple operations or to avoid exceptions when accidental writing or reading outside of the Interval occurs.\n Illustrates the effect of various OutOfBoundsStrategies. (a) shows out of bounds with a constant value, (b) shows a mirroring strategy, (c) shows the periodic strategy, and (d) shows a strategy that uses random values.\n{% include code org=‘imglib’ repo=‘imglib2-tutorials’ branch=‘master’ path=‘src/main/java/Example5.java’ line-start=‘34’ %}",
    "crumbs": [
      "ImgLib2 Examples"
    ]
  },
  {
    "objectID": "imglib2/examples.html#example-6---basic-built-in-algorithms",
    "href": "imglib2/examples.html#example-6---basic-built-in-algorithms",
    "title": "ImgLib2 Examples",
    "section": "Example 6 - Basic built-in algorithms",
    "text": "Example 6 - Basic built-in algorithms\nImgLib2 contains a growing number of built-in standard algorithms. In this section, we will show some of those, illustrate how to use them and give some examples of what it might be used for.\nTypically algorithms provide static methods for simple calling, but they also have classes which you can instantiate yourself to have more options.\nImportant: Algorithms do not allow to work on a different dimensionality than the input data. You can achieve that by selecting hyperslices using Views (see Example 6a - version 4). In this way you can for example apply two-dimensional gaussians to each frame of a movie independently.\n\nExample 6a - Gaussian convolution\nThe Gaussian convolution has its own wiki page. You can apply the Gaussian convolution with different sigmas in any dimension. It will work on any kind RandomAccessibleInterval. Below we show a examples of a simple gaussian convolution (variation 1), convolution using a different OutOfBoundsStrategy (variation 2), convolution of a part of an Interval (variation 3), and convolution of in a lower dimensionality than the image data (variation 4).\n Shows the result of the four examples for Gaussian convolution. (a) shows a simple Gaussian convolution with sigma=8. (b) shows the same Gaussian convolution but using an OutOfBoundsConstantValue instead. (c) shows the result when convolving part of the image in-place. (d) shows the result when individually convolving 1-dimensional parts on the image.\n\nExample 6a - Gaussian convolution (variation 1 - simple)\nHere, we simply apply a Gaussian convolution with a sigma of 8. Note that it could be applied in-place as well when calling Gauss.inFloatInPlace( … ). The Gaussian convolution uses by default the OutOfBoundsMirrorStrategy.\n{% include code org=‘imglib’ repo=‘imglib2-tutorials’ branch=‘master’ path=‘src/main/java/Example6a1.java’ line-start=‘34’ %}\n\n\nExample 6a - Gaussian convolution (variation 2 - different OutOfBoundsStrategy)\nHere we use an OutOfBoundsStrategyConstantValue instead. It results in continuously darker borders as the zero-values from outside of the image are used in the convolution. Note that the computation is done in-place here. However, we still need to provide an ImgFactory as the Gaussian convolution needs to create temporary image(s) - except for the one-dimensional case.\n{% include code org=‘imglib’ repo=‘imglib2-tutorials’ branch=‘master’ path=‘src/main/java/Example6a2.java’ line-start=‘34’ %}\n\n\nExample 6a - Gaussian convolution (variation 3 - only part of an Interval)\nHere we only convolve part of an Interval, or in this case part of the Img. Note that for convolution he will actually use the real image values outside of the defined Interval. The OutOfBoundsStrategy is only necessary if the kernel is that large so that it will actually grep image values outside of the underlying Img.\nNote: if you wanted, you could force him to use an OutOfBoundsStrategy directly outside of the Interval. For that you would have to create an RandomAccessibleInterval on the Img, extend it by an OutOfBoundsStrategy and give this as input to the Gaussian convolution.\n{% include code org=‘imglib’ repo=‘imglib2-tutorials’ branch=‘master’ path=‘src/main/java/Example6a3.java’ line-start=‘34’ %}\n\n\nExample 6a - Gaussian convolution (variation 4 - with a lower dimensionality)\nThis example shows howto apply an algorithm to a lower dimensionality as the image data you are working on. Therefore we use Views to create HyperSlices which have n-1 dimensions. We simply apply the algorithm in-place on those Views which will automatically update the image data in the higher-dimensional data.\nSpecifically, we apply 1-dimensional Gaussian convolution in 30-pixel wide stripes using a sigma of 16. Note that whenever you request an HyperSlice for a certain dimension, you will get back a View that contains all dimensions but this one.\n{% include code org=‘imglib’ repo=‘imglib2-tutorials’ branch=‘master’ path=‘src/main/java/Example6a4.java’ line-start=‘34’ %}\n\n\n\nExample 6b - Convolution in Fourier space\nIn image processing it is sometimes necessary to convolve images with non-separable kernels. This can be efficiently done in Fourier space exploiting the convolution theorem. It states that a convolution in real-space corresponds to a multiplication in Fourier-space, as vice versa. Note that the computation time for such a convolution is independent of the size and shape of the kernel.\nNote that it is useful to normalize the kernel prior to Fourier convolution so that the sum of all pixels is one. Otherwise, the resulting intensities will be increased.\n Shows the effect of the Fourier convolution. The left image was convolved with the kernel depicted in the lower left corner, the right panel shows the convolved image. Note that the computation speed does not depend on the size or the shape of the kernel.\nImportant: This source code is only GPLv2!\n{% include code org=‘imglib’ repo=‘imglib2-tutorials’ branch=‘master’ path=‘src/main/java/Example6b.java’ line-start=‘54’ %}\n\n\nExample 6c - Complex numbers and Fourier transforms\nIn this example we show how to work with complex numbers and Fourier transforms. We show how to determine the location of a template in an image exploiting the Fourier Shift Theorem. We therefore compute the Fast Fourier Transform of a template, invert it and convolve it in Fourier space with the original image.\nComputing an FFT is straight forward. It does not offer a static method because the instance of the FFT is required to perform an inverse FFT. This is necessary because the input image needs to be extended to a size supported by the 1-d FFT method (edu_mines_jtk.jar). In order to restore the complete input image remembering those parameters is essential.\nFor the display of complex image data we provide Converters to display the gLog of the power-spectrum (default), phase-spectrum, real values, and imaginary values. It is, however, straight forward to implement you own Converters.\nNote that for inverting the kernel we use methods defined for ComplexType, also the basic math operations add, mul, sub and div are implemented in complex math. The inverse FFT finally takes the instance of the FFT as a parameter from which it takes all required parameters for a correct inversion.\nThe final convolution of the inverse template with the image is performed using the FourierConvolution (see example 6b). Note that all possible locations of the template in the image have been tested. The peak in the result image clearly marks the location of the template, while the computation time for the whole operation takes less than a second.\n Shows the result and intermediate steps of the template matching using the Fourier space. In the upper panel you see the input image as well as the template that we use from matching. Below we show four different views of the Fast Fourier Transform of the template: the power spectrum, the phase spectrum, the real values, and the imaginary values. In the lower panel you see the result of the convolution of the inverse template with the image. The position where the template was located in the image is significantly visible. In the bottom right corner you see the inverse FFT of the inverse kernel.\nImportant: This source code is only GPLv2!\n{% include code org=‘imglib’ repo=‘imglib2-tutorials’ branch=‘master’ path=‘src/main/java/Example6c.java’ line-start=‘54’ %}",
    "crumbs": [
      "ImgLib2 Examples"
    ]
  },
  {
    "objectID": "imglib2/examples.html#example-7---interpolation",
    "href": "imglib2/examples.html#example-7---interpolation",
    "title": "ImgLib2 Examples",
    "section": "Example 7 - Interpolation",
    "text": "Example 7 - Interpolation\nInterpolation is a basic operation required in many image processing tasks. In the terminology of ImgLib2 it means to convert a RandomAccessible into a RealRandomAccessible which is able to create a RealRandomAccess. It can be positioned at real coordinates instead of only integer coordinates and a return a value for each real location. Currently, three interpolation schemes are available for ImgLib2:\n\nNearest neighbor interpolation (also for available for any kind of data that can return a nearest neighbor like sparse datasets)\nLinear interpolation\nLanczos interpolation\n\nIn the example we magnify a given real interval in the RealRandomAccessible which is based on the interpolation on an Img and compare the results of all three interpolation methods.\n Shows the result for three different interpolators when magnifying a small part of the image by 10x. The nearest neighbor interpolation is computed fastest and is the most versatile as it requires no computation but just a lookout. The result is, however, very pixelated. The linear interpolation produces reasonable results and computes quite fast. The Lanczos interpolation shows visually most pleasing results but also introduces slight artifacts in the background.\n{% include code org=‘imglib’ repo=‘imglib2-tutorials’ branch=‘master’ path=‘src/main/java/Example7.java’ line-start=‘34’ %}",
    "crumbs": [
      "ImgLib2 Examples"
    ]
  },
  {
    "objectID": "imglib2/examples.html#example-8---working-with-sparse-data",
    "href": "imglib2/examples.html#example-8---working-with-sparse-data",
    "title": "ImgLib2 Examples",
    "section": "Example 8 - Working with sparse data",
    "text": "Example 8 - Working with sparse data\nImgLib2 supports sparsely sampled data, i.e. collections of locations together with their value. Such datasets typically implement the IterableRealInterval interface, which means they can be iterated and have real-valued locations in n-dimensional space. Currently ImgLib2 supports to store such collections either as list (RealPointSampleList) or KDTree. The RealPointSampleList can be iterated, whereas the KDTree additionally supports three efficient ways of searching for nearest neighboring points in the n-dimensional space (NearestNeighborSearch, KNearestNeighborSearch, and RadiusNeighborSearch).\nIn order to display sparse data ImgLib2 currently supports two interpolation schemes, the NearestNeighborInterpolation and the InverseDistanceWeightingInterpolation. They can compute a value for every location in space by returning either the value of the closest sample or an interpolated, distance-weighted value of the k nearest neighbors to the sampled location. The interpolation scheme therefore converts any IterableRealInterval into a RealRandomAccessible that can be displayed by wrapping it into a RandomAccessible and defining Interval using Views.\nThis is, however, not only useful for display. Note that you execute on such data any algorithm or method that is implemented for RealRandomAccessible or RandomAccessible, like Gaussian convolution in the first example. Note that none of these ever exists in memory, it is done completely virtual on just the sparse samples.\n\nExample 8a - Create random sparse data, display and convolve it\nIn this example we create a certain number of random samples with random intensities inside a certain Interval. Using nearest neighbor interpolation we wrap it into a RealRandomAccessible, wrap it again into a RandomAccessible, define an Interval on it and display it. On the same virtual data we perform a Gaussian convolution and show it, too.\n On the left hand side it shows nearest-neighbor rendered random sparse data as created in example 8a. The right hand side shows the result of a Gaussian convolution, run directly on the virtual RandomAccessibleInterval.\n{% include code org=‘imglib’ repo=‘imglib2-tutorials’ branch=‘master’ path=‘src/main/java/Example8a.java’ line-start=‘34’ %}\n\n\nExample 8b - Randomly sample an existing image and display it\nIn this example we sample an existing image at random locations and render the result using a nearest neighbor interpolation as well as a distance-weighted average of the k nearest neighbors.\n\nShows the result of sparse sampling of an existing image using a varying number of random samples. The upper panel shows the rendering using nearest neighbor interpolation, the lower panel uses an interpolated, distance-weighted value of the k nearest neighbors relative to each sampled location (i.e. each pixel).\n{% include code org=‘imglib’ repo=‘imglib2-tutorials’ branch=‘master’ path=‘src/main/java/Example8b.java’ line-start=‘34’ %}",
    "crumbs": [
      "ImgLib2 Examples"
    ]
  },
  {
    "objectID": "resources/bigdataviewer_links.html",
    "href": "resources/bigdataviewer_links.html",
    "title": "BigDataViewer (BDV) Resources",
    "section": "",
    "text": "GitHub Repository: https://github.com/bigdataviewer\nBigDataViewer ImageJ Documentation: https://imagej.net/plugins/bdv/"
  },
  {
    "objectID": "resources/bigdataviewer_links.html#general-bigdataviwer-resources",
    "href": "resources/bigdataviewer_links.html#general-bigdataviwer-resources",
    "title": "BigDataViewer (BDV) Resources",
    "section": "",
    "text": "GitHub Repository: https://github.com/bigdataviewer\nBigDataViewer ImageJ Documentation: https://imagej.net/plugins/bdv/"
  },
  {
    "objectID": "resources/bigdataviewer_links.html#video-lectures",
    "href": "resources/bigdataviewer_links.html#video-lectures",
    "title": "BigDataViewer (BDV) Resources",
    "section": "Video Lectures",
    "text": "Video Lectures\n\nBigDataViewer Presentation by Tobias Pietzsch, a [NEUBIAS Academy @Home] Webinar\nBig Data I: Visualisation, File Formats and Processing in FIJI\n\nVideo: https://www.youtube.com/watch?v=LHI7vXiUUms\n\nMarwan Zouinkhi How to Produce Videos with BigDataViewer\n\nVideo: https://www.youtube.com/watch?v=vXu4ZOboEio"
  },
  {
    "objectID": "resources/bigdataviewer_links.html#tutorials-and-notebooks",
    "href": "resources/bigdataviewer_links.html#tutorials-and-notebooks",
    "title": "BigDataViewer (BDV) Resources",
    "section": "Tutorials and Notebooks",
    "text": "Tutorials and Notebooks\n\nBigDataViewer playground: https://github.com/bigdataviewer/bigdataviewer-playground\n\nCollection of various add-on and query actions for BDV\n\nBigDataViewer-vistools: https://github.com/bigdataviewer/bigdataviewer-vistools\n\nDeliver the BdvFunctions class – API to make BDV a quick visualization tool in other projects\n\nDAIS learnathon by Florian Jug: https://github.com/fjug/TutorialBigDataViewer\n\nExample of how to view user image data in a BDV stand-alone window as well as in BDV embedded into one’s own frame\nHow to incrementally add images into one common view\nHow to show additional custom overlay data (such as spheres) over the pixel data\nHow to query and modify BDV state (such as view angle)\n\nDAIS learnathon by Tobias Pietzsch: Example how to draw in BDV into a virtual large image"
  },
  {
    "objectID": "resources/bigdataviewer_links.html#references",
    "href": "resources/bigdataviewer_links.html#references",
    "title": "BigDataViewer (BDV) Resources",
    "section": "References",
    "text": "References\n\nPublication : Pietzsch, T., Saalfeld, S., Preibisch, S., & Tomancak, P. (2015). BigDataViewer: Visualization and Processing for Large Image Data Sets. Nature Methods, 12(6), 481–483.,doi:10.1038/nmeth.3392\nSee also ImgLib2 Resources"
  },
  {
    "objectID": "ecosystem/PreibischLab_multiview-reconstruction/index.html",
    "href": "ecosystem/PreibischLab_multiview-reconstruction/index.html",
    "title": "Multiview Reconstruction",
    "section": "",
    "text": "Software for the reconstruction of multi-view microscopic acquisitions like Selective Plane Illumination Microscopy (SPIM) Data."
  },
  {
    "objectID": "ecosystem/segment-anything-models-java_SAMJ/index.html",
    "href": "ecosystem/segment-anything-models-java_SAMJ/index.html",
    "title": "SamJ",
    "section": "",
    "text": "Segment Anything Model (SAM), and similar models, wrapper for Java based software."
  },
  {
    "objectID": "ecosystem/duderstadt-lab_mars-fx/index.html",
    "href": "ecosystem/duderstadt-lab_mars-fx/index.html",
    "title": "mars-fx",
    "section": "",
    "text": "JavaFX GUI for processing single-molecule TIRF and FMT data in the Structure and Dynamics of Molecular Machines research group."
  },
  {
    "objectID": "ecosystem/index.html",
    "href": "ecosystem/index.html",
    "title": "Ecosystem",
    "section": "",
    "text": "Below follows an non-exhaustive list of Fiji plugins and other software that uses either ImgLib2 or BigDataViewer:\n\n\n\n\n    \n      \n      \n    \n\n\n\n\n\n\n\n\n\n\nMoBIE Fiji Viewer\n\n\n\n\n\n\nImageJ\n\n\nFiji\n\n\nBigDataViewer\n\n\nImgLib2\n\n\nSciJava\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPredictorOp\n\n\n\n\n\n\nFiji\n\n\nBigDataViewer\n\n\nImgLib2\n\n\nSciJava\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nBigDataProcessor2\n\n\n\n\n\n\nFiji\n\n\nImageJ\n\n\nBigDataViewer\n\n\nHDF5\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFiji Plugin PlateViewer\n\n\n\n\n\n\nFiji\n\n\nBigDataViewer\n\n\nImgLib2\n\n\nSciJava\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFiji\n\n\n\n\n\n\nFiji\n\n\nImageJ\n\n\nBigDataViewer\n\n\nImgLib2\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nBVV-playground\n\n\n\n\n\n\nImageJ\n\n\nFiji\n\n\nBigDataViewer\n\n\nImgLib2\n\n\nSciJava\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nBIGCAT\n\n\n\n\n\n\nImageJ\n\n\nFiji\n\n\nBigDataViewer\n\n\nImgLib2\n\n\nSciJava\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLabel Editor\n\n\n\n\n\n\nImageJ\n\n\nFiji\n\n\nBigDataViewer\n\n\nSciJava\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nInteractiveWatershed\n\n\n\n\n\n\nImageJ\n\n\nImgLib2\n\n\nSciJava\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nBIOP Kheops Command\n\n\n\n\n\n\nImageJ\n\n\nFiji\n\n\nBigDataViewer\n\n\nSciJava\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nJanelia Render Tools And Services\n\n\n\n\n\n\nSciJava\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nBigTrace plugin\n\n\n\n\n\n\nFiji/ImageJ\n\n\nBigDataViewer\n\n\nimglib2\n\n\nBigVolumeViewer\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nImgLib2 Icy\n\n\n\n\n\n\nImgLib2\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSNT\n\n\n\n\n\n\nImageJ\n\n\nFiji\n\n\nImgLib2\n\n\nSciJava\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nindago\n\n\n\n\n\n\nImageJ\n\n\nFiji\n\n\nBigDataViewer\n\n\nImgLib2\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCosem-segmentation-analysis\n\n\n\n\n\n\nImageJ\n\n\nFiji\n\n\nBigDataViewer\n\n\nImgLib2\n\n\nSciJava\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMastodon\n\n\n\n\n\n\nFiji\n\n\nImageJ\n\n\nBigDataViewer\n\n\nImgLib2\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMoBIE IO\n\n\n\n\n\n\nImageJ\n\n\nFiji\n\n\nBigDataViewer\n\n\nImgLib2\n\n\nSciJava\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMoBIE\n\n\n\n\n\n\nFiji/ImageJ\n\n\nBigDataViewer\n\n\nimglib2\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSAM network inside Fiji\n\n\n\n\n\n\nImageJ\n\n\nImgLib2\n\n\nSciJava\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFiji plugin for context aware trainable segmentation\n\n\n\n\n\n\nFiji\n\n\nBigDataViewer\n\n\nImgLib2\n\n\nSciJava\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nplugins/CircleSkinner_.jar\n\n\n\n\n\n\nImageJ\n\n\nImgLib2\n\n\nSciJava\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFiji Plugin PlateViewer\n\n\n\n\n\n\nImageJ\n\n\nFiji\n\n\nBigDataViewer\n\n\nImgLib2\n\n\nSciJava\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nBigDataViewer Playground Display\n\n\n\n\n\n\nImageJ\n\n\nFiji\n\n\nBigDataViewer\n\n\nSciJava\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPerkinElmer Operetta Importer\n\n\n\n\n\n\nImageJ\n\n\nSciJava\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nImagejfx\n\n\n\n\n\n\nImageJ\n\n\nFiji\n\n\nImgLib2\n\n\nSciJava\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPlugin To Register Images to Atlases\n\n\n\n\n\n\nImageJ\n\n\nFiji\n\n\nBigDataViewer\n\n\nSciJava\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nBiop Bigdataviewer Tools and Plugins\n\n\n\n\n\n\nImageJ\n\n\nFiji\n\n\nBigDataViewer\n\n\nImgLib2\n\n\nSciJava\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMTrack\n\n\n\n\n\n\nImageJ\n\n\nFiji\n\n\nImgLib2\n\n\nSciJava\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSelector For BigDataViewer\n\n\n\n\n\n\nImageJ\n\n\nFiji\n\n\nBigDataViewer\n\n\nSciJava\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPaintera\n\n\n\n\n\n\nFiji\n\n\nBigDataViewer\n\n\nImgLib2\n\n\nSciJava\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPoint manager for imglib2 and imagej projects\n\n\n\n\n\n\nImageJ\n\n\nFiji\n\n\nBigDataViewer\n\n\nImgLib2\n\n\nSciJava\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDeform\n\n\n\n\n\n\nFiji\n\n\nBigDataViewer\n\n\nImgLib2\n\n\nSciJava\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nmetaseg\n\n\n\n\n\n\nImageJ\n\n\nFiji\n\n\nBigDataViewer\n\n\nImgLib2\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nBigDataViewer Bioformats Bridge\n\n\n\n\n\n\nImageJ\n\n\nFiji\n\n\nBigDataViewer\n\n\nSciJava\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSpimdata Extra Settings\n\n\n\n\n\n\nImageJ\n\n\nFiji\n\n\nBigDataViewer\n\n\nSciJava\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHot-knife\n\n\n\n\n\n\nImageJ\n\n\nFiji\n\n\nBigDataViewer\n\n\nImgLib2\n\n\nSciJava\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMultiview Simulation\n\n\n\n\n\n\nFiji\n\n\nImgLib2\n\n\nSciJava\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nKeller Lab Block file type (.klb) - BigDataViewer backend\n\n\n\n\n\n\nFiji\n\n\nBigDataViewer\n\n\nSciJava\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFMI TrackMate Add-ons\n\n\n\n\n\n\nImageJ\n\n\nFiji\n\n\nImgLib2\n\n\nSciJava\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nlimeseg\n\n\n\n\n\n\nImageJ\n\n\nImgLib2\n\n\nSciJava\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPhase Contrast Segmentation Toolbox (PHANTAST)\n\n\n\n\n\n\nImageJ\n\n\nFiji\n\n\nImgLib2\n\n\nSciJava\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nBigWarp plugin for Fiji\n\n\n\n\n\n\nImageJ\n\n\nFiji\n\n\nBigDataViewer\n\n\nImgLib2\n\n\nSciJava\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nColocalization_by_Cross_Correlation\n\n\n\n\n\n\nImageJ\n\n\nFiji\n\n\nImgLib2\n\n\nSciJava\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nRadial Symmetry\n\n\n\n\n\n\nImageJ\n\n\nFiji\n\n\nBigDataViewer\n\n\nImgLib2\n\n\nSciJava\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMaMuT\n\n\n\n\n\n\nImageJ\n\n\nFiji\n\n\nBigDataViewer\n\n\nImgLib2\n\n\nSciJava\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLabkit\n\n\n\n\n\n\nFiji\n\n\nBigDataViewer\n\n\nImgLib2\n\n\nPixel Classification\n\n\nSegmentation\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nScanCo100_BoneJ_Calibration\n\n\n\n\n\n\nImageJ\n\n\nFiji\n\n\nImgLib2\n\n\nSciJava\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nimglib2access\n\n\n\n\n\n\nImgLib2\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nmars-core\n\n\n\n\n\n\nImageJ\n\n\nImgLib2\n\n\nSciJava\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nBig Stitcher\n\n\n\n\n\n\nImageJ\n\n\nFiji\n\n\nBigDataViewer\n\n\nImgLib2\n\n\nSciJava\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nmars-fx\n\n\n\n\n\n\nImageJ\n\n\nFiji\n\n\nBigDataViewer\n\n\nImgLib2\n\n\nSciJava\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nilastik imageJ modules\n\n\n\n\n\n\nImageJ\n\n\nImgLib2\n\n\nSciJava\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSamJ\n\n\n\n\n\n\nImgLib2\n\n\nSciJava\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nmars-swing\n\n\n\n\n\n\nImageJ\n\n\nFiji\n\n\nBigDataViewer\n\n\nImgLib2\n\n\nSciJava\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMultiview Reconstruction\n\n\n\n\n\n\nImageJ\n\n\nFiji\n\n\nBigDataViewer\n\n\nImgLib2\n\n\nSciJava\n\n\n\n\n\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "ecosystem/axtimwalde_ImgLib2Access/index.html",
    "href": "ecosystem/axtimwalde_ImgLib2Access/index.html",
    "title": "imglib2access",
    "section": "",
    "text": "Simplified access to ImgLib2 pixel data for teaching purposes"
  },
  {
    "objectID": "ecosystem/Labkit/index.html",
    "href": "ecosystem/Labkit/index.html",
    "title": "Labkit",
    "section": "",
    "text": "Labkit is a user-friendly Fiji plugin for the segmentation of microscopy image data.\nIt offers easy to use manual and automated image segmentation routines that can be rapidly applied to single- and multi-channel images as well as to timelapse movies in 2D or 3D. LABKIT is specifically designed to work efficiently on big image data and enables users of consumer laptops to conveniently work with multiple-terabyte images. This efficiency is achieved by using ImgLib2 and BigDataViewer as well as a memory efficient and fast implementation of the random forest based pixel classification algorithm as the foundation of our software. Optionally we harness the power of graphics processing units (GPU) to gain additional runtime performance. LABKIT is easy to install on virtually all laptops and workstations. Additionally, LABKIT is compatible with high performance computing (HPC) clusters for distributed processing of big image data. The ability to use pixel classifiers trained in LABKIT via the ImageJ macro language enables our users to integrate this functionality as a processing step in automated image processing workflows."
  },
  {
    "objectID": "ecosystem/PreibischLab_RS-FISH/index.html",
    "href": "ecosystem/PreibischLab_RS-FISH/index.html",
    "title": "Radial Symmetry",
    "section": "",
    "text": "A plugin for radial symmetry localization on smFISH (and other) images."
  },
  {
    "objectID": "ecosystem/saalfeldlab_bigwarp/index.html",
    "href": "ecosystem/saalfeldlab_bigwarp/index.html",
    "title": "BigWarp plugin for Fiji",
    "section": "",
    "text": "A tool for manual pointwise deformable registration using bigdataviewer."
  },
  {
    "objectID": "ecosystem/NicoKiaru_LimeSeg/index.html",
    "href": "ecosystem/NicoKiaru_LimeSeg/index.html",
    "title": "limeseg",
    "section": "",
    "text": "Lipid Membrane Segmentation method for FIJI/ImageJ. https://doi.org/10.1186/s12859-018-2471-0"
  },
  {
    "objectID": "ecosystem/bhoeckendorf_klb-bdv/index.html",
    "href": "ecosystem/bhoeckendorf_klb-bdv/index.html",
    "title": "Keller Lab Block file type (.klb) - BigDataViewer backend",
    "section": "",
    "text": "The KLB is a file format developed at the Keller Lab at Janelia Research Campus to efficiently store and retrieve large 5D images (&gt;4GB) using lossless compression. The format tries to combine the JPEG2000 lossless compression levels with the block flexibility offered by HDF5 to access arbitrary regions of interest. Inspired by Parallel BZIP2, a common Linux command, we partition images into blocks and each block is compressed in parallel using the Bzip2. Both reading and writing are parallelized and scale linearly with the number of cores making it much faster than JPEG2000 and HDF5 in common multi-core machines."
  },
  {
    "objectID": "ecosystem/BIOP_bigdataviewer-bioformats/index.html",
    "href": "ecosystem/BIOP_bigdataviewer-bioformats/index.html",
    "title": "BigDataViewer Bioformats Bridge",
    "section": "",
    "text": "Commands and function for opening, conversion and easy use of bioformats format into BigDataViewer"
  },
  {
    "objectID": "ecosystem/srinituraga_cremi-deform/index.html",
    "href": "ecosystem/srinituraga_cremi-deform/index.html",
    "title": "Deform",
    "section": "",
    "text": "Deform HDF5 sources"
  },
  {
    "objectID": "ecosystem/saalfeldlab_paintera/index.html",
    "href": "ecosystem/saalfeldlab_paintera/index.html",
    "title": "Paintera",
    "section": "",
    "text": "New Era Painting and annotation tool"
  },
  {
    "objectID": "ecosystem/Kapoorlabs-paris_MTrack/index.html",
    "href": "ecosystem/Kapoorlabs-paris_MTrack/index.html",
    "title": "MTrack",
    "section": "",
    "text": "MTrack"
  },
  {
    "objectID": "ecosystem/BIOP_ijp-imagetoatlas/index.html",
    "href": "ecosystem/BIOP_ijp-imagetoatlas/index.html",
    "title": "Plugin To Register Images to Atlases",
    "section": "",
    "text": "Collection of tools to register images to atlases in Fiji."
  },
  {
    "objectID": "ecosystem/BIOP_ijp-operetta-importer/index.html",
    "href": "ecosystem/BIOP_ijp-operetta-importer/index.html",
    "title": "PerkinElmer Operetta Importer",
    "section": "",
    "text": "Hold your horses"
  },
  {
    "objectID": "ecosystem/sbesson_fiji-plugin-plateViewer/index.html",
    "href": "ecosystem/sbesson_fiji-plugin-plateViewer/index.html",
    "title": "Fiji Plugin PlateViewer",
    "section": "",
    "text": "TODO"
  },
  {
    "objectID": "ecosystem/embl-cba_cats/index.html",
    "href": "ecosystem/embl-cba_cats/index.html",
    "title": "Fiji plugin for context aware trainable segmentation",
    "section": "",
    "text": "A plugin for context aware trainable segmentation of big image data."
  },
  {
    "objectID": "ecosystem/mobie_mobie/index.html",
    "href": "ecosystem/mobie_mobie/index.html",
    "title": "MoBIE",
    "section": "",
    "text": "MoBIE is a Fiji plugin for exploring large multi-modal image data sets."
  },
  {
    "objectID": "ecosystem/Mastodon/index.html",
    "href": "ecosystem/Mastodon/index.html",
    "title": "Mastodon",
    "section": "",
    "text": "Mastodon is a large-scale tracking and track-editing framework for large, multi-view images.\nThese are typically generated in the domain Development Biology or Stem-Cell Biology or Cell Biology.\nMain features:\n\nLazy-loading of TB sized image data\nAutomated cell or particle tracking\nManual curation and correction of tracking results\nManual and semi-automatic tracking"
  },
  {
    "objectID": "ecosystem/TrNdy_indago/index.html",
    "href": "ecosystem/TrNdy_indago/index.html",
    "title": "indago",
    "section": "",
    "text": "indigare (ital.) - investigate."
  },
  {
    "objectID": "ecosystem/tinevez_imglib2-icy/index.html",
    "href": "ecosystem/tinevez_imglib2-icy/index.html",
    "title": "ImgLib2 Icy",
    "section": "",
    "text": "ImgLib2 wrappers for Icy sequences."
  },
  {
    "objectID": "ecosystem/saalfeldlab_render/index.html",
    "href": "ecosystem/saalfeldlab_render/index.html",
    "title": "Janelia Render Tools And Services",
    "section": "",
    "text": "A collection of tools and HTTP services (APIs) for rendering transformed image tiles."
  },
  {
    "objectID": "ecosystem/mpicbg-scicomp_Interactive-H-Watershed/index.html",
    "href": "ecosystem/mpicbg-scicomp_Interactive-H-Watershed/index.html",
    "title": "InteractiveWatershed",
    "section": "",
    "text": "InteractiveWatershed"
  },
  {
    "objectID": "ecosystem/saalfeldlab_bigcat/index.html",
    "href": "ecosystem/saalfeldlab_bigcat/index.html",
    "title": "BIGCAT",
    "section": "",
    "text": "Collaborative volume annotation and segmentation with BigDataViewer"
  },
  {
    "objectID": "ecosystem/Fiji/index.html",
    "href": "ecosystem/Fiji/index.html",
    "title": "Fiji",
    "section": "",
    "text": "Fiji is an image processing package—a “batteries-included” distribution of ImageJ and ImageJ2, bundling a lot of plugins which facilitate scientific image analysis.\nThe ImageJ2 data model underlying Fiji is built on ImgLib2, and Fiji includes the BigDataViewer in its distribution, along with many plugins making use of these two technologies."
  },
  {
    "objectID": "ecosystem/BigDataProcessor2/index.html",
    "href": "ecosystem/BigDataProcessor2/index.html",
    "title": "BigDataProcessor2",
    "section": "",
    "text": "BigDataProcessor2 (BDP2) is a Fiji plugin for interactive processing of TB-sized image data.\nBDP2 uses BigDataViewer for rendering and the ImgLib2 library for image processing. The BDP2 is the new version of BigDataProcessor1.\nMain features:\n\nlazy-loading of TB sized image data\nlazy-processing of TB sized image data\nImageJ macro scripting support"
  },
  {
    "objectID": "ecosystem/mobie_mobie-viewer-fiji/index.html",
    "href": "ecosystem/mobie_mobie-viewer-fiji/index.html",
    "title": "MoBIE Fiji Viewer",
    "section": "",
    "text": "Fiji viewer for MoBIE projects"
  },
  {
    "objectID": "ecosystem/bioimage-io_PredictorOp/index.html",
    "href": "ecosystem/bioimage-io_PredictorOp/index.html",
    "title": "PredictorOp",
    "section": "",
    "text": "Model runner demo for ImgLib2 consumers."
  },
  {
    "objectID": "ecosystem/embl-cba_plateviewer/index.html",
    "href": "ecosystem/embl-cba_plateviewer/index.html",
    "title": "Fiji Plugin PlateViewer",
    "section": "",
    "text": "Fiji plugin for inspection of high-throughput microscopy multi-well image data"
  },
  {
    "objectID": "ecosystem/UU-cellbiology_bvv-playground/index.html",
    "href": "ecosystem/UU-cellbiology_bvv-playground/index.html",
    "title": "BVV-playground",
    "section": "",
    "text": "Volume rendering of bdv datasets with gamma and transparency option"
  },
  {
    "objectID": "ecosystem/juglab_LabelEditor/index.html",
    "href": "ecosystem/juglab_LabelEditor/index.html",
    "title": "Label Editor",
    "section": "",
    "text": "UI component for image segmentation label comparison and selection"
  },
  {
    "objectID": "ecosystem/BIOP_ijp-kheops/index.html",
    "href": "ecosystem/BIOP_ijp-kheops/index.html",
    "title": "BIOP Kheops Command",
    "section": "",
    "text": "IJ2 commands that use bio-formats to create pyramidal ome.tiff"
  },
  {
    "objectID": "ecosystem/BigTrace/BigTrace.html",
    "href": "ecosystem/BigTrace/BigTrace.html",
    "title": "BigTrace plugin",
    "section": "",
    "text": "FIJI plugin for tracing and analysis of curvilinear structures (filaments, vessels, neurites) in volumetric microscopy datasets.\nThe plugin implements 3D ROIs (points, straight/curved lines, planes) for manual/semi-automatic segmentation of lines, curves, and spotty objects. It allows volumetric measurements of intensity and geometrical features. The plugin is scriptable using ImageJ macros."
  },
  {
    "objectID": "ecosystem/morphonets_SNT/index.html",
    "href": "ecosystem/morphonets_SNT/index.html",
    "title": "SNT",
    "section": "",
    "text": "The ImageJ framework for quantitative neuroanatomy"
  },
  {
    "objectID": "ecosystem/mobie_mobie-io/index.html",
    "href": "ecosystem/mobie_mobie-io/index.html",
    "title": "MoBIE IO",
    "section": "",
    "text": "Readers and writers for image data in MoBIE projects"
  },
  {
    "objectID": "ecosystem/segment-anything-models-java_SAMJ-IJ/index.html",
    "href": "ecosystem/segment-anything-models-java_SAMJ-IJ/index.html",
    "title": "SAM network inside Fiji",
    "section": "",
    "text": "A Fiji plugin for interactive segmentation using the SAM network"
  },
  {
    "objectID": "ecosystem/tinevez_CircleSkinner/index.html",
    "href": "ecosystem/tinevez_CircleSkinner/index.html",
    "title": "plugins/CircleSkinner_.jar",
    "section": "",
    "text": "A Fiji plugin for the automated detection and quantification of circular structure in images."
  },
  {
    "objectID": "ecosystem/BIOP_bigdataviewer-playground-display/index.html",
    "href": "ecosystem/BIOP_bigdataviewer-playground-display/index.html",
    "title": "BigDataViewer Playground Display",
    "section": "",
    "text": "Display (metadata and projectors) for BigDataViewer Playground."
  },
  {
    "objectID": "ecosystem/BIOP_bigdataviewer-biop-tools/index.html",
    "href": "ecosystem/BIOP_bigdataviewer-biop-tools/index.html",
    "title": "Biop Bigdataviewer Tools and Plugins",
    "section": "",
    "text": "Big data viewer tools BIOP - EPFL"
  },
  {
    "objectID": "ecosystem/BIOP_bigdataviewer-selector/index.html",
    "href": "ecosystem/BIOP_bigdataviewer-selector/index.html",
    "title": "Selector For BigDataViewer",
    "section": "",
    "text": "Selector Behaviours for BigDataViewer"
  },
  {
    "objectID": "ecosystem/kephale_point-manager/index.html",
    "href": "ecosystem/kephale_point-manager/index.html",
    "title": "Point manager for imglib2 and imagej projects",
    "section": "",
    "text": "A tool for managing imglib2 RealPoints."
  },
  {
    "objectID": "ecosystem/juglab_metaseg/index.html",
    "href": "ecosystem/juglab_metaseg/index.html",
    "title": "metaseg",
    "section": "",
    "text": "Meta-segmentation tool for joining many segmentation hypotheses created by various methods."
  },
  {
    "objectID": "ecosystem/BIOP_bigdataviewer-spimdata-extras/index.html",
    "href": "ecosystem/BIOP_bigdataviewer-spimdata-extras/index.html",
    "title": "Spimdata Extra Settings",
    "section": "",
    "text": "Repo containing extra settings that can be stored in spimdata file format"
  },
  {
    "objectID": "ecosystem/PreibischLab_multiview-simulation/index.html",
    "href": "ecosystem/PreibischLab_multiview-simulation/index.html",
    "title": "Multiview Simulation",
    "section": "",
    "text": "Library for simulating a multi-view acquisition including attenuation, convolution, reduced sampling and poission noise."
  },
  {
    "objectID": "ecosystem/fmi-faim_fmi-trackmate-addons/index.html",
    "href": "ecosystem/fmi-faim_fmi-trackmate-addons/index.html",
    "title": "FMI TrackMate Add-ons",
    "section": "",
    "text": "FMI Add-ons for TrackMate in Fiji"
  },
  {
    "objectID": "ecosystem/nicjac_PHANTAST-FIJI/index.html",
    "href": "ecosystem/nicjac_PHANTAST-FIJI/index.html",
    "title": "Phase Contrast Segmentation Toolbox (PHANTAST)",
    "section": "",
    "text": "The phae contrast segmentation toolbox (PHANTAST) enables high performance segmentation of phase contrast microscopy images"
  },
  {
    "objectID": "ecosystem/andmccall_Colocalization_by_Cross_Correlation/index.html",
    "href": "ecosystem/andmccall_Colocalization_by_Cross_Correlation/index.html",
    "title": "Colocalization_by_Cross_Correlation",
    "section": "",
    "text": "An ImageJ plugin for spatial correlation/colocalization analysis that is more compatible with super-resolution images than traditional pixel-wise colocalization algorithms. Has several benefits over pixel-wise algorithms:\n\nRemoves the requirement for overlap of the signals, instead allowing for spatial correlation to be measured across a distance.\nResults directly improve with improved image quality and resolution. In contrast, pixel-wise methods must be correctly interpreted using the image resolution for context, a challenging prospect for general users.\nDesigned to be simple to execute, taking only two single-channel images, a mask of the region to be analyzed, and a few utility options as input."
  },
  {
    "objectID": "ecosystem/fiji_MaMuT/index.html",
    "href": "ecosystem/fiji_MaMuT/index.html",
    "title": "MaMuT",
    "section": "",
    "text": "Fiji plugin for the annotation of massive, multi-view data."
  },
  {
    "objectID": "ecosystem/andmccall_ScanCo100BoneJcalibration/index.html",
    "href": "ecosystem/andmccall_ScanCo100BoneJcalibration/index.html",
    "title": "ScanCo100_BoneJ_Calibration",
    "section": "",
    "text": "Plugin to import ScanCo100 bone density calibration from DICOM metadata. May work with similar metadata from other scanners, but this is untested. Available at ImageJ update site: https://sites.imagej.net/UBoiaf-microct/"
  },
  {
    "objectID": "ecosystem/duderstadt-lab_mars-core/index.html",
    "href": "ecosystem/duderstadt-lab_mars-core/index.html",
    "title": "mars-core",
    "section": "",
    "text": "Molecule Archive Suite (Mars) - core data storage and processing algorithms."
  },
  {
    "objectID": "ecosystem/PreibischLab_BigStitcher/index.html",
    "href": "ecosystem/PreibischLab_BigStitcher/index.html",
    "title": "Big Stitcher",
    "section": "",
    "text": "Multiview stitching of large datasets."
  },
  {
    "objectID": "ecosystem/ilastik_ilastik4ij/index.html",
    "href": "ecosystem/ilastik_ilastik4ij/index.html",
    "title": "ilastik imageJ modules",
    "section": "",
    "text": "These ImageJ plugins wrap ilastik workflows"
  },
  {
    "objectID": "ecosystem/duderstadt-lab_mars-swing/index.html",
    "href": "ecosystem/duderstadt-lab_mars-swing/index.html",
    "title": "mars-swing",
    "section": "",
    "text": "Swing GUI for analysis of single-molecule TIRF and FMT data in the Structure and Dynamics of Molecular Machines research group"
  },
  {
    "objectID": "resources/imglib2_links.html",
    "href": "resources/imglib2_links.html",
    "title": "ImgLib2 Resources",
    "section": "",
    "text": "Blog: https://imglib.github.io/imglib2-blog/\nGitHub Repository: https://github.com/imglib/imglib2\nImageJ Documentation: https://imagej.net/imglib2/\n\n\n\n\nAlbert Cardona - Fast scripting with ImgLib2 in Fiji’s Script Editor\n\nVideo: Watch here\n\nStephan Saalfeld - Large data lazy processing with ImgLib2 and CLIJ2\n\nVideo: Watch here\n\n\n\n\n\n\nBlog example on Jupyter Notebook: How to Display ImgLib2 Data\n(LOCI?) ImageJ Tutorials Jupyter Notebook1: ImgLib2 Basics\n(LOCI?) ImageJ Tutorials Jupyter Notebook2: ImgLib2 in Detail\nImgLib2-intro : ImgLib2 introductory workshop (older)\nImgLib2-advanced : ImgLib2 advanced workshop (older)\nSaalfeldlab ImgLib2-intro I2K2020 ImgLib2 Intro\nSaalfeldlab ImgLib2-advanced : I2K2020 ImgLib2 Advanced\nSaalfeldlab i2k-tutorial: I2K2020 tutorial (Use N5, ImgLib2-Cache, and Spark)\nDAIS learnathon by Matthias Arzt: imglib2-algorithm-workshop\nDAIS learnathon by Tobias Pietzsch: imglib2-cache-examples\n\n\n\n\n\nLearning ImgLib2 Development\nOther threads on Image.sc\nImgLib2 Documentation on imagej.net wiki\n\n\n\n\n\nPublication : Tobias Pietzsch, Stephan Preibisch, Pavel Tomančák, Stephan Saalfeld, ImgLib2—generic image processing in Java, Bioinformatics, Volume 28, Issue 22, November 2012, Pages 3009–3011, https://doi.org/10.1093/bioinformatics/bts543\nSee also BigDataViewer Resources\n\n\n\n\n\nnta.kt (Saalfeld lab) The nta.kt library brings n-dimensional transformation and algebra to Kotlin. It combines the expressive power and flexibility of the Java image processing library ImgLib2 with the convenience and clarity that Kotlin language features provide.\nimglib2-trainable-segmentation (random forests) (Matthias Arzt, DAIS project) The repository shows example programs for segmentation of 2D and 3D images using random forests. One only needs to provide an input image and its (segmentation) labeling."
  },
  {
    "objectID": "resources/imglib2_links.html#video-lectures",
    "href": "resources/imglib2_links.html#video-lectures",
    "title": "ImgLib2 Resources",
    "section": "",
    "text": "Albert Cardona - Fast scripting with ImgLib2 in Fiji’s Script Editor\n\nVideo: Watch here\n\nStephan Saalfeld - Large data lazy processing with ImgLib2 and CLIJ2\n\nVideo: Watch here"
  },
  {
    "objectID": "resources/imglib2_links.html#tutorials-and-notebooks",
    "href": "resources/imglib2_links.html#tutorials-and-notebooks",
    "title": "ImgLib2 Resources",
    "section": "",
    "text": "Blog example on Jupyter Notebook: How to Display ImgLib2 Data\n(LOCI?) ImageJ Tutorials Jupyter Notebook1: ImgLib2 Basics\n(LOCI?) ImageJ Tutorials Jupyter Notebook2: ImgLib2 in Detail\nImgLib2-intro : ImgLib2 introductory workshop (older)\nImgLib2-advanced : ImgLib2 advanced workshop (older)\nSaalfeldlab ImgLib2-intro I2K2020 ImgLib2 Intro\nSaalfeldlab ImgLib2-advanced : I2K2020 ImgLib2 Advanced\nSaalfeldlab i2k-tutorial: I2K2020 tutorial (Use N5, ImgLib2-Cache, and Spark)\nDAIS learnathon by Matthias Arzt: imglib2-algorithm-workshop\nDAIS learnathon by Tobias Pietzsch: imglib2-cache-examples"
  },
  {
    "objectID": "resources/imglib2_links.html#learning-imglib2-discussions-at-image.sc",
    "href": "resources/imglib2_links.html#learning-imglib2-discussions-at-image.sc",
    "title": "ImgLib2 Resources",
    "section": "",
    "text": "Learning ImgLib2 Development\nOther threads on Image.sc\nImgLib2 Documentation on imagej.net wiki"
  },
  {
    "objectID": "resources/imglib2_links.html#references",
    "href": "resources/imglib2_links.html#references",
    "title": "ImgLib2 Resources",
    "section": "",
    "text": "Publication : Tobias Pietzsch, Stephan Preibisch, Pavel Tomančák, Stephan Saalfeld, ImgLib2—generic image processing in Java, Bioinformatics, Volume 28, Issue 22, November 2012, Pages 3009–3011, https://doi.org/10.1093/bioinformatics/bts543\nSee also BigDataViewer Resources"
  },
  {
    "objectID": "resources/imglib2_links.html#uncategorized",
    "href": "resources/imglib2_links.html#uncategorized",
    "title": "ImgLib2 Resources",
    "section": "",
    "text": "nta.kt (Saalfeld lab) The nta.kt library brings n-dimensional transformation and algebra to Kotlin. It combines the expressive power and flexibility of the Java image processing library ImgLib2 with the convenience and clarity that Kotlin language features provide.\nimglib2-trainable-segmentation (random forests) (Matthias Arzt, DAIS project) The repository shows example programs for segmentation of 2D and 3D images using random forests. One only needs to provide an input image and its (segmentation) labeling."
  },
  {
    "objectID": "imglib2/matlab.html",
    "href": "imglib2/matlab.html",
    "title": "Creating Imglib2 images in MATLAB",
    "section": "",
    "text": "This page recenses experiments with creating ImgLib2 images from MATLAB, and then calling ImgLib2 algorithm from MATLAB. We aim first at showing how to build ImgLib2 types from MATLAB types, then to do that efficiently. By this we mean having to share a single, massive low level data piece between ImgLib2 and MATLAB, which is not doable simply due to MATLAB memory model.\nAll snippets listed here are to be run from MATLAB. We rely on Miji to set up class path, so you have to start every MATLAB session with the command",
    "crumbs": [
      "Creating Imglib2 images in MATLAB"
    ]
  },
  {
    "objectID": "imglib2/matlab.html#creating-a-new-imglib2-image-in-matlab",
    "href": "imglib2/matlab.html#creating-a-new-imglib2-image-in-matlab",
    "title": "Creating Imglib2 images in MATLAB",
    "section": "Creating a new ImgLib2 image in MATLAB",
    "text": "Creating a new ImgLib2 image in MATLAB\nIn MATLAB, we are limited to native type images (float, uint8, uint16, …) represented as native arrays. The matching ImgLib2 container for this is the {% include github repo=‘imglib’ branch=‘master’ path=‘core/src/main/java/net/imglib2/img/array/ArrayImg.java’ label=‘ArrayImg’ %}.\nBecause ImgLib2 authors wrote nice static utilities, our work is relatively easy. The class ArrayImgs has all the methods you need, one per native type.\n&gt;&gt; load clown\n&gt;&gt; img = net.imglib2.img.array.ArrayImgs.doubles(X(:), size(X));\n&gt;&gt; net.imglib2.img.display.imagej.ImageJFunctions.show(img); % ImageJ display\n&gt;&gt; imshow(X,[]) % [[MATLAB]] display\n\nWe note that the ImageJ display is rotated and flipped regarding the MATLAB image. This is because MATLAB arrays are expected to be arranged along columns, whereas Java arrays are arranged along lines. We would need to permute dimension 0 and dimension 1 to display the data in ImageJ as expected in MATLAB.\nNote also that the raw data was cast from 64-bit double data to 32-bit float for display. But the source img has the expected type.",
    "crumbs": [
      "Creating Imglib2 images in MATLAB"
    ]
  },
  {
    "objectID": "imglib2/matlab.html#matlab-to-imglib2-bridge-functions",
    "href": "imglib2/matlab.html#matlab-to-imglib2-bridge-functions",
    "title": "Creating Imglib2 images in MATLAB",
    "section": "MATLAB to ImgLib2 bridge functions",
    "text": "MATLAB to ImgLib2 bridge functions\nThe exacts method in ArrayImgs depend on the native type you want to use, so you would have to deal with all possible cases. But there is already some MATLAB functions in Fiji that does that in the scripts folder of your Fiji installation: {% include github repo=‘fiji’ branch=‘master’ path=‘scripts/copytoImg.m’ label=‘copytoImg’ %} and {% include github repo=‘fiji’ branch=‘master’ path=‘scripts/copytoImgPlus.m’ label=‘copytoImgPlus’ %}. You need therefore to add scripts to your MATLAB path, but this is most likely already done since it also contains Miji which you need to call already.\nThe first function generates a plain Img. The second one generates and ImgPlus which allows you specifying the spatial calibration, image name and axis types. Check the help of these functions for details.",
    "crumbs": [
      "Creating Imglib2 images in MATLAB"
    ]
  },
  {
    "objectID": "imglib2/matlab.html#example-usage",
    "href": "imglib2/matlab.html#example-usage",
    "title": "Creating Imglib2 images in MATLAB",
    "section": "Example usage",
    "text": "Example usage\nLet’s put ImgLib2 to work to filter a source image using anisotropic diffusion:\nload clown\nMiji(false);\nimg = copytoImg(X);\nfor i = 1 : 10 % do it 10 times, in place\n    net.imglib2.algorithm.pde.PeronaMalikAnisotropicDiffusion.inFloatInPlace(img, 0.15, 10);\nend\nnet.imglib2.img.display.imagej.ImageJFunctions.show(img);",
    "crumbs": [
      "Creating Imglib2 images in MATLAB"
    ]
  },
  {
    "objectID": "imglib2/matlab.html#retrieving-the-content-of-an-imglib2-image-in-matlab",
    "href": "imglib2/matlab.html#retrieving-the-content-of-an-imglib2-image-in-matlab",
    "title": "Creating Imglib2 images in MATLAB",
    "section": "Retrieving the content of an ImgLib2 image in MATLAB",
    "text": "Retrieving the content of an ImgLib2 image in MATLAB\nNow we want to get the result back in MATLAB. Since we are using ArrayImg, we can always access the underlying java primitive array that the Img wraps, but we still have to keep in mind the X and Y dimension permutation. Also: the wrapped array is a 1D, very long array, that can be looked upon as the row-by-row concatenation of the image content. We have to reshape it in MATLAB to give the image back its aspect:\n% Retrieve a copy (see below) of the java primitive array\n&gt;&gt; I = img.update([]).getCurrentStorageArray; \n% Reshape it to match the initial aspect. Careful, we need to remember we permuted X & Y.\n&gt;&gt; J = reshape(I, size(X'));  % X' not X\n% Display it with X & Y permuted\n&gt;&gt; imshow(J', [])\nThis is all and nice and worked as expected. But it worked because we were using doubles for this image. Let’s try with a more memory-saving type. First, let’s create a uint8 image from a MATLAB array of this type:\n&gt;&gt; clear\n&gt;&gt; load clown\n&gt;&gt; Y = ind2gray(X, map);\n&gt;&gt; Z = uint8(255*Y); \n&gt;&gt; imshow(Z)\n&gt;&gt; img = copytoImg(Z);\n&gt;&gt; net.imglib2.img.display.imagej.ImageJFunctions.show(img);\nThis just builds an acceptable MATLAB uint8 image and a UnsignedByteType ImgLib2 image. Let’s suppose we modified this image, keeping its type, and want to retrieve the content in MATLAB. We do just like before:\n&gt;&gt; I = img.update([]).getCurrentStorageArray; \n&gt;&gt; J = reshape(I, size(X'));  % X' not X\n&gt;&gt; imshow(J', [])\n\nWhat happened here? The gray levels are all messed up. Checking the class of the returned array gives a clue:\n&gt;&gt; class(J)\n\nans =\n \nint8\nAha! So we gave to ImgLib2 an uint8 array, but it gives us back an int8 array, with all values wrapped. This is actually something that should have been expected: There is no unsigned byte type in Java, only signed byte type. This is a language design choice we could discuss for hours, but in Java there just isn’t uint8 or uint16[^1].\nImgLib2 developers managed to deal with it elegantly. Since the library can abstract about everything, having an image type which is not directly backed up by an existing primitive type is not a problem. The uint8 is represented internally by something Java can handle, and ImgLib2 makes sure the unsigned byte type arithmetics are respected whenever the image content is retrieved or display.\nBut when we call the getCurrentStorageArray method, we retrieve this internal representation, and it just happens that it is of type int8, that is signed byte. The values are a bit mixed, since int8 ranges from -128 to 127, while uint8 range from 0 to 255. MATLAB has a built-in function to put it back right:\n&gt;&gt; I = img.update([]).getCurrentStorageArray; \n&gt;&gt; J = typecast(I, 'uint8');\n&gt;&gt; K = reshape(J, size(X'));\n&gt;&gt; imshow(K')\nBut of course, there is a MATLAB function that does all of this for you, and that you can also find in the scripts folder of your Fiji installation: {% include github repo=‘fiji’ branch=‘master’ path=‘scripts/copytoMatlab.m’ label=‘copytoMatlab’ %}.",
    "crumbs": [
      "Creating Imglib2 images in MATLAB"
    ]
  },
  {
    "objectID": "imglib2/matlab.html#matlab-arrays-are-not-shared",
    "href": "imglib2/matlab.html#matlab-arrays-are-not-shared",
    "title": "Creating Imglib2 images in MATLAB",
    "section": "MATLAB arrays are not shared",
    "text": "MATLAB arrays are not shared\nWe expect the underlying raw data - an array of doubles - to be shared between MATLAB and ImgLib2. Unfortunately, it isn’t so. Let’s try to turn the first column entirely white\n&gt;&gt; close all\n&gt;&gt; X(:,1) = 255;\n&gt;&gt; imshow(X,[])\n&gt;&gt; net.imglib2.img.display.imagej.ImageJFunctions.show(img);\nIt did not work: the ImgLib2 image did not see the change. This means that it does not wrap the MATLAB array, but a copy of it. This is a shame and this is of crucial importance. Not only we might have some very large data to process we wish not to duplicate in memory, but we might want to take advantage of some ImgLib2 algorithms that run in place and modify the source image.\nThis is by construction, and there is no workaround, at least for Java1. MATLAB passes all the data per-value, not per-reference and this is what happened here.",
    "crumbs": [
      "Creating Imglib2 images in MATLAB"
    ]
  },
  {
    "objectID": "imglib2/matlab.html#using-java-arrays-in-matlab",
    "href": "imglib2/matlab.html#using-java-arrays-in-matlab",
    "title": "Creating Imglib2 images in MATLAB",
    "section": "Using Java arrays in MATLAB",
    "text": "Using Java arrays in MATLAB\nA first attempt to solve this would be to try and use Java arrays in MATLAB, which is made possible by the function javaArray. As explained in the [MATLAB docs, you can use this function to instantiate proper Java arrays, which we could then use to create an ImgLib2 image, and play with the same data both on the MATLAB side and on the ImgLib2 side.\nBut this would unsatisfactory as well. The javaArray function allows the creation of Java objects, but not of primitive types. As suggested on the MATLAB docs, and noted here:\nMATLAB can pass Java objects when calling a Java function, and modifications to these objects are afterwards available in MATLAB - except when the Java object is an array of a primitive data type&lt;/u&gt;. In this case automatic conversion between [MATLAB](https://imagej.net/scripting/matlab) and Java kicks in, making a Java array-of-primitive-double correspond directly to a double matrix in [MATLAB](https://imagej.net/scripting/matlab) - which is by [MATLAB](https://imagej.net/scripting/matlab) conventions a thing “passed as value” so no return values are possible.\nSo this means that we could create an array of java.lang.Double[] and use its reference, but we cannot have and manipulate a plain native double[] array without MATLAB shadowing any change because it operates on a copy.\nAn array of java.lang.Double[] is not acceptable for most of our use cases. We expect to deal sometimes with very large images - the main reason for trying to escape duplicating data in memory - and a Double object adds some overhead on the primitive it wraps we would like to avoid.\nAs of now (MATLAB 2013a), this answer seems to be definitive: There is no workaround if we are to stay with a native array in MATLAB.",
    "crumbs": [
      "Creating Imglib2 images in MATLAB"
    ]
  },
  {
    "objectID": "imglib2/matlab.html#using-imglib2-types-as-primary-data-holder",
    "href": "imglib2/matlab.html#using-imglib2-types-as-primary-data-holder",
    "title": "Creating Imglib2 images in MATLAB",
    "section": "Using ImgLib2 types as primary data holder",
    "text": "Using ImgLib2 types as primary data holder\nTherefore, a solution implies a change of approach. We will not use MATLAB matrices as data holder, but use ImgLib2 structures. We can access the raw data through ImgLib2 facilities (cursor, randomAcess, …). The changes made are then done in place, and will be visible from both ImgLib2 and MATLAB, provided the data is accessed from the ImgLib2 container. We also already saw that ArrayImgs wrap a native array, that we can copy to MATLAB shall we need to quickly get the whole dataset.\nWith this strategy, MATLAB steps aside a bit, since we use ImgLib2 for basically all data manipulation. It takes the role of a scripting language like Jython, from which you make plain call to Java classes. Duplicating the native array wrapped in an ArrayImg allows you still make the best our of MATLAB easily, but you must design a good tactic in your script to avoid these local copies to exist for too long.",
    "crumbs": [
      "Creating Imglib2 images in MATLAB"
    ]
  },
  {
    "objectID": "imglib2/matlab.html#references",
    "href": "imglib2/matlab.html#references",
    "title": "Creating Imglib2 images in MATLAB",
    "section": "References",
    "text": "References\n[^1] :Check here for the details of unsigned types story.",
    "crumbs": [
      "Creating Imglib2 images in MATLAB"
    ]
  },
  {
    "objectID": "imglib2/matlab.html#footnotes",
    "href": "imglib2/matlab.html#footnotes",
    "title": "Creating Imglib2 images in MATLAB",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nFor C++, you can write a Mex wrapper that will force MATLAB to operate on the reference of an array.↩︎",
    "crumbs": [
      "Creating Imglib2 images in MATLAB"
    ]
  },
  {
    "objectID": "imglib2/getting-started.html",
    "href": "imglib2/getting-started.html",
    "title": "ImgLib2 - Getting Started",
    "section": "",
    "text": "Before you dive into ImgLib2 for real, you should know how to create and display an image, so that you can visually enjoy the fruits of your labor.\nThe following piece of code creates and displays an 400x320 8bit gray-level image:\nimport net.imglib2.img.Img;\nimport net.imglib2.img.array.ArrayImgFactory;\nimport net.imglib2.img.display.imagej.ImageJFunctions;\nimport net.imglib2.type.numeric.integer.UnsignedByteType;\n\npublic class CreateAndDisplay\n{\n    public static void main( final String[] args )\n    {\n        final Img&lt; UnsignedByteType &gt; img = new ArrayImgFactory&lt; UnsignedByteType &gt;()\n            .create( new long[] { 400, 320 }, new UnsignedByteType() );\n        ImageJFunctions.show( img );\n    }\n}\nWhen you run this example, you should get a window showing a black 400x320 image. In lines 10-11, the image is created. In line 12 it is displayed. Now, that is one awfully long line just to create a black image. Let’s break it down into smaller parts.\nfinal ImgFactory&lt; UnsignedByteType &gt; factory = new ArrayImgFactory&lt; UnsignedByteType &gt;();\nfinal long[] dimensions = new long[] { 400, 320 };\nfinal UnsignedByteType type = new UnsignedByteType();\nfinal Img&lt; UnsignedByteType &gt; img = factory.create( dimensions, type );\nPixel images in ImgLib2 are created using an ImgFactory. There are different ImgFactories, that create pixel containers with different memory layouts. Here, we create an ArrayImgFactory. This factory creates in containers that map to a single flat Java array:\nfinal ImgFactory&lt; UnsignedByteType &gt; factory\n        = new ArrayImgFactory&lt; UnsignedByteType &gt;();\nThe type parameter of the factory that specifies the value type of the image we want to create. We want to create a 8-bit gray-level image, thus we use UnsignedByteType.\nNext we create a long[] array that specifies the image size in every dimension. The length of the array specifies the number of dimensions. Here, we state that we want to create 400x320 2D image:\nfinal long[] dimensions = new long[] { 400, 320 };\nFinally, we need to provide a type variable, that is a variable having the type that is to be stored in the image. This must match the generic type parameter of the ImgFactory. Thus we create an UnsignedByteType:\nfinal UnsignedByteType type = new UnsignedByteType();\nThen we can create the image, using the factory, dimensions, and type variable:\nfinal Img&lt; UnsignedByteType &gt; img = factory.create( dimensions, type );\nWe store the result of the create() method in an Img variable. Img is a convenience interface that gathers properties of pixel image containers such as having a number of dimensions, being able to iterate it’s pixels, etc.\nThis image is then displayed using:\nImageJFunctions.show( img );\nImageJFunctions provides convenience methods to wrap ImgLib2 constructs into ImageJ containers and display them. It works with 2D and 3D images and can handle most of the pixel types supported by ImgLib2. ImgLib2 provides more sophisticated ways of getting image data to your screen, but we will not go into that now. As a rule of thumb, if you have something remotely resembling a pixel grid, usually you can ImageJFunctions.show() it.",
    "crumbs": [
      "ImgLib2 - Getting Started"
    ]
  },
  {
    "objectID": "imglib2/getting-started.html#creating-and-displaying-an-image",
    "href": "imglib2/getting-started.html#creating-and-displaying-an-image",
    "title": "ImgLib2 - Getting Started",
    "section": "",
    "text": "Before you dive into ImgLib2 for real, you should know how to create and display an image, so that you can visually enjoy the fruits of your labor.\nThe following piece of code creates and displays an 400x320 8bit gray-level image:\nimport net.imglib2.img.Img;\nimport net.imglib2.img.array.ArrayImgFactory;\nimport net.imglib2.img.display.imagej.ImageJFunctions;\nimport net.imglib2.type.numeric.integer.UnsignedByteType;\n\npublic class CreateAndDisplay\n{\n    public static void main( final String[] args )\n    {\n        final Img&lt; UnsignedByteType &gt; img = new ArrayImgFactory&lt; UnsignedByteType &gt;()\n            .create( new long[] { 400, 320 }, new UnsignedByteType() );\n        ImageJFunctions.show( img );\n    }\n}\nWhen you run this example, you should get a window showing a black 400x320 image. In lines 10-11, the image is created. In line 12 it is displayed. Now, that is one awfully long line just to create a black image. Let’s break it down into smaller parts.\nfinal ImgFactory&lt; UnsignedByteType &gt; factory = new ArrayImgFactory&lt; UnsignedByteType &gt;();\nfinal long[] dimensions = new long[] { 400, 320 };\nfinal UnsignedByteType type = new UnsignedByteType();\nfinal Img&lt; UnsignedByteType &gt; img = factory.create( dimensions, type );\nPixel images in ImgLib2 are created using an ImgFactory. There are different ImgFactories, that create pixel containers with different memory layouts. Here, we create an ArrayImgFactory. This factory creates in containers that map to a single flat Java array:\nfinal ImgFactory&lt; UnsignedByteType &gt; factory\n        = new ArrayImgFactory&lt; UnsignedByteType &gt;();\nThe type parameter of the factory that specifies the value type of the image we want to create. We want to create a 8-bit gray-level image, thus we use UnsignedByteType.\nNext we create a long[] array that specifies the image size in every dimension. The length of the array specifies the number of dimensions. Here, we state that we want to create 400x320 2D image:\nfinal long[] dimensions = new long[] { 400, 320 };\nFinally, we need to provide a type variable, that is a variable having the type that is to be stored in the image. This must match the generic type parameter of the ImgFactory. Thus we create an UnsignedByteType:\nfinal UnsignedByteType type = new UnsignedByteType();\nThen we can create the image, using the factory, dimensions, and type variable:\nfinal Img&lt; UnsignedByteType &gt; img = factory.create( dimensions, type );\nWe store the result of the create() method in an Img variable. Img is a convenience interface that gathers properties of pixel image containers such as having a number of dimensions, being able to iterate it’s pixels, etc.\nThis image is then displayed using:\nImageJFunctions.show( img );\nImageJFunctions provides convenience methods to wrap ImgLib2 constructs into ImageJ containers and display them. It works with 2D and 3D images and can handle most of the pixel types supported by ImgLib2. ImgLib2 provides more sophisticated ways of getting image data to your screen, but we will not go into that now. As a rule of thumb, if you have something remotely resembling a pixel grid, usually you can ImageJFunctions.show() it.",
    "crumbs": [
      "ImgLib2 - Getting Started"
    ]
  },
  {
    "objectID": "imglib2/getting-started.html#opening-and-displaying-image-files",
    "href": "imglib2/getting-started.html#opening-and-displaying-image-files",
    "title": "ImgLib2 - Getting Started",
    "section": "Opening And Displaying Image Files",
    "text": "Opening And Displaying Image Files\nYou can open image files with ImgOpener which is using LOCI Bio-Formats. The following opens and displays an image file:\nimport net.imglib2.img.Img;\nimport net.imglib2.img.array.ArrayImgFactory;\nimport net.imglib2.img.display.imagej.ImageJFunctions;\nimport io.scif.img.ImgIOException;\nimport io.scif.img.ImgOpener;\nimport net.imglib2.type.numeric.integer.UnsignedByteType;\n\npublic class OpenAndDisplay\n{\n    public static void main( final String[] args )\n    {\n        try\n        {\n            final Img&lt; UnsignedByteType &gt; img = new ImgOpener().openImg( \"graffiti.tif\",\n                new ArrayImgFactory&lt; UnsignedByteType &gt;(), new UnsignedByteType() );\n            ImageJFunctions.show( img );\n        }\n        catch ( final ImgIOException e )\n        {\n            e.printStackTrace();\n        }\n    }\n}\nThe image is loaded in lines 14-15. Lets look the steps in more detail. We create an ImgOpener:\nfinal ImgOpener opener = new ImgOpener();\nWhen opening an image, we can specify which memory layout to use and as which value type we want to load the image. We want to use the ArrayImg layout again, and we want to have UnsignedByteType values again.\nSimilar to the above example we need an ImgFactory and an instance of the value type:\nfinal ImgFactory&lt; UnsignedByteType &gt; factory = new ArrayImgFactory&lt; UnsignedByteType &gt;();\nfinal UnsignedByteType type = new UnsignedByteType();\nThen we can use the openImg() method, giving a filename, ImgFactory, and type instance:\nfinal Img&lt; UnsignedByteType &gt; img = opener.openImg( \"graffiti.tif\", factory, type );\nIf there is a problem reading the image, openImg() throws an ImgIOException. If all goes well, we store the result in an Img variable for convenience. (Actually the result is an ImgPlus wrapping an ArrayImg.)",
    "crumbs": [
      "ImgLib2 - Getting Started"
    ]
  },
  {
    "objectID": "imglib2/getting-started.html#notes",
    "href": "imglib2/getting-started.html#notes",
    "title": "ImgLib2 - Getting Started",
    "section": "Notes",
    "text": "Notes\n\nNote that Img is just convenience interface. When you get more proficient with ImgLib2 you will find yourself using it less and less. You will either be more concrete or more general than that. In the above example, we could be more concrete – the result of the ArrayImgFactory&lt; UnsignedByteType &gt;.create() is actually an ArrayImg&lt; UnsignedByteType, ByteArray &gt;. In algorithm implementations, you want to be as generic as possible to not constrain yourself to specific image types. You will specify only the super-interfaces of Img that you really need. For instance, if you need something which has boundaries and can be iterated you would use IterableInterval.\nThere are more ImgLib2 Examples on Opening, creating and displaying images.",
    "crumbs": [
      "ImgLib2 - Getting Started"
    ]
  },
  {
    "objectID": "imglib2/algorithms.html",
    "href": "imglib2/algorithms.html",
    "title": "ImgLib2 Algorithms",
    "section": "",
    "text": "Algorithms should either implement java.lang.Runnable if they do not return an object or java.util.concurrent.Callable if they do; no further interface hierarchy will provided for now\n\n\n\nMultithreading will be solved through the ops package for easily parallelizable algorithms\n\n\n\nMore complicated algorithms that can provide significantly increased performance by implementing their own multithreading scenarios should implement the MultiThreading interface which allows to adjust the number of threads\n\n\n\nAlgorithms should take RandomAccessible, RandomAccessibleInterval and/or Iterable as input, Img should be only used as temporary data structure\n\nRandomAccessible should be used if the OutOfBounds is defined externally (e.g. for gaussian convolution), an Interval should be passed as an extra parameter which defines the area that should be processed\nRandomAccessibleInterval should be used if the algorithm defines its own OutOfBounds strategy (e.g. FFT) outside the given boundary; an Interval should be passed as an extra parameter which defines the area that should be processed\nIterable should be used if per-pixel operations are performed, here multithreading is delegated upstream\n\n\n\n\nAlgorithms will be split into Maven subpackages where each subpackage can manage its own dependencies and licenses\n\nGauss\nFFT\nFourierConvolution\nIntegralImg\nScaleSpace\n…\n\n\n\n\nJUnit tests should be placed in the respective subpackages and must not require any additional imports\n\n\n\nHuman tests that might display images, show graphs or require any other imports than the algorithm itself should be placed in the ImgLib2-Tests project following the path convention of the algorithm\n\n\n\nStandard images for Human tests will not be part of the git repository but will be available as http-link; a special opener class net.imglib2.io.ImgIOUtils will provide download and permanent caching in the temporary directory of each computer\n\n\n\nAlgorithms will have no direct dependency on the ImageJ2 plugin framework as they are generic; extra classes will provide access to the functionality of those algorithms\n\n\n\nA Benchmarker class will be implemented to measure the performance for different containers, types, operating systems and machines",
    "crumbs": [
      "ImgLib2 Algorithms"
    ]
  },
  {
    "objectID": "imglib2/algorithms.html#conventions-for-algorithm-development-in-imglib2",
    "href": "imglib2/algorithms.html#conventions-for-algorithm-development-in-imglib2",
    "title": "ImgLib2 Algorithms",
    "section": "",
    "text": "Algorithms should either implement java.lang.Runnable if they do not return an object or java.util.concurrent.Callable if they do; no further interface hierarchy will provided for now\n\n\n\nMultithreading will be solved through the ops package for easily parallelizable algorithms\n\n\n\nMore complicated algorithms that can provide significantly increased performance by implementing their own multithreading scenarios should implement the MultiThreading interface which allows to adjust the number of threads\n\n\n\nAlgorithms should take RandomAccessible, RandomAccessibleInterval and/or Iterable as input, Img should be only used as temporary data structure\n\nRandomAccessible should be used if the OutOfBounds is defined externally (e.g. for gaussian convolution), an Interval should be passed as an extra parameter which defines the area that should be processed\nRandomAccessibleInterval should be used if the algorithm defines its own OutOfBounds strategy (e.g. FFT) outside the given boundary; an Interval should be passed as an extra parameter which defines the area that should be processed\nIterable should be used if per-pixel operations are performed, here multithreading is delegated upstream\n\n\n\n\nAlgorithms will be split into Maven subpackages where each subpackage can manage its own dependencies and licenses\n\nGauss\nFFT\nFourierConvolution\nIntegralImg\nScaleSpace\n…\n\n\n\n\nJUnit tests should be placed in the respective subpackages and must not require any additional imports\n\n\n\nHuman tests that might display images, show graphs or require any other imports than the algorithm itself should be placed in the ImgLib2-Tests project following the path convention of the algorithm\n\n\n\nStandard images for Human tests will not be part of the git repository but will be available as http-link; a special opener class net.imglib2.io.ImgIOUtils will provide download and permanent caching in the temporary directory of each computer\n\n\n\nAlgorithms will have no direct dependency on the ImageJ2 plugin framework as they are generic; extra classes will provide access to the functionality of those algorithms\n\n\n\nA Benchmarker class will be implemented to measure the performance for different containers, types, operating systems and machines",
    "crumbs": [
      "ImgLib2 Algorithms"
    ]
  },
  {
    "objectID": "imglib2/workshop-introductory.html",
    "href": "imglib2/workshop-introductory.html",
    "title": "ImgLib2 - Introductory Workshop",
    "section": "",
    "text": "Please download the following archive and the presentation to follow the workshop presentation:\n\nThe presentation as PDF\n\n\n\nThe sources for this workshop and completed examples\n\n\n\nthe sources for this workshop, completed examples and pictures",
    "crumbs": [
      "ImgLib2 - Introductory Workshop"
    ]
  },
  {
    "objectID": "imglib2/changes-from-imglib1.html",
    "href": "imglib2/changes-from-imglib1.html",
    "title": "Changes from ImgLib1 to ImgLib2",
    "section": "",
    "text": "warning\n\n\n\nthe content of this page has not been vetted since shifting away from MediaWiki. If you’d like to help, check out the how to help guide!\nAt the Madison hackathon, quite a lot has been done about design issues of the originally published ImgLib (which was already the 6th generation). Unfortunately, these improvements were not possible in a fully backwards-compatible manner.",
    "crumbs": [
      "Changes from ImgLib1 to ImgLib2"
    ]
  },
  {
    "objectID": "imglib2/changes-from-imglib1.html#where-is-the-image",
    "href": "imglib2/changes-from-imglib1.html#where-is-the-image",
    "title": "Changes from ImgLib1 to ImgLib2",
    "section": "Where is the Image?",
    "text": "Where is the Image?\n ImgLib2 interfaces for data collections in n-dimensional Euclidean space. The key feature is distinction between random access vs. iteration and real vs. integer coordinate access.’%}\nIn ImgLib, the Image class was a wrapper for a limited subset of possible meta-data and a Container that provided access to the actual pixels. The overwhelming majority of methods in both Image and Container were almost identical. Furthermore, implementing algorithms for Image limited their portability to situations where different meta-data or less meta-data was required or different strategies for pixel access were appropriate.}\n[Fig]]imglib2-data.png’ title=‘Fig. 1 ImgLib2 interfaces for data collections in n-dimensional Euclidean space. The key feature is distinction between random access vs. iteration and real vs. integer coordinate access.’%} In ImgLib, the Image class was a wrapper for a limited subset of possible meta-data and a Container that provided access to the actual pixels. The overwhelming majority of methods in both Image and Container were almost identical. Furthermore, implementing algorithms for Image limited their portability to situations where different meta-data or less meta-data was required or different strategies for pixel access were appropriate.\nIn ImgLib2, the Image class has been abandoned. Instead, there is a set of interfaces that describe how data elements (pixels) can be accessed. Fig. 2 shows a UML-diagram visualizing the interface inheritance graph. The most important interfaces are\n\nRandomAccessible, RealRandomAccessible\nIterableInterval, IterableRealInterval\n\nActual images that store pixels in a regular equidistant grid implement the Img interface that combines a reasonable subset of the above interfaces. The basic storage strategies like ArrayImg, CellImg, PlanarImg, ImagePlusImg or ListImg implement this interface and can be used directly without being wrapped into something else.\nOpposed to the intuitive shortcut that you would just replace Image by Img then, we suggest to consider implementing algorithms for the type of pixel access that you actually need. Iterating and localizing all pixels is possible with IterableRealInterval or IterableInterval, random access comes from RandomAccessible and RealRandomAccessible. That is, the Img interface is almost always a too strict constraint for the possible input, but usually a good choice for writing the result.",
    "crumbs": [
      "Changes from ImgLib1 to ImgLib2"
    ]
  },
  {
    "objectID": "imglib2/changes-from-imglib1.html#where-is-the-localizablecursor",
    "href": "imglib2/changes-from-imglib1.html#where-is-the-localizablecursor",
    "title": "Changes from ImgLib1 to ImgLib2",
    "section": "Where is the LocalizableCursor?",
    "text": "Where is the LocalizableCursor?\n{% include thumbnail src=‘imglib2-access.png’ title=‘Fig. 2 ImgLib2 interfaces for access to sample data and to real and integer coordinates in n-dimensional Euclidean space.’%} Iteration in ImgLib2 (as in ImgLib) implies constant and thus repeatable order. Therefore a Cursor can always localize itself, either by going the hard way and reasoning the position from it’s iteration index or by tracking the position per move. There is no extra interface required to distinguish this behavior but you can choose which Cursor to acquire by Iterable(Real)Interval.cursor() and Iterable(Real)Interval.localizingCursor(). Fig. 2 shows a UML-diagram visualizing the interface inheritance graph.\n{% include clear%}",
    "crumbs": [
      "Changes from ImgLib1 to ImgLib2"
    ]
  },
  {
    "objectID": "imglib2/changes-from-imglib1.html#where-is-the-localizablebydimcursor",
    "href": "imglib2/changes-from-imglib1.html#where-is-the-localizablebydimcursor",
    "title": "Changes from ImgLib1 to ImgLib2",
    "section": "Where is the LocalizableByDimCursor?",
    "text": "Where is the LocalizableByDimCursor?\nThe LocalizableByDimCursor was a combination of an iterator and random access. Combining these two concepts is a bad idea and so we split them. Random access is provided by classes implementing the interfaces RandomAccess or RealRandomAccess. You get them by RandomAccessible.randomAccess() or RealRandomAccessible.realRandomAccess() respectively. Fig. 2 shows a UML-diagram visualizing the interface inheritance graph.",
    "crumbs": [
      "Changes from ImgLib1 to ImgLib2"
    ]
  },
  {
    "objectID": "imglib2/changes-from-imglib1.html#how-does-imglib2-handle-outofbounds",
    "href": "imglib2/changes-from-imglib1.html#how-does-imglib2-handle-outofbounds",
    "title": "Changes from ImgLib1 to ImgLib2",
    "section": "How does ImgLib2 handle OutOfBounds?",
    "text": "How does ImgLib2 handle OutOfBounds?\nHandling out of bounds behavior is invariant to data storage. We have therefore moved it into the final implementations ExtendedRandomAccessibleInterval and ExtendedRealRandomAccessibleRealInterval. The usage is trivial as follows:\nExtendedRandomAccessibleInterval&lt; IntType, Img&lt; IntType&gt; &gt; extendedInterval =\n    new ExtendedRandomAccessibleInterval&lt; IntType, Img&lt; IntType &gt; &gt;(\n        myIntImg,\n        new OutOfBoundsMirrorFactory&lt; IntType, Img&lt; IntType &gt; &gt;( Boundary.DOUBLE ) );\nRandomAccess&lt; IntType &gt; randomAccess = extendedInterval.randomAccess();\nThat way, out of boundary location handling is available for all Intervals that are compatible with the passed OutOfBoundsFactory (the existing work for all RandomAccessible & Interval).\nA simple shortcut is to call:\nRandomAccessible&lt; IntType &gt; interval = Views.extend( myIntImg,\n     new OutOfBoundsMirrorFactory&lt; IntType, Img&lt; IntType &gt; &gt;( Boundary.DOUBLE ) );\nFor standard out of bounds strategies there are also static convenience methods:\n/* Mirroring Strategy where the last pixel is the mirror */\nRandomAccessible&lt; IntType &gt; interval = Views.extendMirrorSingle( myIntImg );\n\n/* Mirroring Strategy where the mirror lies behind the last pixel */\nRandomAccessible&lt; IntType &gt; interval = Views.extendMirrorDouble( myIntImg );\n\n/* Strategy where periodicity of the space is assumed (like FFT) */\nRandomAccessible&lt; IntType &gt; interval = Views.extendPeriodic( myIntImg );\n\n/* Strategy that returns a constant value outside the boundaries */\nRandomAccessible&lt; IntType &gt; interval = Views.extendValue( myIntImg, new IntType( 5 ) );\nThey placed in the Views class because it is a special view onto an Img or also any RandomAccessibleInterval.",
    "crumbs": [
      "Changes from ImgLib1 to ImgLib2"
    ]
  },
  {
    "objectID": "imglib2/changes-from-imglib1.html#where-did-the-neighborhoodcursor-and-regionofinterestcursor-go",
    "href": "imglib2/changes-from-imglib1.html#where-did-the-neighborhoodcursor-and-regionofinterestcursor-go",
    "title": "Changes from ImgLib1 to ImgLib2",
    "section": "Where did the NeighborhoodCursor and RegionOfInterestCursor go?",
    "text": "Where did the NeighborhoodCursor and RegionOfInterestCursor go?\nThey have been removed and will be replaced by a slightly different concept that was not possible in ImgLib before due to lack of appropriate interfaces. Both Neighborhood and HyperBox will implement IterableInterval and/or RandomAccessible. They will be provided by an IterableInterval&lt; Neighborhood &gt; or RandomAccessible&lt; HyperBox &gt; respectively (plus other combinations, and real variants).",
    "crumbs": [
      "Changes from ImgLib1 to ImgLib2"
    ]
  },
  {
    "objectID": "imglib2/changes-from-imglib1.html#where-is-the-chunk",
    "href": "imglib2/changes-from-imglib1.html#where-is-the-chunk",
    "title": "Changes from ImgLib1 to ImgLib2",
    "section": "Where is the Chunk?",
    "text": "Where is the Chunk?\nChunk was introduced as a way for parallel processing of independent sections on iterable data. We have replaced it by IterableIntervalSubset which is an IterableInterval itself and thus can be used transparently in all implementations using IterableInterval.",
    "crumbs": [
      "Changes from ImgLib1 to ImgLib2"
    ]
  },
  {
    "objectID": "imglib2/changes-from-imglib1.html#changes-within-imglib2",
    "href": "imglib2/changes-from-imglib1.html#changes-within-imglib2",
    "title": "Changes from ImgLib1 to ImgLib2",
    "section": "Changes within ImgLib2",
    "text": "Changes within ImgLib2\n\nImgCursor has been removed for being empty—simply use Cursor instead\nThe ImgOpener returns an ImgPlus, not an Img to store additional meta-data as retrieved through LOCI bioformats.",
    "crumbs": [
      "Changes from ImgLib1 to ImgLib2"
    ]
  },
  {
    "objectID": "imglib2/migrate-from-imglib1.html",
    "href": "imglib2/migrate-from-imglib1.html",
    "title": "How To Migrate Code From ImgLib To ImgLib2",
    "section": "",
    "text": "ImgLib2 is a major redesign of ImgLib, and much has changed. This page attempts to provide a “how-to” guide for bringing existing ImgLib1 code up to date with ImgLib2. It is intended as a “quick start” guide—for more details, see the Changes from ImgLib1 to ImgLib2 page.",
    "crumbs": [
      "How To Migrate Code From ImgLib To ImgLib2"
    ]
  },
  {
    "objectID": "imglib2/migrate-from-imglib1.html#rename-packages",
    "href": "imglib2/migrate-from-imglib1.html#rename-packages",
    "title": "How To Migrate Code From ImgLib To ImgLib2",
    "section": "Rename packages",
    "text": "Rename packages\nAll packages have changed prefix to avoid a name clash, and to conform to convention (imglib2.net now points to us):\n\nmpicbg.imglib → net.imglib2\n\nHence, it is easiest to perform a global search and replace for all instances of the old string with the new. This holds for all renames listed below.\nSome core packages have also changed further:\n\nmpicbg.imglib.image → net.imglib2.img",
    "crumbs": [
      "How To Migrate Code From ImgLib To ImgLib2"
    ]
  },
  {
    "objectID": "imglib2/migrate-from-imglib1.html#rename-classes",
    "href": "imglib2/migrate-from-imglib1.html#rename-classes",
    "title": "How To Migrate Code From ImgLib To ImgLib2",
    "section": "Rename classes",
    "text": "Rename classes\nIn general, the Image class has been replaced with Img. Many classes with “Image” in the name have thus been changed to “Img” instead:\n\nImage → Img\nImageFactory → ImgFactory\nImageOpener → ImgOpener\n\nPlease note that there are cases where using Img is not appropriate, and a better alternative exists; see the Changes from ImgLib1 to ImgLib2 page for a more complete explanation.",
    "crumbs": [
      "How To Migrate Code From ImgLib To ImgLib2"
    ]
  },
  {
    "objectID": "imglib2/migrate-from-imglib1.html#use-long-for-dimensional-lengths",
    "href": "imglib2/migrate-from-imglib1.html#use-long-for-dimensional-lengths",
    "title": "How To Migrate Code From ImgLib To ImgLib2",
    "section": "Use long for dimensional lengths",
    "text": "Use long for dimensional lengths\nAll dimensional lengths are now long (and long[]) instead of int (and int[]).",
    "crumbs": [
      "How To Migrate Code From ImgLib To ImgLib2"
    ]
  },
  {
    "objectID": "imglib2/migrate-from-imglib1.html#rename-dimensional-length-accessor-methods",
    "href": "imglib2/migrate-from-imglib1.html#rename-dimensional-length-accessor-methods",
    "title": "How To Migrate Code From ImgLib To ImgLib2",
    "section": "Rename dimensional length accessor methods",
    "text": "Rename dimensional length accessor methods\nIn addition, core methods for querying dimensional lengths have changed names:\n\ngetNumDimensions() → numDimensions()\ngetDimension(int) → dimension(int)\ngetDimensions() → dimensions(long[])\n\nFor dimensions(long[]), note that it only populates an existing array. There is no method to allocate and return a new dimensional array. Instead, use the following code:\nfinal long[] dims = new long[img.numDimensions()];\nimg.dimensions(dims);",
    "crumbs": [
      "How To Migrate Code From ImgLib To ImgLib2"
    ]
  },
  {
    "objectID": "imglib2/migrate-from-imglib1.html#remove-references-to-container-and-containerfactory",
    "href": "imglib2/migrate-from-imglib1.html#remove-references-to-container-and-containerfactory",
    "title": "How To Migrate Code From ImgLib To ImgLib2",
    "section": "Remove references to Container and ContainerFactory",
    "text": "Remove references to Container and ContainerFactory\nContainers are now built in to the Img. For instance, PlanarImg (an implementation of Img) replaces PlanarContainer. Essentially, ContainerFactory and ImageFactory have been combined into ImgFactory. If you have code that creates a Container or ContainerFactory, it is no longer necessary—just create the correct kind of Img or ImgFactory instead (e.g., PlanarImgFactory).",
    "crumbs": [
      "How To Migrate Code From ImgLib To ImgLib2"
    ]
  },
  {
    "objectID": "imglib2/migrate-from-imglib1.html#update-cursor-logic",
    "href": "imglib2/migrate-from-imglib1.html#update-cursor-logic",
    "title": "How To Migrate Code From ImgLib To ImgLib2",
    "section": "Update cursor logic",
    "text": "Update cursor logic\nThere were previously three types: Cursor, LocalizableCursor and LocalizableByDimCursor. This is still true, but the terminology has changed: a cursor can now be “localizable”—meaning you can tell where it is in the dimensional structure—and/or “positionable”—meaning you can move the cursor to somewhere else. Essentially, the three kinds of cursors are now:\n\nimg.cursor() – returns a Cursor with “read-only” access to the dimensional position which is calculated on demand which might be an expensive calculation. Use when you don’t care where you are in the structure (or only sparsely need this information), and want the most efficient path.\nimg.localizingCursor() – returns a Cursor with “read-only” access to the dimensional position. Such Cursors track their position at each fwd() call and thus can calculate it more efficiently than the above. Use when you always or often need to know where the cursor currently sits, but don’t need to change the position other than normal iteration.\nimg.randomAccess() – returns a RandomAccess with “read-write” access to the dimensional position. Use when you need to change the position.\n\nAnother way of looking at it is that Cursors are similar to InputStreams and must go forward, whereas RandomAccesses are similar to RandomAccessFiles and can seek back and forth at will.",
    "crumbs": [
      "How To Migrate Code From ImgLib To ImgLib2"
    ]
  },
  {
    "objectID": "imglib2/migrate-from-imglib1.html#update-out-of-bounds-code",
    "href": "imglib2/migrate-from-imglib1.html#update-out-of-bounds-code",
    "title": "How To Migrate Code From ImgLib To ImgLib2",
    "section": "Update out of bounds code",
    "text": "Update out of bounds code\nOut of bounds access is now handled differently. Previously you could pass an out of bounds strategy factory to a localizable cursor constructor. In a similar fashion now you extend an interval with an out of bounds strategy factory.\nHere is an example:\nExtendedRandomAccessibleInterval&lt; IntType, Img&lt; IntType&gt; &gt; extendedInterval =\n  new ExtendedRandomAccessibleInterval&lt; IntType, Img&lt; IntType &gt; &gt;(\n      myIntImg,\n      new OutOfBoundsMirrorFactory&lt; IntType, Img&lt; IntType &gt; &gt;( Boundary.DOUBLE ) );\nRandomAccess&lt; IntType &gt; randomAccess = extendedInterval.randomAccess();",
    "crumbs": [
      "How To Migrate Code From ImgLib To ImgLib2"
    ]
  },
  {
    "objectID": "imglib2/migrate-from-imglib1.html#rename-rgblegacytype-to-argbtype",
    "href": "imglib2/migrate-from-imglib1.html#rename-rgblegacytype-to-argbtype",
    "title": "How To Migrate Code From ImgLib To ImgLib2",
    "section": "Rename RGBLegacyType to ARGBType",
    "text": "Rename RGBLegacyType to ARGBType\nIf you were using RGBALegacyType, note that it has changed to ARGBType, but serves the same purpose.",
    "crumbs": [
      "How To Migrate Code From ImgLib To ImgLib2"
    ]
  },
  {
    "objectID": "imglib2/migrate-from-imglib1.html#use-net.imglib2.display.projector-instead-of-mpicbg.imglib.image.display.display",
    "href": "imglib2/migrate-from-imglib1.html#use-net.imglib2.display.projector-instead-of-mpicbg.imglib.image.display.display",
    "title": "How To Migrate Code From ImgLib To ImgLib2",
    "section": "Use net.imglib2.display.Projector instead of mpicbg.imglib.image.display.Display",
    "text": "Use net.imglib2.display.Projector instead of mpicbg.imglib.image.display.Display\nThe Display class and corresponding packages are no longer applicable to ImgLib2. Instead, create a Projector.",
    "crumbs": [
      "How To Migrate Code From ImgLib To ImgLib2"
    ]
  },
  {
    "objectID": "imglib2/migrate-from-imglib1.html#additional-issues",
    "href": "imglib2/migrate-from-imglib1.html#additional-issues",
    "title": "How To Migrate Code From ImgLib To ImgLib2",
    "section": "Additional issues",
    "text": "Additional issues\nThe RegionOfInterestCursor class is no longer available and its replacement is not yet in place. You’ll need to work around this in the short term.\nThe Image.clone() method has been now named Img.copy().",
    "crumbs": [
      "How To Migrate Code From ImgLib To ImgLib2"
    ]
  },
  {
    "objectID": "imglib2/gauss-package.html",
    "href": "imglib2/gauss-package.html",
    "title": "Gauss package for ImgLib2",
    "section": "",
    "text": "The gauss package for ImgLib2 is an generic, optimized implementation of the traditional Gaussian convolution. It can perform anisotropic, n-dimensional convolution on any image or any interval on an image, if required even in-place.\nThe computation is performed multi-threaded and accesses each pixel of the input and output containers only once to guarantee high performance, even on paged cell containers. The precision of the computation can be of any ImgLib2 NumericType, however, there are more efficient implementations for convolution with float and double precision. Any precision of gaussian convolution can be computed on any type of real valued input data, it will be internally wrapped to either float or double. For other conversions (e.g. perform a gaussian convolution on complex float data with complex double precision) respective converters need to be provided. However, any NumericType can always be convolved with its own precision. Warning: this might reduce the accuracy of the computation significantly if the Type itself is an integer type.\n\n\n\nThe Gauss package for ImgLib2 consists of several classes which abstract the convolution operations to n dimensions. The developer/user should use the static methods provided in the Gauss.java class. It will determine itself which class should be used with which parameters in order to provide the best performance possible.\n\n\nFor computing a Gaussian convolution on an entire Img, simply call one the following lines of code:\nimport net.imglib2.algorithm.gauss.Gauss;\n\n// the source\nfinal Img&lt; T &gt; img = ...\n\n// define the sigma for each dimension\nfinal double[] sigma = new double[ img.numDimensions() ];\nfor ( int d = 0; d &lt; sigma.length; ++d )\n    sigma[ d ] = 1 + d;\n\n//\n// float-precision\n//\n// compute with float precision, but on T\nfinal Img&lt; T &gt; convolved = Gauss.inFloat( sigma, img );\n\n// compute with float precision, and output a FloatType Img\nfinal Img&lt; FloatType &gt; convolved = Gauss.toFloat( sigma, img );\n\n// compute with float precision in-place\nGauss.inFloatInPlace( sigma, img );\n\n//\n// double-precision\n//\n// compute with double precision, but on T\nfinal Img&lt; T &gt; convolved = Gauss.inDouble( sigma, img );\n\n// compute with double precision, and output a FloatType Img\nfinal Img&lt; DoubleType &gt; convolved = Gauss.toDouble( sigma, img );\n\n// compute with double precision in-place\nGauss.inDoubleInPlace( sigma, img );\n\n//\n// precision defined by the type T itself (this will produce garbage if T has insufficient range \n// or accuracy like ByteType, IntType, etc, but will work nicely on for example ComplexFloatType)\n//\n// compute with precision of T\nfinal Img&lt; T &gt; convolved = Gauss.inNumericType( sigma, img );\n\n// compute with precision of T in-place\nGauss.inNumericTypeInPlace( sigma, img );\nBy default, the Gaussian convolution will use the OutOfBoundsMirrorFactory with single boundary. If another OutOfBoundsFactory is desired, it can be defined on any of those methods as follows:\n// compute with float precision, but on T using an periodic (FFT-like) strategy where at the end of\n// each dimension the image simply starts again\nfinal Img&lt; T &gt; convolved = Gauss.inFloat( sigma, img, \n  new OutOfBoundsPeriodicFactory&lt;FloatType, RandomAccessibleInterval&lt;FloatType&gt;&gt;() ) );\n\n\n\nFor more advanced use of the Gaussian convolution, it accepts RandomAccessibles as input and output, too. In this way the developer has complete freedom which area to convolve and where to write the result. The input and output can be any RandomAccessible, i.e. also any kind of transformed View or Type.\nTo perform a Gaussian convolution on RandomAccessible you need to specify more input variables:\n\nthe sigma in each dimension\nthe input RandomAccessible (has to cover all the area required for the convolution, you might need to use Views.extend( … ) if it is too small\nthe Interval in which the Randomaccessible should be convolved. Note that more pixels around this area are required to perform the convolution, see implementation\nthe output RandomAccessible specifies the target, i.e. where the result will be written to (can be the same as the input)\nthe Location in the output RandomAccessible defines where the content will be inserted\nan ImageFactory for creating the temporary images, it has to be of the type in which the computation is performed. If it is inFloat, it will require an ImgFactory, inDouble will require ImgFactory and inNumericType needs an ImageFactory\n\nAn example on how to call the most generic version of the Gaussian convolution can be found below in the examples section.\n\n\n\n// create a new, empty 2-d image\nfinal ArrayImgFactory&lt;FloatType&gt; factory = new ArrayImgFactory&lt;FloatType&gt;();\nfinal Img&lt;FloatType&gt; img = factory.create( new int[]{ 512, 256 }, new FloatType() );\n\n// fill it with some funny content          \nint i = 0;\nfor ( final FloatType f : img )\n    f.set( i++ );\n            \nfor ( final FloatType f : img )\n    if ( i++ % 7 == 0 || i % 8 == 0 )\n        f.set( f.get() * 1.5f );\n\n// show the input           \nImageJFunctions.show( img );\n\n// define the 2-d sigmas\nfinal double[] sigma = new double[] { 2, 0.75 };\n\n// compute a gauss convolution with double precision\nImageJFunctions.show( Gauss.inDouble( sigma, img ) );   \n\n// compute a Gaussian convolution in-place in a small Interval  \nGauss.inFloat( sigma, Views.extendMirrorSingle( img ), new FinalInterval( new long[]{300,150},\n    new long[]{ 400,200 } ), img, new Location( new long[] {300,150} ), img.factory() );\n\n// show the result\nImageJFunctions.show( img );\nAnother nice example of the generality of the gaussian convolution is the Game of Death 2 which uses Gaussian convolution to simulate diffusion of different species of viruses. It redefines the add() operator of our new NumericType called LifeForm which can then be used to start the simulation. The Game of Death 2 is included in the imglib repository.\n\n\n\n\nThe first (obvious) core idea of the implementation is to break down the convolution into one-dimensional convolutions along each dimension. In order to properly convolve all input data, a continuously decreasing area has to be convolved when going along each dimension (see figure). This is necessary as the input for dimension d+1 has to be convolved in dimension d in order to produce the correct result.\nThe second core idea is to not iterate over the output but over the input to save operations and access the input as little as possible as it might be an expensive operation (page cell container, renderer, …). Furthermore, the symmetry of the gauss kernel allows to skip almost half of all operations as each input pixel contributes left and right of itself with with the same weight. This, however, includes a more complicated logic, special cases at the beginning and end of each line, as well as different operations if the kernel is larger than the convolved image.\nFor more details please refer to the source code for now, it is linked on top of this page.\n{% include img src=“gauss” width=“780” caption=“Visualizes the offsets and sizes required to perform an n-dimensional gaussian convolution” %}",
    "crumbs": [
      "Gauss package for ImgLib2"
    ]
  },
  {
    "objectID": "imglib2/gauss-package.html#purpose",
    "href": "imglib2/gauss-package.html#purpose",
    "title": "Gauss package for ImgLib2",
    "section": "",
    "text": "The gauss package for ImgLib2 is an generic, optimized implementation of the traditional Gaussian convolution. It can perform anisotropic, n-dimensional convolution on any image or any interval on an image, if required even in-place.\nThe computation is performed multi-threaded and accesses each pixel of the input and output containers only once to guarantee high performance, even on paged cell containers. The precision of the computation can be of any ImgLib2 NumericType, however, there are more efficient implementations for convolution with float and double precision. Any precision of gaussian convolution can be computed on any type of real valued input data, it will be internally wrapped to either float or double. For other conversions (e.g. perform a gaussian convolution on complex float data with complex double precision) respective converters need to be provided. However, any NumericType can always be convolved with its own precision. Warning: this might reduce the accuracy of the computation significantly if the Type itself is an integer type.",
    "crumbs": [
      "Gauss package for ImgLib2"
    ]
  },
  {
    "objectID": "imglib2/gauss-package.html#documentation",
    "href": "imglib2/gauss-package.html#documentation",
    "title": "Gauss package for ImgLib2",
    "section": "",
    "text": "The Gauss package for ImgLib2 consists of several classes which abstract the convolution operations to n dimensions. The developer/user should use the static methods provided in the Gauss.java class. It will determine itself which class should be used with which parameters in order to provide the best performance possible.\n\n\nFor computing a Gaussian convolution on an entire Img, simply call one the following lines of code:\nimport net.imglib2.algorithm.gauss.Gauss;\n\n// the source\nfinal Img&lt; T &gt; img = ...\n\n// define the sigma for each dimension\nfinal double[] sigma = new double[ img.numDimensions() ];\nfor ( int d = 0; d &lt; sigma.length; ++d )\n    sigma[ d ] = 1 + d;\n\n//\n// float-precision\n//\n// compute with float precision, but on T\nfinal Img&lt; T &gt; convolved = Gauss.inFloat( sigma, img );\n\n// compute with float precision, and output a FloatType Img\nfinal Img&lt; FloatType &gt; convolved = Gauss.toFloat( sigma, img );\n\n// compute with float precision in-place\nGauss.inFloatInPlace( sigma, img );\n\n//\n// double-precision\n//\n// compute with double precision, but on T\nfinal Img&lt; T &gt; convolved = Gauss.inDouble( sigma, img );\n\n// compute with double precision, and output a FloatType Img\nfinal Img&lt; DoubleType &gt; convolved = Gauss.toDouble( sigma, img );\n\n// compute with double precision in-place\nGauss.inDoubleInPlace( sigma, img );\n\n//\n// precision defined by the type T itself (this will produce garbage if T has insufficient range \n// or accuracy like ByteType, IntType, etc, but will work nicely on for example ComplexFloatType)\n//\n// compute with precision of T\nfinal Img&lt; T &gt; convolved = Gauss.inNumericType( sigma, img );\n\n// compute with precision of T in-place\nGauss.inNumericTypeInPlace( sigma, img );\nBy default, the Gaussian convolution will use the OutOfBoundsMirrorFactory with single boundary. If another OutOfBoundsFactory is desired, it can be defined on any of those methods as follows:\n// compute with float precision, but on T using an periodic (FFT-like) strategy where at the end of\n// each dimension the image simply starts again\nfinal Img&lt; T &gt; convolved = Gauss.inFloat( sigma, img, \n  new OutOfBoundsPeriodicFactory&lt;FloatType, RandomAccessibleInterval&lt;FloatType&gt;&gt;() ) );\n\n\n\nFor more advanced use of the Gaussian convolution, it accepts RandomAccessibles as input and output, too. In this way the developer has complete freedom which area to convolve and where to write the result. The input and output can be any RandomAccessible, i.e. also any kind of transformed View or Type.\nTo perform a Gaussian convolution on RandomAccessible you need to specify more input variables:\n\nthe sigma in each dimension\nthe input RandomAccessible (has to cover all the area required for the convolution, you might need to use Views.extend( … ) if it is too small\nthe Interval in which the Randomaccessible should be convolved. Note that more pixels around this area are required to perform the convolution, see implementation\nthe output RandomAccessible specifies the target, i.e. where the result will be written to (can be the same as the input)\nthe Location in the output RandomAccessible defines where the content will be inserted\nan ImageFactory for creating the temporary images, it has to be of the type in which the computation is performed. If it is inFloat, it will require an ImgFactory, inDouble will require ImgFactory and inNumericType needs an ImageFactory\n\nAn example on how to call the most generic version of the Gaussian convolution can be found below in the examples section.\n\n\n\n// create a new, empty 2-d image\nfinal ArrayImgFactory&lt;FloatType&gt; factory = new ArrayImgFactory&lt;FloatType&gt;();\nfinal Img&lt;FloatType&gt; img = factory.create( new int[]{ 512, 256 }, new FloatType() );\n\n// fill it with some funny content          \nint i = 0;\nfor ( final FloatType f : img )\n    f.set( i++ );\n            \nfor ( final FloatType f : img )\n    if ( i++ % 7 == 0 || i % 8 == 0 )\n        f.set( f.get() * 1.5f );\n\n// show the input           \nImageJFunctions.show( img );\n\n// define the 2-d sigmas\nfinal double[] sigma = new double[] { 2, 0.75 };\n\n// compute a gauss convolution with double precision\nImageJFunctions.show( Gauss.inDouble( sigma, img ) );   \n\n// compute a Gaussian convolution in-place in a small Interval  \nGauss.inFloat( sigma, Views.extendMirrorSingle( img ), new FinalInterval( new long[]{300,150},\n    new long[]{ 400,200 } ), img, new Location( new long[] {300,150} ), img.factory() );\n\n// show the result\nImageJFunctions.show( img );\nAnother nice example of the generality of the gaussian convolution is the Game of Death 2 which uses Gaussian convolution to simulate diffusion of different species of viruses. It redefines the add() operator of our new NumericType called LifeForm which can then be used to start the simulation. The Game of Death 2 is included in the imglib repository.",
    "crumbs": [
      "Gauss package for ImgLib2"
    ]
  },
  {
    "objectID": "imglib2/gauss-package.html#implementation",
    "href": "imglib2/gauss-package.html#implementation",
    "title": "Gauss package for ImgLib2",
    "section": "",
    "text": "The first (obvious) core idea of the implementation is to break down the convolution into one-dimensional convolutions along each dimension. In order to properly convolve all input data, a continuously decreasing area has to be convolved when going along each dimension (see figure). This is necessary as the input for dimension d+1 has to be convolved in dimension d in order to produce the correct result.\nThe second core idea is to not iterate over the output but over the input to save operations and access the input as little as possible as it might be an expensive operation (page cell container, renderer, …). Furthermore, the symmetry of the gauss kernel allows to skip almost half of all operations as each input pixel contributes left and right of itself with with the same weight. This, however, includes a more complicated logic, special cases at the beginning and end of each line, as well as different operations if the kernel is larger than the convolved image.\nFor more details please refer to the source code for now, it is linked on top of this page.\n{% include img src=“gauss” width=“780” caption=“Visualizes the offsets and sizes required to perform an n-dimensional gaussian convolution” %}",
    "crumbs": [
      "Gauss package for ImgLib2"
    ]
  },
  {
    "objectID": "imglib2/faq.html",
    "href": "imglib2/faq.html",
    "title": "ImgLib2 FAQ",
    "section": "",
    "text": "It is a library that helps you to implement algorithms for multi-dimensional data processing. The idea is that you can concentrate on the essence of your algorithm rather than syntactic sugar. It is possible to implement an algorithm without specifying what the image’s data type is, how many dimensions it has, and how the image is stored.\nImgLib2 is also the foundation of the ImageJ2 data model.",
    "crumbs": [
      "ImgLib2 FAQ"
    ]
  },
  {
    "objectID": "imglib2/faq.html#what-is-imglib2-anyway",
    "href": "imglib2/faq.html#what-is-imglib2-anyway",
    "title": "ImgLib2 FAQ",
    "section": "",
    "text": "It is a library that helps you to implement algorithms for multi-dimensional data processing. The idea is that you can concentrate on the essence of your algorithm rather than syntactic sugar. It is possible to implement an algorithm without specifying what the image’s data type is, how many dimensions it has, and how the image is stored.\nImgLib2 is also the foundation of the ImageJ2 data model.",
    "crumbs": [
      "ImgLib2 FAQ"
    ]
  },
  {
    "objectID": "imglib2/faq.html#how-do-i-migrate-my-imglib1-code-to-imglib2",
    "href": "imglib2/faq.html#how-do-i-migrate-my-imglib1-code-to-imglib2",
    "title": "ImgLib2 FAQ",
    "section": "How do I migrate my ImgLib1 code to ImgLib2?",
    "text": "How do I migrate my ImgLib1 code to ImgLib2?\nThere is some rudimentary documentation, but you will most likely need to ask more detailed questions on the ImageJ Forum.",
    "crumbs": [
      "ImgLib2 FAQ"
    ]
  },
  {
    "objectID": "imglib2/faq.html#how-to-create-a-new-image-from-scratch",
    "href": "imglib2/faq.html#how-to-create-a-new-image-from-scratch",
    "title": "ImgLib2 FAQ",
    "section": "How to create a new image from scratch?",
    "text": "How to create a new image from scratch?\nint w = 768, h = 512, timepoints = 20;\nImg&lt;FloatType&gt; img = ArrayImgs.floats(w, h, timepoints);",
    "crumbs": [
      "ImgLib2 FAQ"
    ]
  },
  {
    "objectID": "imglib2/accessors.html",
    "href": "imglib2/accessors.html",
    "title": "ImgLib2 - Accessors",
    "section": "",
    "text": "In ImgLib2, images are manipulated using Accessors. For pixel images, you can think of an accessor as a movable reference to a pixel.\n\nYou can move it around the image (for example make it reference a pixel at specific coordinates).\nYou can de-reference it to get the pixel value.\nAnd of course, you can ask its current position.\n\nThe accessors provided by ImgLib2 typically implement Cursor or RandomAccess. Cursor and RandomAccess are aggregations of interfaces covering the above three points. A simplified UML diagram for the interface hierarchy is shown below. (The simplification is with respect to real-coordinate interfaces for continuous images that are left out for now.)\n\n\n\n“imglib2-accessors-simplified-integer”\n\n\nImgLib2 supports two basic access patterns:\n\nRandomAccess provides n-dimensional random access through the Positionable interface. It can be positioned at arbitrary integer coordinates.\nCursor provides iteration through the Iterator interface. It can be moved forward to visit all pixels of the image once.\n\nBoth, RandomAccess and Cursor implement the Sampler interface which allows to access pixel values. Both implement the Localizable interface which allows to retrieve the accessors current pixel coordinates. Both inherit (through Localizable) the EuclideanSpace interval which allows to get the number of dimensions of the image.\nNote, that Sampler, RandomAccess, and Cursor have a type paramer &lt;T&gt; that refers to the value type of the underlying image.",
    "crumbs": [
      "ImgLib2 - Accessors"
    ]
  },
  {
    "objectID": "imglib2/accessors.html#introduction",
    "href": "imglib2/accessors.html#introduction",
    "title": "ImgLib2 - Accessors",
    "section": "",
    "text": "In ImgLib2, images are manipulated using Accessors. For pixel images, you can think of an accessor as a movable reference to a pixel.\n\nYou can move it around the image (for example make it reference a pixel at specific coordinates).\nYou can de-reference it to get the pixel value.\nAnd of course, you can ask its current position.\n\nThe accessors provided by ImgLib2 typically implement Cursor or RandomAccess. Cursor and RandomAccess are aggregations of interfaces covering the above three points. A simplified UML diagram for the interface hierarchy is shown below. (The simplification is with respect to real-coordinate interfaces for continuous images that are left out for now.)\n\n\n\n“imglib2-accessors-simplified-integer”\n\n\nImgLib2 supports two basic access patterns:\n\nRandomAccess provides n-dimensional random access through the Positionable interface. It can be positioned at arbitrary integer coordinates.\nCursor provides iteration through the Iterator interface. It can be moved forward to visit all pixels of the image once.\n\nBoth, RandomAccess and Cursor implement the Sampler interface which allows to access pixel values. Both implement the Localizable interface which allows to retrieve the accessors current pixel coordinates. Both inherit (through Localizable) the EuclideanSpace interval which allows to get the number of dimensions of the image.\nNote, that Sampler, RandomAccess, and Cursor have a type paramer &lt;T&gt; that refers to the value type of the underlying image.",
    "crumbs": [
      "ImgLib2 - Accessors"
    ]
  },
  {
    "objectID": "imglib2/accessors.html#randomaccess",
    "href": "imglib2/accessors.html#randomaccess",
    "title": "ImgLib2 - Accessors",
    "section": "RandomAccess",
    "text": "RandomAccess\nRandomAccess provides n-dimensional random access through the Positionable interface. It can be used to access pixels at arbitrary integer coordinates. The following code uses a RandomAccess to draw some white pixels into an image.\nimport java.util.Random;\n\nimport net.imglib2.RandomAccess;\nimport net.imglib2.img.Img;\nimport net.imglib2.img.array.ArrayImgFactory;\nimport net.imglib2.img.display.imagej.ImageJFunctions;\nimport net.imglib2.type.numeric.integer.UnsignedByteType;\n\npublic class DrawWhitePixels\n{\n    public static void main( final String[] args )\n    {\n        final int[] dimensions = new int[] { 400, 320 };\n        final Img&lt; UnsignedByteType &gt; img = new ArrayImgFactory&lt; UnsignedByteType &gt;()\n            .create( dimensions, new UnsignedByteType() );\n\n        final RandomAccess&lt; UnsignedByteType &gt; r = img.randomAccess();\n        final Random random = new Random();\n        for ( int i = 0; i &lt; 1000; ++i )\n        {\n            final int x = ( int ) ( random.nextFloat() * img.max( 0 ) );\n            final int y = ( int ) ( random.nextFloat() * img.max( 1 ) );\n            r.setPosition( x, 0 );\n            r.setPosition( y, 1 );\n            final UnsignedByteType t = r.get();\n            t.set( 255 );\n        }\n\n        ImageJFunctions.show( img );\n    }\n}\nIn lines 013-015 we create a 8-bit gray-level image, in line 029 we show the result (like in the previous example).\nIn line 017 we create a RandomAccess to the image. Img implements the RandomAccessible interface, thus we can use randomAccess() to obtain one. The RandomAccess has the same generic type, UnsignedByteType, as the image.\nfinal RandomAccess&lt; UnsignedByteType &gt; r = img.randomAccess();\nIn the for loop (lines 019-027) we set 1000 random pixels to the value 255 (white). First we obtain the x, y coordinates of a random pixel within the image boundaries.\nfinal int x = ( int ) ( random.nextFloat() * img.max( 0 ) );\nfinal int y = ( int ) ( random.nextFloat() * img.max( 1 ) );\nThen we position the RandomAccess at those coordinates.\nr.setPosition( x, 0 );\nr.setPosition( y, 1 );\nThe setPosition() method (from the Positionable interface) takes two parameters: the coordinate and the dimension. So we set the coordinate in dimension 0 to the value x, and we set the coordinate in dimension 1 to the value y.\nAfter the RandomAccess has been positioned correctly, we can get() the pixel at that coordinate.\nfinal UnsignedByteType t = r.get();\nWe get an instance of the pixel value type UnsignedByteType that acts as a reference to the pixel. We set the pixel value via this reference\nt.set( 255 );\n\nNotes\n\nget() is defined in the Sampler interface, so you can obtain pixel references from a Cursor in exactly the same way.\nOften, the T obtained from Sampler&lt;T&gt;.get() is a proxy object that is re-used internally. You should assume that moving the accessor invalidates the proxy. If you want to keep a permanent reference to a pixel, use the Sampler&lt;T&gt;.copy() method. In the above example, this would return a copy of the RandomAccess refering to the same pixel.\nThe Positionable, Localizable, … interfaces are not restricted to accessors. In fact, many ImgLib2 entities are Localizable. For instance, the Point class implements Positionable and Localizable, and simply represents a n-dimensional coordinate. In your own code, whenever you have something that can provide coordinates, you should consider implementing Localizable.",
    "crumbs": [
      "ImgLib2 - Accessors"
    ]
  },
  {
    "objectID": "imglib2/accessors.html#a-taste-of-generic-algorithms",
    "href": "imglib2/accessors.html#a-taste-of-generic-algorithms",
    "title": "ImgLib2 - Accessors",
    "section": "A Taste of Generic Algorithms",
    "text": "A Taste of Generic Algorithms\nBefore we move on to the “other” accessor, Cursor, let’s consider a generalization of the previous example. Let’s say we like setting random pixels, and because we plan to do this a lot in the future, we extract this functionality into a method.\nEasy enough. But what if we want to apply the method to images of another value type, e.g. DoubleType or ARGBType? What if we want to apply it to a 3D image? ImgLib2 allows you to write code that handles of this transparently. In the following we write a function, that sets 1000 random pixels to “white”, no matter what.\nLet’s take it step by step, starting from the original non-generic version. First, we extract a set-1000-pixels method for 2D Img&lt;UnsignedByteType&gt;.\npublic static void draw( final Img&lt; UnsignedByteType &gt; img )\n{\n    final RandomAccess&lt; UnsignedByteType &gt; r = img.randomAccess();\n    final Random random = new Random();\n    for ( int i = 0; i &lt; 1000; ++i )\n    {\n        final int x = ( int ) ( random.nextFloat() * img.max( 0 ) );\n        final int y = ( int ) ( random.nextFloat() * img.max( 1 ) );\n        r.setPosition( x, 0 );\n        r.setPosition( y, 1 );\n        final UnsignedByteType t = r.get();\n        t.set( 255 );\n    }\n}\nWe can add a generic parameter to the method handle arbitrary value types T. We want something like\npublic static &lt; T &gt; void draw( final Img&lt; T &gt; img )\n{ ... }\nHowever, for a generic T, we no longer know what “white” is. 255 will certainly not do. So we need to pass the “white” value into the method.\npublic static &lt; T &gt; void draw( final Img&lt; T &gt; img, final T white )\n{ ... }\nFurthermore, we need a way to set a pixel to this value. Note, that the Sampler.get() method provides a reference to the pixel. Changing that reference won’t do any good, and there is no Sampler.set() method! We need to ensure that we can use the reference to change the pixel value.\nAt the root of the ImgLib2 type hierarchy lies Type. A type T extending Type&lt;T&gt; must have a set( T ) method, which is exactly what we need. So we make our method only accept those T’s.\npublic static &lt; T extends Type&lt; T &gt; &gt; void draw( final Img&lt; T &gt; img, final T white )\n{ ... }\nReplacing the UnsignedByteType with the generic T, and using white instead of 255, we obtain a more general version of draw().\npublic class DrawWhitePixelsGeneric\n{\n    public static &lt; T extends Type&lt; T &gt; &gt; void draw( final Img&lt; T &gt; img, final T white )\n    {\n        final RandomAccess&lt; T &gt; r = img.randomAccess();\n        final Random random = new Random();\n        for ( int i = 0; i &lt; 1000; ++i )\n        {\n            final int x = ( int ) ( random.nextFloat() * img.max( 0 ) );\n            final int y = ( int ) ( random.nextFloat() * img.max( 1 ) );\n            r.setPosition( x, 0 );\n            r.setPosition( y, 1 );\n            final T t = r.get();\n            t.set( white );\n        }\n    }\n\n    public static void main( final String[] args )\n    {\n        final int[] dimensions = new int[] { 400, 320 };\n        final Img&lt; UnsignedByteType &gt; img = new ArrayImgFactory&lt; UnsignedByteType &gt;()\n            .create( dimensions, new UnsignedByteType() );\n        draw( img, new UnsignedByteType( 255 ) );\n        ImageJFunctions.show( img );\n    }\n}\nNote, that we have to pass new UnsignedByteType( 255 ) when calling draw().\nNext, lets think about dimensionality independence. Instead of setPosition() for just dimensions 0 and 1, we can do so for as many dimensions as the image happens to have. We get the number of dimensions using\nfinal int n = img.numDimensions();\n(Img also extends EuclideanSpace).\nWe loop over all dimensions when setting the position of the RandomAccess:\nfor ( int d = 0; d &lt; n; ++d )\n{\n    final int x = ( int ) ( random.nextFloat() * img.max( d ) );\n    r.setPosition( x, d );\n}\nSetting the position dimension-by-dimension may be inefficient, because the RandomAccess might need to modify internal state with each setPosition() call. Instead, we may pass a int[] or long[] array comprising the coordinates to set the position at once.\nNow the method looks like this:\npublic static &lt; T extends Type&lt; T &gt; &gt; void draw( final Img&lt; T &gt; img, final T white )\n{\n    final int n = img.numDimensions();\n    final long[] pos = new long[ n ];\n\n    final RandomAccess&lt; T &gt; r = img.randomAccess();\n    final Random random = new Random();\n    for ( int i = 0; i &lt; 1000; ++i )\n    {\n        for ( int d = 0; d &lt; n; ++d )\n            pos[ d ] = ( int ) ( random.nextFloat() * img.max( d ) );\n        r.setPosition( pos );\n        final T t = r.get();\n        t.set( white );\n    }\n}\nFinally, there is no need to restrict ourselves to Img. After all, we do not need many of the features of Img. We need be able to get a RandomAccess, so we need RandomAccessible&lt;T&gt;. We need to be able to get the number of dimensions and the extent in every dimension, so we need Interval. These two are conveniently gathered in RandomAccessibleInterval&lt;T&gt;. So lets make that\npublic static &lt; T extends Type&lt; T &gt; &gt;\n    void draw( final RandomAccessibleInterval&lt; T &gt; img, final T white )\n{ ... }\nNow we are able to apply draw() to many ImgLib2 constructs that are not pixel Imgs. For instance there are Views that employ on-the-fly coordinate transforms, sampled and interpolated data, etc.\nHowever, with great power comes great responsibility… Taking a general Interval means that we no longer can assume that the interval starts at coordinates (0,0,…,0). Thus we need to make a final modification to correctly draw between min and max of the interval.\nimport java.util.Random;\n\nimport net.imglib2.RandomAccess;\nimport net.imglib2.RandomAccessibleInterval;\nimport net.imglib2.img.Img;\nimport net.imglib2.img.array.ArrayImgFactory;\nimport net.imglib2.img.display.imagej.ImageJFunctions;\nimport net.imglib2.type.Type;\nimport net.imglib2.type.numeric.ARGBType;\nimport net.imglib2.type.numeric.integer.IntType;\nimport net.imglib2.type.numeric.integer.UnsignedByteType;\n\npublic class DrawWhitePixelsGeneric\n{\n    public static &lt; T extends Type&lt; T &gt; &gt;\n        void draw( final RandomAccessibleInterval&lt; T &gt; img, final T white )\n    {\n        final int n = img.numDimensions();\n        final long[] min = new long[ n ];\n        img.min( min );\n        final long[] scale = new long[ n ];\n        for ( int d = 0; d &lt; n; ++d )\n            scale[ d ] = img.max( d ) - min[ d ];\n        final long[] pos = new long[ n ];\n\n        final RandomAccess&lt; T &gt; r = img.randomAccess();\n        final Random random = new Random();\n        for ( int i = 0; i &lt; 1000; ++i )\n        {\n            for ( int d = 0; d &lt; n; ++d )\n                pos[ d ] = min[ d ] + ( long ) ( random.nextFloat() * scale[ d ] );\n            r.setPosition( pos );\n            r.get().set( white );\n        }\n    }\n\n    public static void main( final String[] args )\n    {\n        final Img&lt; ARGBType &gt; img = new ArrayImgFactory&lt; ARGBType &gt;()\n            .create( new int[] {400, 320, 100}, new ARGBType() );\n        draw( img, new ARGBType( 0xffffffff ) );\n        ImageJFunctions.show( img );\n    }\n}\nAnd we used it on a 3D ARGBType image (which means a color image with red/green/blue/alpha values). Ta daaaaaa…\n\nNotes\n\nBesides setPosition() in a single or all dimensions, you can also relatively move a RandomAccess in one or all dimensions, or move the RandomAccess pixel-wise in one dimension (Have a look at the Positionable API doc!) Which of those is most efficient depends on the situation.\nThere is a setPosition() version which takes a Localizable. Often a situation occurs where you want to position accessor a to the same location as accessor b. In this situation you can avoid localizing b into an array and using that array to set the position of a. You can simply a.setPosition( b ) because b is Localizable.\nBy image, we do not necessarily mean pixel image.\nwe use the generic parameter &lt; T extends Type&lt; T &gt; &gt; instead of &lt; Type &gt; throughout ImgLib2 since that allows us to be more type-safe. Imagine implementing an add(a, b) method for a certain type: using the simpler generic parameter would not allow us to enforce both parameters to have the same subclass of Type!\nwe create as many variables as possible outside of the loop (in particular, objects) since creating objects costs a bit of execution time and can easily dominate the performance of the algorithm if one is not careful about it.",
    "crumbs": [
      "ImgLib2 - Accessors"
    ]
  },
  {
    "objectID": "imglib2/accessors.html#cursor",
    "href": "imglib2/accessors.html#cursor",
    "title": "ImgLib2 - Accessors",
    "section": "Cursor",
    "text": "Cursor\nA Cursor can be used to visit all pixels of an image once. However, the Cursor concept is not limited to pixel images. A Cursor can be used to iterate every collection of Localizable samples.\nCursor provides iteration through the net.imglib2.Iterator interface. Iterator.fwd() advances the cursor. Iterator.hasNext() returns true if the cursor can be advanced further. Initially, a Cursor points before the first element. You have to call fwd() once to move to the first element.\nNote, that the ImgLib2 net.imglib2.Iterator interface is different from Java’s java.util.Iterator. However, for convenience, Cursor implements java.util.Iterator as well.\nJust like RandomAccess, Cursor extends Sampler, so you can get() the value of the current pixel (respectively sample). It also implements Localizable, so you can query the coordinates of the current sample.\nLet’s look at an example: We load an image and find the maximum value (the intensity of the brightest pixel).\nimport net.imglib2.Cursor;\nimport net.imglib2.img.Img;\nimport net.imglib2.img.array.ArrayImgFactory;\nimport net.imglib2.io.ImgIOException;\nimport net.imglib2.io.ImgOpener;\nimport net.imglib2.type.numeric.integer.UnsignedByteType;\n\npublic class FindMaximumValue\n{\n    public static void main( final String[] args ) throws ImgIOException\n    {\n        final Img&lt; UnsignedByteType &gt; img = new ImgOpener().openImg( \"graffiti.tif\",\n            new ArrayImgFactory&lt; UnsignedByteType &gt;(), new UnsignedByteType() );\n        final Cursor&lt; UnsignedByteType &gt; cursor = img.cursor();\n        int max = 0;\n        while ( cursor.hasNext() )\n        {\n            cursor.fwd();\n            final UnsignedByteType t = cursor.get();\n            max = Math.max( t.get(), max );\n        }\n        System.out.println( \"max = \" + max );\n    }\n}\nIn line 014 we get a Cursor from the image. In lines 016-021 we iterate the image using hasNext() and fwd(). In line 019 we get() the value at the current position. Again, this is an instance of the pixel value type UnsignedByteType that acts as a reference to the pixel.\nCursor implements java.util.Iterator which has the next() method. This is a combination of fwd() and get(). Instead of\ncursor.fwd();\nfinal UnsignedByteType t = cursor.get();\nwe could write\nfinal UnsignedByteType t = cursor.next();\nFor even more syntactic sugar, every IterableInterval (such as Img) implements java.lang.Iterable. This allows to use the Java for-each loop and replace the lengthy while loop like so:\nfor( UnsignedByteType t : img )\n    max = Math.max( t.get(), max );\nHowever, note that in this construct the Cursor is hidden and you can not use it to get the current location. Therefore, you will often use the while form.\nLet’s extend the previous example. Now we are also interested in the coordinates of the maximum. Cursor extends the Localizable interface which provides methods to get the current location either dimension-by-dimension or all at once. (Have a look at the Localizable API doc!)\nimport net.imglib2.Cursor;\nimport net.imglib2.img.Img;\nimport net.imglib2.img.array.ArrayImgFactory;\nimport net.imglib2.io.ImgIOException;\nimport net.imglib2.io.ImgOpener;\nimport net.imglib2.type.numeric.integer.UnsignedByteType;\n\npublic class FindMaximumValueAndLocation\n{\n    public static void main( final String[] args ) throws ImgIOException\n    {\n        final Img&lt; UnsignedByteType &gt; img = new ImgOpener().openImg( \"graffiti.tif\",\n            new ArrayImgFactory&lt; UnsignedByteType &gt;(), new UnsignedByteType() );\n        final Cursor&lt; UnsignedByteType &gt; cursor = img.cursor();\n        int max = 0;\n        final long[] pos = new long[2];\n        while ( cursor.hasNext() )\n        {\n            cursor.fwd();\n            final UnsignedByteType t = cursor.get();\n            if ( t.get() &gt; max )\n            {\n                max = t.get();\n                cursor.localize( pos );\n            }\n        }\n        System.out.println( \"max = \" + max );\n        System.out.println( \"found at ( \" + pos[0] + \", \" + pos[1] + \")\" );\n    }\n}\nIn line 016 we create a long[] position field which is updated (024) everytime a better max value is found. Here, we use a 2D position field, because we know, that the position is 2D.\n\nGeneric version\nLet’s look at a generic version of the maximum-finding example.\nimport net.imglib2.Cursor;\nimport net.imglib2.IterableInterval;\nimport net.imglib2.img.Img;\nimport net.imglib2.img.array.ArrayImgFactory;\nimport net.imglib2.io.ImgIOException;\nimport net.imglib2.io.ImgOpener;\nimport net.imglib2.type.Type;\nimport net.imglib2.type.numeric.integer.UnsignedByteType;\n\npublic class FindMaximumValueAndLocationGeneric\n{\n    public static &lt; T extends Comparable&lt; T &gt; &gt;\n            Cursor&lt; T &gt; findmax( final IterableInterval&lt; T &gt; iterable )\n    {\n        final Cursor&lt; T &gt; cursor = iterable.cursor();\n        cursor.fwd();\n        Cursor&lt; T &gt; max = cursor.copyCursor();\n        while ( cursor.hasNext() )\n            if ( cursor.next().compareTo( max.get() ) &gt; 0 )\n                max = cursor.copyCursor();\n        return max;\n    }\n\n    public static void main( final String[] args ) throws ImgIOException\n    {\n        final Img&lt; UnsignedByteType &gt; img = new ImgOpener().openImg( \"graffiti.tif\",\n            new ArrayImgFactory&lt; UnsignedByteType &gt;(), new UnsignedByteType() );\n        final Cursor&lt; UnsignedByteType &gt; max = findmax( img );\n        System.out.println( \"max = \" + max.get().get() );\n        System.out.println( \"found at ( \" + max.getLongPosition( 0 ) + \", \" +\n                                            max.getLongPosition( 1 ) + \")\" );\n    }\n}\nWe define the method findmax as\npublic static &lt; T extends Comparable&lt; T &gt; &gt;\n        Cursor&lt; T &gt; findmax( final IterableInterval&lt; T &gt; iterable )\nFirst, note that we do not take an Img&lt;T&gt; as the parameter, because that would be too restrictive. All we need is something that is iterable. Because we can easily put interval bounds on every iterable set of Localizables, ImgLib2 does not define an Iterable super-interface for IterableInterval. So IterableInterval is the most general we can go here.\nFor finding the maximum, the only restriction we have to put on type T is that it is comparable.\nThe return value of findmax is a Cursor&lt;T&gt;. Instead of creating a new class that represents a tuple of maximum value and coordinates, we simply return a Cursor positioned at the maximum.\nTo remember the maximum, we simply take a new copy of the iterating cursor whenever a better max value is found.\nif ( cursor.next().compareTo( max.get() ) &gt; 0 )\n    max = cursor.copyCursor();\nRemember that next() is equivalent to fwd() followed by get(). So, cursor.next() returns the current T.\nLines 028-031 show how to use findmax and get the maximum value and coordinates from the resulting Cursor. For a change, we used the dimension-by-dimension getLongPosition() of the Localizable interface.\n\n\nNotes\n\nThe iteration order is subject to implementation, specialized for each memory layout to minimize access time. For example, an ArrayImg has a different iteration order from a CellImg. This is nicely illustrated in ImgLib2 Example 2b - Duplicating an Img using a different ImgFactory.\nTypically, there are two variants of Cursors available. One that calculates its location per each iteration and one that calculates it only per localization request. The former is more efficient when localization occurs frequently, the latter otherwise. In the maximum-finding example, we use the latter because localization is only required once after the maximum has been found. The former one could be obtained using localizingCursor() instead of cursor() (see IterableInterval API doc.)\ncopyCursor() is a work-around to circumvent a javac bug with covariant return type overriding (see bug report). In the future (with JDK7) every Sampler can be copied using copy() instead of having specialised copyCursor(), copyRandomAccess(), … methods.",
    "crumbs": [
      "ImgLib2 - Accessors"
    ]
  },
  {
    "objectID": "imglib2/accessors.html#accessors-for-continuous-coordinates",
    "href": "imglib2/accessors.html#accessors-for-continuous-coordinates",
    "title": "ImgLib2 - Accessors",
    "section": "Accessors for Continuous Coordinates",
    "text": "Accessors for Continuous Coordinates\nImgLib2 is not restricted to rasterized images and integer coordinates It also supports continuous images and real-valued coordinates. Examples where this is appropriate are\n\nan interpolated image, where an interpolated value can be obtained at any real coordinate. Note that this is a bounded, but continuous image. Thus it is not iterable.\na procedurally generated image, where a value can be computed at any real coordinate (continuous, unbounded, non-iterable).\ncollections of samples taken at arbitrary real coordinates (discrete, bounded, iterable).\n\nThe following image shows the UML diagram for the ImgLib2 accessor interface hierarchy. The real-coordinate counterparts that were missing in the simplified version above are highlighted.\n\n\n\nUML for ImgLib2 accessor interfaces\n\n\nReal equivalents of the Positionable and Localizable interfaces have been added by which real-valued coordinates can be accessed.\nSomething that is RealPositionable can be positioned at real coordinates. There are methods to set absolute or relative position, for a single or all dimensions, in analogy to the integer Positionable. You can also set a RealPositionable to the location of a RealLocalizable. Note that RealPositionable extends Positionable, which is quite natural: Whenever something can be positioned at arbitrary real coordinates, of course it can be positioned to integer coordinates as well.\nRealLocalizable allows to get a real coordinate from an accessor. Again, this is completely analogous to the integer Localizable. In this case, the inheritance relationship is the other way around - Localizable extends RealLocalizable. Something that is able to provide its integer coordinates is always able to provide them as real coordinates too.\nIn Combination with Sampler, we obtain random-access and iteration accessor interfaces. RealRandomAccess provides n-dimensional random access through the RealPositionable interface. RealCursor provides iteration through the Iterator interface.\nBoth, RealRandomAccess and RealCursor are RealLocalizable. Note that the inheritance relationship of Localizable and RealLocalizable propagates to the cursors. Every Cursor is also a RealCursor (because it can provide its current integer coordinates as real coordinates as well). There is no such relationship between RandomAccess and RealRandomAccess.\n\nA RealRandomAccess to Render Mandelbrot Fractals\nLet’s look at an example. The following code defines a RealRandomAccess which computes the Mandelbrot set{% include wikipedia title=‘Mandelbrot set’ text=‘Mandelbrot set’%}. More precisely, our RealRandomAccess can be positioned at an arbitray 2D coordinate in the complex plane. When we get() its value, it computes an iteration count for its current position using an Mandelbrot set#Escape_time_algorithm {% include wikipedia title=‘Mandelbrot set#Escape_time_algorithm’ text=‘Escape time algorithm’%}\nimport net.imglib2.RealPoint;\nimport net.imglib2.RealRandomAccess;\nimport net.imglib2.type.numeric.integer.UnsignedByteType;\n\npublic class MandelbrotRealRandomAccess extends RealPoint\n        implements RealRandomAccess&lt; UnsignedByteType &gt;\n{\n    final UnsignedByteType t;\n\n    public MandelbrotRealRandomAccess()\n    {\n        super( 2 ); // number of dimensions is 2\n        t = new UnsignedByteType();\n    }\n\n    public static final int mandelbrot( final double re0, final double im0,\n            final int maxIterations )\n    {\n        double re = re0;\n        double im = im0;\n        int i = 0;\n        for ( ; i &lt; maxIterations; ++i )\n        {\n            final double squre = re * re;\n            final double squim = im * im;\n            if ( squre + squim &gt; 4 )\n                break;\n            im = 2 * re * im + im0;\n            re = squre - squim + re0;\n        }\n        return i;\n    }\n\n    @Override\n    public UnsignedByteType get()\n    {\n        t.set( mandelbrot( position[ 0 ], position[ 1 ], 255 ) );\n        return t;\n    }\n\n    @Override\n    public MandelbrotRealRandomAccess copyRealRandomAccess()\n    {\n        return copy();\n    }\n\n    @Override\n    public MandelbrotRealRandomAccess copy()\n    {\n        final MandelbrotRealRandomAccess a = new MandelbrotRealRandomAccess();\n        a.setPosition( this );\n        return a;\n    }\n}\nFirst of all, note that we extend RealPoint. Instead of implementing the interface RealRandomAccess&lt; UnsignedByteType &gt;, we make use of this classawhich has most of the required methods implemented already.\nActually, all we are left with is to implement the Sampler&lt; UnsignedByteType &gt; interface. ImgLib2 provides several such abstract implementations to minimize development time for new accessor types. The UML diagram below shows MandelbrotRealRandomAccess and the derivative hierarchy of its parent classes.\nThe value (iteration count) at a 2D position (re0,im0) is computer in the static method mandelbrot() in lines 016-032. When calling it, we set the maximum number of iterations to 255. Thus we can use UnsignedByteType as the value type of our accessor. Therefore, we implement the interface RealRandomAccess&lt; UnsignedByteType &gt;.\nIn the constructor in lines 010-014, we call the super class constructor to initialise a 2-dimensional RealPoint. We create the UnsignedByteType member t (declared in line 008) which will store the value that is returned by get().\nOur super class RealPoint implements the RealPositionable and RealLocalizable. We have access to the current position through the double[] position field inherited from RealLocalizable. In get() (lines 035-038) we use it to compute the value at the current position. The value is stored in t which is returned.\nFinally, we provide the copy() and copyRealRandomAccess() methods to complete the RealRandomAccess interface implementation. A copied accessor is supposed to refer to the same position and value, therefore we setPosition in line 051.\n\n\n\nUML for abstract RealRandomAccess class hierarchy\n\n\nNow let’s use the MandelbrotRealRandomAccess to render a pixel image:\nimport net.imglib2.Cursor;\nimport net.imglib2.RealLocalizable;\nimport net.imglib2.RealRandomAccess;\nimport net.imglib2.img.Img;\nimport net.imglib2.img.array.ArrayImgFactory;\nimport net.imglib2.img.display.imagej.ImageJFunctions;\nimport net.imglib2.type.numeric.integer.UnsignedByteType;\n\npublic class DrawMandelbrot\n{\n    public static void main( final String[] args )\n    {\n        final int[] dimensions = new int[] { 600, 400 };\n        final Img&lt; UnsignedByteType &gt; img = new ArrayImgFactory&lt; UnsignedByteType &gt;()\n            .create( dimensions, new UnsignedByteType() );\n\n        final RealRandomAccess&lt;UnsignedByteType&gt; mb = new MandelbrotRealRandomAccess();\n\n        final double scale = 0.005;\n        final double[] offset = new double[] { -2, -1 };\n\n        final Cursor&lt; UnsignedByteType &gt; cursor = img.localizingCursor();\n        while( cursor.hasNext() )\n        {\n            cursor.fwd();\n            for ( int d = 0; d &lt; 2; ++d )\n                mb.setPosition( scale * cursor.getIntPosition( d ) + offset[ d ], d );\n            cursor.get().set( mb.get() );\n        }\n\n        ImageJFunctions.show( img );\n    }\n}\nWe start by creating a 600×400 UnsignedByteType pixel image (lines 013-015). This is the target image into which we will render the mandelbrot fractal and which we will eventually display on screen (line 031).\nWe create a MandelbrotRealRandomAccess which will provide samples from the fractal at arbitray positions.\nfinal RealRandomAccess&lt; UnsignedByteType &gt; mb = new MandelbrotRealRandomAccess();\nWe render the fractal by iterating and setting the pixels of the target image (lines 022-029). In this case, we use a localizing Cursor because we need the cursor’s position at every pixel.\nfinal Cursor&lt; UnsignedByteType &gt; cursor = img.localizingCursor();\nThe current coordinates of the cursor are transferred to the RealRandomAccess using a scale factor and an offset. (Scale and offset are defined in lines 019-020.) We set the coordinates dimension-by-dimension:\nfor ( int d = 0; d &lt; 2; ++d )\n    mb.setPosition( scale * cursor.getIntPosition( d ) + offset[ d ], d );\nFinally, we get a reference to the current pixel, and set it to the value computed by the MandelbrotRealRandomAccess.\ncursor.get().set( mb.get() );\ncursor.get() gives the UnsignedByteType reference to the value under the cursor. mb.get() gives the UnsignedByteType reference to the value computed by the MandelbrotRealRandomAccess. Then we set() the value of the former to the value of the latter.\nWhen you run the code you will see this: \nBecause we have a RealRandomAccess you can zoom in indefinitely (until you hit the double precision limit). If you like, you can play around with the scale and offset values. Here is another example obtained with\nfinal double scale = 0.000125;\nfinal double[] offset = new double[] { -1.3875, 0.045 };\n\n\n\nNotes\n\nIn line 017 we used a RealRandomAccess&lt; UnsignedByteType &gt; variable just to emphasize again the interface implemented by MandelbrotRealRandomAccess. In real code, you would probably use the actual type.\nSampling from a transformed RealRandomAccess to create a pixel image is a quite common task. ImgLib2 provides a framework for on-the-fly transformations, which will be explained later.\nThe RealPositionable, RealLocalizable, … interfaces are not restricted to accessors. For example, the RealPoint class implements RealPositionable and RealLocalizable, and simply represents a n-dimensional coordinate.",
    "crumbs": [
      "ImgLib2 - Accessors"
    ]
  },
  {
    "objectID": "imglib2/accessibles.html",
    "href": "imglib2/accessibles.html",
    "title": "ImgLib2 - Accessibles",
    "section": "",
    "text": "In ImgLib2, images are represented by Accessibles. Image here refers to any (partial) function from coordinates to values.\nIn the previous section we have seen how pixel values can be manipulated using Accessors. Accessors are obtained from Accessibles. For example we have used:\nfinal Cursor&lt; UnsignedByteType &gt; cursor = img.localizingCursor();\nto obtain an iterating accessor from the Accessible img.\nAccessibles represent the data itself. Pixel images, procedurally generated images, views into images (for instance sub-images), interpolated images, sparse collections of samples, the list of local intensity maxima of an image, list of nearest neighbors, etc., are all examples of Accessibles.\nThe UML diagram below shows the integer part of the Accessible interface hierarchy. We will look at the full diagram including Accessibles for real coordinates later. Accessible interfaces have been highlighted.\n{% include img src=“imglib2-accessibles-integer” align=“center” width=“775” caption=“UML for ImgLib2 integer accessible interfaces” %}\nRandomAccessible and RandomAccessibleInterval represent images that are random-accessible at integer coordinates. (Remember: an image is a - possibly partial - function from coordinates to values.) You can obtain a RandomAccess on the data using the randomAccess() or randomAccess(Interval) methods.\nAll ImgLib2 classes representing pixel images are RandomAccessibles. We already used this in a previous example to obtain a RandomAccess on an ArrayImg.\nfinal RandomAccess&lt; UnsignedByteType &gt; r = img.randomAccess();\nIterableInterval represents an iterable collection of samples at integer coordinates. You can obtain a Cursor using the cursor() or localizingCursor() methods. You can obtain the number of elements using size(). The first element can be obtained by firstElement() which is a short-cut for cursor().next().\nRandomAccessibleInterval and IterableInterval represent bounded images where all samples lie within an interval. Both extend Interval which defines methods to obtain the minimum, maximum, and dimensions of the interval. Dimensions refers to the extend of the interval in every dimension, and is defined as maximum - minimum + 1. You can obtain the maximum and minimum in a single or all dimensions. If you obtain it in all dimensions, it can be stored into a long[] array or a Positionable. (Have a look at the Interval API doc.)\n\nRandomAccessibles\nBy convention, a RandomAccessibleInterval represents a function that is defined at all coordinates of the interval. A RandomAccessible on the other hand might be defined only partially. You should be aware of this when creating RandomAccessibleIntervals. For instance it is straightforward to turn a RandomAccessible into a RandomAccessibleInterval by adding interval boundaries. If you do so, it is your responsibility to ensure that the RandomAccessible is fully defined within these boundaries.\nThere are two randomAccess methods, one taking an Interval argument and one without parameters (see RandomAccessible API doc). By using the first method, randomAccess( Interval interval ), you specify that you will use the returned RandomAccess only within the given interval. Some RandomAccessibles provide optimized access on restricted intervals. The second method, randomAccessible() returns a RandomAccess that covers all coordinates where the RandomAccessible is defined. The reason for having both variants is that some RandomAccessibles may provide optimized accessors for specific sub-intervals. Procedurally generated images might be precomputed for certain intervals, boundary condition checks might not be required in certain intervals, etc. All ImgLib2 classes representing pixel images return the same accessor for both methods. However, when writing generic algorithms that work on arbitrary RandomAccessibles, consider using the interval method.\n\n\nIterableIntervals\nThere are two methods for obtaining Cursors, cursor() and localizingCursor(). These typically return different Cursor implementations.\nThe localizingCursor() keeps track of its location whenever you move it forward. When you localize it it will just return that pre-computed location. It is more efficient when localization occurs frequently. For example when you want to compute the centroid coordinates of an iterable list of samples, you would use a localizing cursor.\nThe cursor() only calculates its position when it is localized. For instance when you want to find the maximum value in an IterableInterval you are not interested in the locations of all the samples. You just want to localize the cursor once, at the maximum.\nEvery IterableInterval has an iterationOrder(), that is, a defined sequence in which its values are visited.",
    "crumbs": [
      "ImgLib2 - Accessibles"
    ]
  },
  {
    "objectID": "blog/2022-09-27-n5-imglib2/2022-09-27-n5-imglib2.html",
    "href": "blog/2022-09-27-n5-imglib2/2022-09-27-n5-imglib2.html",
    "title": "How to work with the N5 API and ImgLib2?",
    "section": "",
    "text": "In this notebook, we will learn how to work with the N5 API and ImgLib2.\nThe N5 API unifies block-wise access to potentially very large n-dimensional data over a variety of storage backends. Those backends currently are the simple N5 format on the local filesystem, Google Cloud and AWS-S3, the HDF5 file format and Zarr. The ImgLib2 bindings use this API to make this data available as memory cached lazy cell images through ImgLib2.\nThis notebook uses code and data examples from the ImgLib2 large data tutorial I2K2020 workshop (GitHub repository).\nFirst let’s add the necessary dependencies. We will load the n5-ij module which will transitively load ImgLib2 and all the N5 API modules that we will be using in this notebook. It will also load ImageJ which we will use to display data. If this is the first time you are loading dependencies, running this can take quite a while. Next time, everything will be cached though…\n\n%mavenRepo scijava.public https://maven.scijava.org/content/groups/public\n%maven org.janelia.saalfeldlab:n5-ij:4.0.2\n\nNext, we register a simple renderer that uses ImgLib2’s ImageJ bridge and Spencer Park’s image renderer to render the first 2D slice of a RandomAccessibleInterval into the notebook. We also add a renderer for arrays and maps, because we want to list directories and attributes maps later.\n\n\nCode\nimport com.google.gson.*;\nimport io.github.spencerpark.jupyter.kernel.display.common.*;\nimport io.github.spencerpark.jupyter.kernel.display.mime.*;\nimport net.imglib2.img.display.imagej.*;\nimport net.imglib2.view.*;\nimport net.imglib2.*;\n\ngetKernelInstance().getRenderer().createRegistration(RandomAccessibleInterval.class)\n    .preferring(MIMEType.IMAGE_PNG)\n    .supporting(MIMEType.IMAGE_JPEG, MIMEType.IMAGE_GIF)\n    .register((rai, context) -&gt; Image.renderImage(\n        ImageJFunctions.wrap(rai, rai.toString()).getBufferedImage(),\n        context));\n\ngetKernelInstance().getRenderer().createRegistration(String[].class)\n    .preferring(MIMEType.TEXT_PLAIN)\n    .supporting(MIMEType.TEXT_HTML, MIMEType.TEXT_MARKDOWN)\n    .register((array, context) -&gt; Text.renderCharSequence(Arrays.toString(array), context));\n\ngetKernelInstance().getRenderer().createRegistration(long[].class)\n    .preferring(MIMEType.TEXT_PLAIN)\n    .supporting(MIMEType.TEXT_HTML, MIMEType.TEXT_MARKDOWN)\n    .register((array, context) -&gt; Text.renderCharSequence(Arrays.toString(array), context));\n\ngetKernelInstance().getRenderer().createRegistration(Map.class)\n    .preferring(MIMEType.TEXT_PLAIN)\n    .supporting(MIMEType.TEXT_HTML, MIMEType.TEXT_MARKDOWN)\n    .register((map, context) -&gt; Text.renderCharSequence(map.toString(), context));\n\n\nWe will now open N5 datasets from some sources as lazy-loading ImgLib2 cell images. For opening the N5 readers, we will use the helper class N5Factory which parses the URL and/ or some magic byte in file headers to pick the right reader or writer for the various possible N5 backends. If you know which backend you are using, you should probably use the appropriate implementation directly, it’s not difficult.\n\nimport ij.*;\nimport net.imglib2.converter.*;\nimport net.imglib2.type.numeric.integer.*;\nimport org.janelia.saalfeldlab.n5.*;\nimport org.janelia.saalfeldlab.n5.ij.*;\nimport org.janelia.saalfeldlab.n5.imglib2.*;\nimport org.janelia.saalfeldlab.n5.universe.*;\n\n/* make an N5 reader, we start with a public container on AWS S3 */\nfinal var n5Url = \"https://janelia-cosem.s3.amazonaws.com/jrc_hela-2/jrc_hela-2.n5\";\nfinal var n5Group = \"/em/fibsem-uint16\";\nfinal var n5Dataset = n5Group + \"/s4\";\nfinal var n5 = new N5Factory().openReader(n5Url);\n\n/* open a dataset as a lazy loading ImgLib2 cell image */\nfinal RandomAccessibleInterval&lt;UnsignedShortType&gt; rai = N5Utils.open(n5, n5Dataset);\n\n/* This is a 3D volume, so let's show the center slice */\nViews.hyperSlice(rai, 2, rai.dimension(2) / 2);\n\n\n\n\n\n\n\n\nThat’s a bit low on contrast, let’s make it look like TEM, and let’s show a few of those hyperslices through the 3D volume:\n\nvar raiContrast = Converters.convert(\n    rai,\n    (a, b) -&gt; b.setReal(\n        Math.max(\n            0,\n            Math.min(\n                255,\n                255 - 255 * (a.getRealDouble() - 26000) / 6000))),\n    new UnsignedByteType());\ndisplay(Views.hyperSlice(raiContrast, 2, rai.dimension(2) / 10 * 4), \"image/jpeg\");\ndisplay(Views.hyperSlice(raiContrast, 2, rai.dimension(2) / 2), \"image/jpeg\");\ndisplay(Views.hyperSlice(raiContrast, 2, rai.dimension(2) / 10 * 6), \"image/jpeg\");\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nb3145473-3a3a-49a5-a392-9c5101325063\n\n\nWe can list the attributes and their types of every group or dataset, and read any of them into matching types:\n\nvar groupAttributes = n5.listAttributes(n5Group);\nvar datasetAttributes = n5.listAttributes(n5Dataset);\n\ndisplay(\n    \"**\" + n5Group + \"** attributes are ```\" +\n        groupAttributes.toString().replace(\", \", \",\\n\").replace(\"{\", \"{\\n\") + \"```\",\n    \"text/markdown\");\ndisplay(\n    \"**\" + n5Dataset + \"** attributes are ```\" +\n        datasetAttributes.toString().replace(\", \", \",\\n\").replace(\"{\", \"{\\n\") + \"```\",\n    \"text/markdown\");\n\nvar n5Version = n5.getAttribute(\"/\", \"n5\", String.class);\nvar dimensions = n5.getAttribute(n5Dataset, \"dimensions\", long[].class);\nvar compression = n5.getAttribute(n5Dataset, \"compression\", Compression.class);\nvar dataType = n5.getAttribute(n5Dataset, \"dataType\", DataType.class);\n\ndisplay(n5Version);\ndisplay(dimensions);\ndisplay(compression);\ndisplay(dataType);\n\n/em/fibsem-uint16 attributes are { pixelResolution=class java.lang.Object, multiscales=class [Ljava.lang.Object;, n5=class java.lang.String, scales=class [Ljava.lang.Object;, axes=class [Ljava.lang.String;, name=class java.lang.String, units=class [Ljava.lang.String;}\n\n\n/em/fibsem-uint16/s4 attributes are { transform=class java.lang.Object, pixelResolution=class java.lang.Object, dataType=class java.lang.String, name=class java.lang.String, compression=class java.lang.Object, blockSize=class [J, dimensions=class [J}\n\n\n2.0.0\n\n\n[750, 100, 398]\n\n\norg.janelia.saalfeldlab.n5.GzipCompression@78c84e2f\n\n\nuint16\n\n\n02cf0988-e2fc-483a-8286-9a4ca22aa8db\n\n\nLet’s save the contrast adjusted uin8 version of the volume into three N5 supported containers (N5, Zarr, and HDF5), parallelize writing for N5 and Zarr:\n\nimport java.nio.file.*;\n\n/* create a temporary directory */\nPath tmpDir = Files.createTempFile(\"\", \"\");\nFiles.delete(tmpDir);\nFiles.createDirectories(tmpDir);\nvar tmpDirStr = tmpDir.toString();\n\ndisplay(tmpDirStr);\n\n/* get the dataset attributes (dataType, compression, blockSize, dimensions) */\nfinal var attributes = n5.getDatasetAttributes(n5Dataset);\n\n/* use 10 threads to parallelize copy */\nfinal var exec = Executors.newFixedThreadPool(10);\n\n/* save this dataset into a filsystem N5 container */\ntry (final var n5Out = new N5Factory().openFSWriter(tmpDirStr + \"/test.n5\")) {\n  N5Utils.save(\n      raiContrast,\n      n5Out,\n      n5Dataset,\n      attributes.getBlockSize(),\n      attributes.getCompression(),\n      exec);\n}\n\n/* save this dataset into a filesystem Zarr container */\ntry (final var zarrOut = new N5Factory().openZarrWriter(tmpDirStr + \"/test.zarr\")) {\n  N5Utils.save(\n      raiContrast,\n      zarrOut,\n      n5Dataset,\n      attributes.getBlockSize(),\n      attributes.getCompression(),\n      exec);\n}\n\n/* save this dataset into an HDF5 file, parallelization does not help here */\ntry (final var hdf5Out = new N5Factory().openHDF5Writer(tmpDirStr + \"/test.hdf5\")) {\n  N5Utils.save(\n      raiContrast,\n      hdf5Out,\n      n5Dataset,\n      attributes.getBlockSize(),\n      attributes.getCompression());\n}\n\n/* shot down the executor service */\nexec.shutdown();\n\ndisplay(Files.list(tmpDir).map(a -&gt; a.toString()).toArray(String[]::new));\n\n/tmp/12301290762951248139\n\n\n[/tmp/12301290762951248139/test.n5, /tmp/12301290762951248139/test.zarr, /tmp/12301290762951248139/test.hdf5]\n\n\n19331be9-edd2-413e-b2ad-47bc7627187b\n\n\nNow let us look at them and see if they all contain the same data:\n\ntry (final var n5 = new N5Factory().openReader(tmpDirStr + \"/test.n5\")) {\n  final RandomAccessibleInterval&lt;UnsignedByteType&gt; rai = N5Utils.open(n5, n5Dataset);\n  display(Views.hyperSlice(rai, 2, rai.dimension(2) / 2), \"image/jpeg\");\n}\n\ntry (final var n5 = new N5Factory().openReader(tmpDirStr + \"/test.zarr\")) {\n  final RandomAccessibleInterval&lt;UnsignedByteType&gt; rai = N5Utils.open(n5, n5Dataset);\n  display(Views.hyperSlice(rai, 2, rai.dimension(2) / 2), \"image/jpeg\");    \n}\n\ntry (final var n5 = new N5Factory().openReader(tmpDirStr + \"/test.hdf5\")) {\n  final RandomAccessibleInterval&lt;UnsignedByteType&gt; rai = N5Utils.open(n5, n5Dataset);\n  display(Views.hyperSlice(rai, 2, rai.dimension(2) / 2), \"image/jpeg\");        \n}\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLet’s clean up temporary storage before we end this tutorial.\n\ntry (var n5 = new N5Factory().openWriter(tmpDirStr + \"/test.n5\")) {\n  n5.remove();\n}\ntry (var n5 = new N5Factory().openWriter(tmpDirStr + \"/test.zarr\")) {\n  n5.remove();\n}\ntry (var n5 = new N5Factory().openWriter(tmpDirStr + \"/test.hdf5\")) {\n  n5.remove();\n}\nFiles.delete(tmpDir);"
  },
  {
    "objectID": "blog/2024-04-02-n5-attribute-paths/2024-04-02-n5-attribute-paths.html",
    "href": "blog/2024-04-02-n5-attribute-paths/2024-04-02-n5-attribute-paths.html",
    "title": "N5 attribute paths",
    "section": "",
    "text": "Code\n%mavenRepo scijava.public https://maven.scijava.org/content/groups/public\n%maven org.scijava:scijava-common:2.97.0\n%maven net.imglib2:imglib2:6.2.0\n%maven org.janelia.saalfeldlab:n5:3.1.2\n%maven org.janelia.saalfeldlab:n5-imglib2:7.0.0\n%maven org.janelia.saalfeldlab:n5-universe:1.3.1\n    \nimport java.nio.file.*;\nimport java.util.*;\nimport java.util.stream.*;\nimport java.util.concurrent.*;\n\nimport com.google.gson.*;\n\nimport net.imglib2.*;\nimport net.imglib2.img.array.*;\nimport net.imglib2.type.numeric.real.*;\nimport net.imglib2.view.*;\nimport net.imglib2.util.*;\n\nimport org.janelia.saalfeldlab.n5.*;\nimport org.janelia.saalfeldlab.n5.imglib2.*;\nimport org.janelia.saalfeldlab.n5.universe.*;\n\npublic static void pathInfo(Path p) {\n    try {\n        System.out.println(String.format(\"%s is %d bytes\", p, Files.size(p))); \n    } catch(IOException e ){}\n}\n\npublic static void printBlocks(String path) throws IOException {\n\n    try (Stream&lt;Path&gt; stream = Files.walk(Paths.get(path))) {\n        stream.filter(Files::isRegularFile)\n            .filter( p -&gt; p.getFileName().toString().matches(\"[0-9]\"))\n                .forEach( x -&gt; { pathInfo(x); });\n    }\n}\nRecall that structured metadata attributes can be written to a container using\nN5Writer.setAttribute(String group, String key, Object value)\nand read using\nN5Reader.getAttribute(String group, String key, Class class).\nThese basics are described in the N5 API Basics Tutorial. In this tutorial, we will show that methods accept more sophisticated expressions for the key that we call “attribute paths.” These enable you to set and access any part of the attribute hierarchy."
  },
  {
    "objectID": "blog/2024-04-02-n5-attribute-paths/2024-04-02-n5-attribute-paths.html#arrays",
    "href": "blog/2024-04-02-n5-attribute-paths/2024-04-02-n5-attribute-paths.html#arrays",
    "title": "N5 attribute paths",
    "section": "Arrays",
    "text": "Arrays\nWe’ll start by discussing array attribute indexing. First make some array attribute:\n\nvar n5 = new N5Factory().openWriter(\"attribute-demo.n5\");\nvar group = \"arrayDemo\";\nn5.createGroup(group);\n\nn5.setAttribute(group, \"array\", new double[]{ 5, 6, 7, 8 });\nArrays.toString(n5.getAttribute(group, \"array\", double[].class));\n\n[5.0, 6.0, 7.0, 8.0]\n\n\nIndividual elements of the array can be retrieved by adding [i] after the key, where i is an integer (zero-based indexing). N5 will return null for indexes outside the bounds of the array, including for negative values.\n\nn5.getAttribute(group, \"array[0]\", double.class);  // returns 5.0\nn5.getAttribute(group, \"array[2]\", double.class);  // returns 7.0\nn5.getAttribute(group, \"array[9]\", double.class);  // returns null\nn5.getAttribute(group, \"array[-1]\", double.class); // returns null\n\nThis syntax lets you set individual array elements as well:\n\nn5.setAttribute(group, \"array[1]\", 0.6);\nArrays.toString(n5.getAttribute(group, \"array\", double[].class));\n\n[5.0, 0.6, 7.0, 8.0]\n\n\nThe array will grow if we set a value outside the range of an array. The array will be filled with zeros if the array is numeric.\n\nn5.setAttribute(group, \"array[6]\", 99.99);\nArrays.toString(n5.getAttribute(group, \"array\", double[].class));\n\n[5.0, 0.6, 7.0, 8.0, 0.0, 0.0, 99.99]\n\n\n\nn5.setAttribute(group, \"array[-5]\", -5); // does nothing\nArrays.toString(n5.getAttribute(group, \"array\", double[].class));\n\n[5.0, 0.6, 7.0, 8.0, 0.0, 0.0, 99.99]\n\n\n\nIntStream.range(0, 4).forEach( i -&gt; {\n    n5.setAttribute(group, \"matrix[\"+i+\"][3]\", 0);\n    n5.setAttribute(group, \"matrix[\"+i+\"][\"+i+\"]\", 2*(i+1));\n});\n\nn5.getAttribute(group, \"matrix\", JsonElement.class);\n\n[[2,0,0,0],[0,4,0,0],[0,0,6,0],[0,0,0,8]]\n\n\nAn array that is not numeric that needs to grown will be filled with nulls.\n\nn5.setAttribute(group, \"stringArray\", new String[]{\"a\", \"b\"});\nn5.setAttribute(group, \"stringArray[6]\", \"g\");\n\nArrays.toString(n5.getAttribute(group, \"stringArray\", String[].class));\n\n[a, b, null, null, null, null, g]\n\n\nN5’s setAttribute will always do what is requested when possible, even if it will overwrite data. If safety is necessary, developers should manually check if an attribute key is present. Use of the type JsonElement type is the most safe, because a non-null JsonElement will be returned if data of any type is present at the requested key.\n\n// overwrite the previous array\nn5.setAttribute(group, \"array\", new String[]{\"destroy\"});  // array is now [ \"destroy\" ]\n\nArrays.toString(n5.getAttribute(group, \"array\", String[].class));\n\n[destroy]\n\n\n\nif( n5.getAttribute( group, \"array\", JsonElement.class ) == null )\n    n5.setAttribute(group, \"array\", new String[]{});   // array is still [ \"destroy\" ]\n\nArrays.toString(n5.getAttribute(group, \"array\", String[].class));\n\n[destroy]"
  },
  {
    "objectID": "blog/2024-04-02-n5-attribute-paths/2024-04-02-n5-attribute-paths.html#objects",
    "href": "blog/2024-04-02-n5-attribute-paths/2024-04-02-n5-attribute-paths.html#objects",
    "title": "N5 attribute paths",
    "section": "Objects",
    "text": "Objects\nJSON objects are structures with “fields” that can be referenced by their String name. One way to set objects is by using a Map.\n\nvar group = \"objectDemo\";\nn5.createGroup(group);\n\nvar a = Collections.singletonMap(\"a\", \"A\");\n\nn5.setAttribute(group, \"obj\", a ); \nn5.getAttribute(group, \"obj\", Map.class);\n\n{a=A}\n\n\nThe value for an object’s field can be any type, even another object. Individual fields for an object can be accessed by appending /&lt;field-name&gt; to the attribute name. For example:\n\nvar b = Collections.singletonMap(\"b\", \"B\");\n\n// set the value of obj/a to {b=B}\nn5.setAttribute(group, \"obj/a\", b);\nn5.getAttribute(group, \"obj\", Map.class);\n\n{a={b=B}}\n\n\n\nn5.getAttribute(group, \"obj/a\", Map.class);\n\n{b=B}\n\n\nNotice that it is possible to repeatedly access subfields of nested objects. In fact, the set of all attributes in an N5 group is usually itself an object! We call it the “root object” and access it with the the key \"/\"\n\nn5.getAttribute(group, \"/\", Map.class); \n\n{obj={a={b=B}}}\n\n\nFor the following examples, we’ll use the class Pet defined here:\n\n\nCode\nclass Pet {\n    String name;\n    int age;\n\n    public Pet(String name, int age) {\n        this.name = name;\n        this.age = age;\n    }\n\n    public String toString() {\n        return String.format(\"pet %s is %d\", name, age);\n    }\n}\n\n\n\nn5.setAttribute(group, \"pet\", new Pet(\"Pluto\", 93));\nPet pet = n5.getAttribute(group, \"pet\", Pet.class);\npet\n\npet Pluto is 93\n\n\n\nn5.getAttribute(group, \"pet\", Map.class);\n\n{name=Pluto, age=93.0}\n\n\n\nn5.setAttribute(group, \"pet/likes\", new String[]{\"Micky\"});\nn5.getAttribute(group, \"pet\", Map.class);\n\n{name=Pluto, age=93.0, likes=[Micky]}"
  },
  {
    "objectID": "blog/2024-04-02-n5-attribute-paths/2024-04-02-n5-attribute-paths.html#mixing-object-and-array-indexing",
    "href": "blog/2024-04-02-n5-attribute-paths/2024-04-02-n5-attribute-paths.html#mixing-object-and-array-indexing",
    "title": "N5 attribute paths",
    "section": "Mixing object and array indexing",
    "text": "Mixing object and array indexing\nThis example sets the value of an integer inside several nested arrays and objects.\nNote: When indexing an array, the path separators / before and after the index operator [ ] are optional\n\n// remove all attributes \nn5.removeAttribute(group, \"/\");\n\nn5.setAttribute(group, \"one/[2]/three/[4]\", 5);\nn5.setAttribute(group, \"one[2]three[0]\", 12);\nn5.getAttribute(group, \"/\", JsonElement.class);\n\n{\"one\":[null,null,{\"three\":[12,0,0,0,5]}]}"
  },
  {
    "objectID": "blog/2024-04-02-n5-attribute-paths/2024-04-02-n5-attribute-paths.html#removing-attributes-and-dealing-with-nulls",
    "href": "blog/2024-04-02-n5-attribute-paths/2024-04-02-n5-attribute-paths.html#removing-attributes-and-dealing-with-nulls",
    "title": "N5 attribute paths",
    "section": "Removing attributes and dealing with nulls",
    "text": "Removing attributes and dealing with nulls\nWe saw about that removeAttribute can be used to remove attributes. The first variant takes the group and attribute key as arguments, and returns nothing after removal. The second variant also takes a Class argument and will return the removed object of type T if possible. If the value of the attribute cannot be parsed into the requested type, the attribute will not be removed, even if the key exists.\n\nvar group = \"animals\";\nn5.createGroup(group);\n\nn5.setAttribute(group, \"cow\", \"moo\");\nn5.setAttribute(group, \"dog\", \"woof\");\nn5.setAttribute(group, \"sheep\", \"baa\");\n\nn5.getAttribute(group, \"/\", JsonElement.class);\n\n{\"cow\":\"moo\",\"dog\":\"woof\",\"sheep\":\"baa\"}\n\n\n\nn5.removeAttribute(group, \"cow\"); // void method\nn5.getAttribute(group, \"/\", JsonElement.class);\n\n{\"dog\":\"woof\",\"sheep\":\"baa\"}\n\n\n\nSystem.out.println( \"The doggie says: \" + \n    n5.removeAttribute(group, \"dog\", String.class)\n);\nn5.getAttribute(group, \"/\", JsonElement.class);\n\nThe doggie says: woof\n\n\n{\"sheep\":\"baa\"}\n\n\n\n// throws an exception because the value of \"sheep\" is not an int\ntry {\n    n5.removeAttribute(group, \"sheep\", int.class);\n}catch(N5Exception e ){\n    System.err.println(\"An exception was thrown\");\n}\n\n// observe that the attribute was not removed\nn5.getAttribute(group, \"/\", JsonElement.class);\n\nAn exception was thrown\n\n\n{\"sheep\":\"baa\"}\n\n\n\n\n\n\n\n\nWarning\n\n\n\nIn the default implemenation, setting the value of an attribute to null will remove that attribute (i.e. the attribute’s key will be removed).\nHowever, we strongly recommended using the removeAttribute methods when removing attributes, since setting an attribute to null can lead to inconsistent behaviour, depending on how the N5Writer was created (see below).\nSetting an attribute path to null can even result in creating attributes along the path, regardless of whether serializeNulls is enabled or not.\n\n\nIn cases where it is useful to write the value null into the attributes, you must create an N5Writer using a GsonBuilder with serializeNulls enabled. This example writes a null value to the key \"attr\".\n\nvar n5WithNulls = new N5Factory()\n    .gsonBuilder(new GsonBuilder().serializeNulls())\n    .openWriter(\"attribute-demo.n5\");\n\nn5WithNulls.setAttribute(group, \"attr\", null);\nn5WithNulls.getAttribute(group, \"/\", JsonElement.class);\n\n{\"sheep\":\"baa\",\"attr\":null}"
  },
  {
    "objectID": "blog/2024-04-02-n5-attribute-paths/2024-04-02-n5-attribute-paths.html#keys-are-paths",
    "href": "blog/2024-04-02-n5-attribute-paths/2024-04-02-n5-attribute-paths.html#keys-are-paths",
    "title": "N5 attribute paths",
    "section": "Keys are paths",
    "text": "Keys are paths\nThink about keys as paths into a hierarchy, where / separates levels of the hierarchy. Attribute methods support relative paths, where . refers to “this” path, and .. refers to the parent path.\n\nvar group = \"details\";\nn5.createGroup(group);\n\nn5.setAttribute(group, \"a/b/c\", \"tutorial\");\nn5.getAttribute(group, \"/\", JsonElement.class);\n\n{\"a\":{\"b\":{\"c\":\"tutorial\"}}}\n\n\nThe key a/. is equivalent to a\n\nn5.getAttribute(group, \"a/.\", JsonElement.class);\n\n{\"b\":{\"c\":\"tutorial\"}}\n\n\n\nn5.getAttribute(group, \"a/..\", JsonElement.class);\n\n{\"a\":{\"b\":{\"c\":\"tutorial\"}}}\n\n\nThe parent of an array element refers to the array:\n\nn5.setAttribute(group, \"array\", new String[]{\"Alice\", \"Bob\"});\nn5.getAttribute(group, \"array[0]/..\", JsonElement.class);\n\n[\"Alice\",\"Bob\"]\n\n\nGetting the parent attribute relative to the root will return null\n\nn5.getAttribute(group, \"..\", JsonElement.class) == null;\n\ntrue"
  },
  {
    "objectID": "blog/2024-04-02-n5-attribute-paths/2024-04-02-n5-attribute-paths.html#warnings-and-caveats",
    "href": "blog/2024-04-02-n5-attribute-paths/2024-04-02-n5-attribute-paths.html#warnings-and-caveats",
    "title": "N5 attribute paths",
    "section": "Warnings and caveats",
    "text": "Warnings and caveats\n\n\n\n\n\n\nWarning\n\n\n\nWe strongly recommend against using / or \\ in key names. Similarly, . or .. should not be used in between forward slashes, i.e. avoid (/../ or /./ in key names).\n\n\nWhile we recommend against it, is it possible to use forward slash (/) or backslash (\\) as field names for attributes. Since / is reserved to refer to the root attribute, it must be escaped with a backslash to refer to the literal string \"/\".\nThe code below is not suitable for children, or anyone.\n\nvar group = \"warnings\";\nn5.createGroup(group);\n\nn5.setAttribute(group, \"\\\\/\", \"Please don't do this\");\nn5.setAttribute(group, \"\\\\\", \"UGH\");\nn5.setAttribute(group, \".\", \"what does this mean!?\");\nn5.setAttribute(group, \"..\\\\/.\", \"...pain...\");\n\nn5.getAttribute(group, \"/\", JsonElement.class);\n\n{\"/\":\"Please don't do this\",\"\\\\\":\"UGH\",\".\":\"what does this mean!?\",\"../.\":\"...pain...\"}"
  },
  {
    "objectID": "blog/2022-08-08-keymaps/2022-08-08-keymaps.html",
    "href": "blog/2022-08-08-keymaps/2022-08-08-keymaps.html",
    "title": "User-configurable Keymaps",
    "section": "",
    "text": "How to set up user-configurable keyboard shortcuts using ui-behaviour and BigDataViewer’s Preferences Dialog\n\nWhile developing the BDV Preferences dialog, a “pattern” has emerged of how we wire up the shortcut and action definitions. This tutorial explains the current recommended way of doing that. We give some background about using ui-behaviour etc. Feel free to just skip to the end for the recommended pattern.\n\n\nIn BigDataViewer 10.4 we added a Preferences dialog. This makes settings more user accessible, that previously could only be made through editing config files. In particular, users can now easily override BigDataViewer keybindings to their liking.\nIt is also possible to define and switch between multiple sets of keybindings. For example, in Mastodon, we have predefined keymaps that have * basic BDV key bindings, but many shortcuts remapped to navigate along a cell lineage, or * full BDV key bindings, at the expense of more complicated shortcuts for cell lineage navigation.\nOn top of these users can define their own completely customised keymaps.\nThis is all based on ui-bahaviour, which several tools (BDV-based and otherwise) already use for managing shortcuts. While developing the Mastodon Preferences dialog, and now carrying over to BigDataViewer, a pattern has emerged of how we wire up the shortcut and action definitions. It would be great if this would become a blueprint for actions in other tools, because a) that will make the code easier to understand and b) facilitate reuse of action definitions across projects.\nWe work towards the recommended pattern, from scratch, in a series of examples that you can also find on github.\n\n%%loadFromPOM\n&lt;repository&gt;\n    &lt;id&gt;scijava.public&lt;/id&gt;\n    &lt;url&gt;https://maven.scijava.org/content/groups/public&lt;/url&gt;\n&lt;/repository&gt;\n&lt;dependency&gt;\n    &lt;groupId&gt;sc.fiji&lt;/groupId&gt;\n    &lt;artifactId&gt;bigdataviewer-core&lt;/artifactId&gt;\n    &lt;version&gt;10.4.3&lt;/version&gt;\n&lt;/dependency&gt;\n&lt;dependency&gt;\n    &lt;groupId&gt;org.scijava&lt;/groupId&gt;\n    &lt;artifactId&gt;ui-behaviour&lt;/artifactId&gt;\n    &lt;version&gt;2.0.7&lt;/version&gt;\n&lt;/dependency&gt;\n\n\n\n\nLets look at a basic example of integrating ui-beahviour in a AWT/Swing application.\nWe need a minimal application to play with: MainPanel is a JPanel containing (only) a single JLabel displaying the text \"hello\". The displayed text can be changed by the setText(String) method. We will use this to define different mock “actions”.\n\n/*\n#hide\n*/\nimport java.awt.BorderLayout;\nimport java.awt.Dimension;\nimport javax.swing.JFrame;\nimport javax.swing.JLabel;\nimport javax.swing.JPanel;\nimport javax.swing.border.EmptyBorder;\n\n\npublic class MainPanel extends JPanel\n{\n    private final JLabel label;\n\n    public MainPanel()\n    {\n        setLayout( new BorderLayout() );\n        setBorder( new EmptyBorder( 0, 20, 0, 0 ) );\n        setFocusable( true );\n\n        label = new JLabel( \"hello\" );\n        add( label, BorderLayout.CENTER );\n    }\n\n    public void setText( final String text )\n    {\n        label.setText( text );\n    }\n}\n\nLet’s instantiate a MainPanel and show it in a JFrame.\n\nvar frame = new JFrame( \"Keymaps Demo\" );\nvar panel = new MainPanel();\nframe.add( panel );\nframe.setPreferredSize( new Dimension( 200, 100 ) );\nframe.pack();\nframe.setVisible( true );\n\n\n\n\nMainPanel showing text “hello”\n\n\n\n/*\n#hide\n*/\nimport javax.swing.JComponent;\nimport javax.swing.SwingUtilities;\n\nTo set up ui-behaviour for the panel, we first need an instance of InputActionBindings\n\nimport org.scijava.ui.behaviour.util.InputActionBindings;\n\nvar bindings = new InputActionBindings();\n\nInputActionBindings bind inputs to actions.\nThis is of course exactly what AWT/Swing’s Key Bindings framework (InputMap, ActionMap) does. InputActionBindings adds very little over that; basically only more convenient InputMap chaining.\nSide note: The initial purpose of ui-behaviour was to offer a similar framework for mouse clicks, scrolls, drags, etc. Modeled after InputMap and ActionMap, there are InputTriggerMap and BehaviourMap. Analogous to InputActionBindings there is TriggerBehaviourBindings.\nAnyway, we connect the InputActionBindings instance to our MainPanel as follows.\n\nSwingUtilities.replaceUIActionMap(\n    panel,\n    bindings.getConcatenatedActionMap() );\nSwingUtilities.replaceUIInputMap(\n    panel, JComponent.WHEN_ANCESTOR_OF_FOCUSED_COMPONENT,\n    bindings.getConcatenatedInputMap() );\n\nInputActionBindings manages a chain of InputMap/ActionMap pairs. An Actions object encapsulates one such pair, and feeds new action definitions into it. We create a new Actions (the constructor arguments don’t matter for now) …\n\nimport org.scijava.ui.behaviour.io.InputTriggerConfig;\nimport org.scijava.ui.behaviour.util.Actions;\n\nvar actions = new Actions( new InputTriggerConfig(), \"demo\" );\n\n… and we add the pair to our InputActionBindings under the name “actions”.\n\nactions.install( bindings, \"actions\" );\n\n(We could use the name later to remove, replace, or temporarily block the InputMap/ActionMap pair.)\nThe actions instance is now connected to the panel via bindings. We can finally use it to add new shortcuts.\n\nactions.runnableAction(\n    () -&gt; panel.setText( \"Action A triggered\" ),\n    \"Action A\",\n    \"SPACE\", \"A\" );\n\nThe actions.runnableAction method takes the following arguments\npublic void runnableAction(\n    final Runnable runnable,\n    final String name,\n    final String... defaultKeyStrokes )\n\nA Runnable to run when the action is triggered.\nA unique name for the action (this will be used as the actions key in the underlying InputMap/ActionMap.\nZero or more keystrokes that should trigger the action.\n\nHere for example, the Runnable sets the text “Action A triggered” in the panel label. It is added under the name “Action A”, and triggered by the “SPACE” key, or the “A” key by default. The syntax for key strokes is described here.\nLet’s add a few more actions.\n\nactions.runnableAction(\n    () -&gt; panel.setText( \"Action B triggered\" ),\n    \"Action B\",\n    \"B\", \"shift B\" );\nactions.runnableAction(\n    () -&gt; panel.setText( \"Action C triggered\" ),\n    \"Action C\",\n    \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\", \"0\" );\n\nNow we can use these defined shortcuts to run these three actions (which will change the text label to “Action A/B/C triggered”.  You can find the full example on github.\n\n\n\nAnother goal of ui-behaviour is to make mouse and key bindings easily configurable by the user (for example through config files).\nThis is the purpose of the Actions constructor arguments\nvar action = new Actions( new InputTriggerConfig(), \"demo\" );\nThe first argument is a InputTriggerConfig, and after that one or more String contexts are given (more on that later).\nThe InputTriggerConfig contains is basically a map from action names to key bindings. When adding a new action, for example like this:\nactions.runnableAction(\n    () -&gt; mainPanel.setText( \"Action B triggered\" ),\n    \"Action B\",\n    \"B\", \"shift B\" );\nthen actions will first look into its InputTriggerConfig to check whether any key binding is associated with the respective action name (“Action B”). If nothing is defined in the InputTriggerConfig then (and only then) the specified default key bindings will be used (\"B\" and \"shift B\").\n\n\nSo far, we just used a new, empty InputTriggerConfig, meaning we just get the specified defaults, which is exactly what we want for prototyping. If the project becomes more mature, and we want to change the config from outside, we can load the InputTriggerConfig from a config file.\n\nimport org.scijava.ui.behaviour.io.yaml.YamlConfigIO;\n\nReader reader = new FileReader( \"config.yaml\" );\nvar config = new InputTriggerConfig( YamlConfigIO.read( reader ) );\n\nThe config.yaml file looks like this:\n---\n- !mapping\naction: Action A\ncontexts: [demo]\ntriggers: [SPACE, A]\n- !mapping\naction: Action B\ncontexts: [demo]\ntriggers: [N]\nThe format should be more or less self-explanatory.\nThe loaded config should now map the String \"Action A\" to the Set of Strings {\"SPACE\", \"A\"}, and \"Action B\" to {\"N\"}. We could set up actions with the loaded config in the constructor, and then define the same actions as in the previous example.\nAlternatively, we can just update the existing Actions with the new config.\n\nactions.updateKeyConfig(config, false);\n\nThe config contains bindings for “Action A” and “Action B”. These will override the specified default bindings. So “Action A” will be triggered by the “SPACE” or “A” keys, and “Action B” will be triggered by “N”.\nThe config doesn’t specify anything for “Action C”, so that will be triggered by the programmatically specified defaults, that is, “1”, “2”, etc.\n\n\n\nBesides the InputTriggerConfig, the Actions constructor also requires one ore more String... context arguments.\nThe idea is that the same action (or at least action name) might occur in different contexts, that is, different tools, different windows of the same tool, etc. For example, an action named “Undo” could occur in many contexts and it would be nice to be able to assign different shortcuts, depending on context.\nTherefore, an InputTriggerConfig does not directly map action to shortcuts, but rather maps (action, context) pairs to shortcuts, where action and context are both Strings. So, for example, (\"Undo\", \"bdv\") can map to a different shortcut than (\"Undo\", \"paintera\").\nThe context arguments given in the Actions constructor specify which subsets of key bindings defined in the InputTriggerConfig should be considered. In the above example, we have\nvar actions = new Actions( config, \"demo\" )\nThis actions will pick up bindings for (\"Undo\", \"demo\") from the config, but not (\"Undo\", \"bdv\") for example.\n\n\n\nThere is a special trigger \"not mapped\" that can be used to specify that a particular action should not be associated to any shortcut. For example, if we add\n- !mapping\naction: Action C\ncontexts: [demo]\ntriggers: [not mapped]\nto the config.yaml file, then “Action C” will be disabled, that is, the programmatic defaults “1”, “2”, etc., will not be used.\nYou can find the full example on github.\n\n\n\n\nBeing able to define shortcuts through a config file is useful. The config files can be edited, and distributed between different users or computers.\nEven more comfortable is to be able to modify shortcuts directly through the UI, at runtime.\n\n\nFor this, we use bdv.ui.settings.SettingsPanel. This panel implements a typical Preferences layout (like it’s used in Eclipse, for example) with a tree of preferences sections on the left, the selected section on the right, and Apply, Ok, Cancel buttons on the bottom.\nThe following PrefererencesDialog contains only the SettingsPanel, and a method addPage() to adds new sections (bdv.ui.settings.SettingsPage) to the preferences tree.\n\n/*\n#hide\n*/\nimport java.awt.Frame;\nimport java.awt.event.WindowAdapter;\nimport java.awt.event.WindowEvent;\n\nimport javax.swing.JDialog;\nimport javax.swing.WindowConstants;\n\n\nimport bdv.ui.settings.SettingsPage;\nimport bdv.ui.settings.SettingsPanel;\n\npublic class PreferencesDialog extends JDialog\n{\n    private final SettingsPanel settingsPanel;\n\n    public PreferencesDialog( final Frame owner )\n    {\n        super( owner, \"Preferences\", false );\n        settingsPanel = new SettingsPanel();\n        settingsPanel.onOk( () -&gt; setVisible( false ) );\n        settingsPanel.onCancel( () -&gt; setVisible( false ) );\n\n        setDefaultCloseOperation( WindowConstants.HIDE_ON_CLOSE );\n        addWindowListener( new WindowAdapter()\n        {\n            @Override\n            public void windowClosing( final WindowEvent e )\n            {\n                settingsPanel.cancel();\n            }\n        } );\n\n        getContentPane().add( settingsPanel, BorderLayout.CENTER );\n        pack();\n    }\n\n    public void addPage( final SettingsPage page )\n    {\n        settingsPanel.addPage( page );\n        pack();\n    }\n}\n\nLet’s instantiate a PreferencesDialog for our example, and add a keyboard shortcut (command-comma or control-comma) to show it.\n\nvar preferencesDialog = new PreferencesDialog( frame );\nactions.runnableAction(\n    () -&gt; preferencesDialog.setVisible( !preferencesDialog.isVisible() ),\n    \"Preferences\",\n    \"meta COMMA\", \"ctrl COMMA\" );\n\nNext, we want to add a preferences section for configuring shortcuts. There is bdv.ui.keymap.KeymapSettingsPage that we can readily use. In the end this will give us something like this:  What remains to be done is to fill the settings page with a list of configurable actions.\n\n\n\nSpecifially, we need to supply the KeymapSettingsPage with a list of existing actions, with short textual descriptions. This is done by creating a CommandDescriptions object and adding the configurable actions.\n\nimport org.scijava.ui.behaviour.io.gui.CommandDescriptions;\n\nvar descriptions = new CommandDescriptions();\n\ndescriptions.setKeyconfigContext( \"demo\" );\n\ndescriptions.add( \"Action A\", new String[] { \"SPACE\" }, \"trigger Action A\" );\ndescriptions.add( \"Action B\", new String[] { \"B\", \"shift B\" }, \"trigger Action B\" );\n\nFor each action, we add its name and default shortcuts in the same way we did when creating the action, and a short description (this is just for showing to the user, so can be left empty if you’re lazy…).\nThe other thing we need to supply to the KeymapSettingsPage is a KeymapManager. KeymapManager maintains a set of named Keymaps (some built-in, some user-defined). A Keymap is a simple container for a InputTriggerConfig, adding just a name and support for listeners to be notified when the InputTriggerConfig changes.\nOur KeymapManager extends the existing AbstractKeymapManager base class. The only thing that needs to be done is providing one or more default Keymaps. We can build a default keymap from the above descriptions. (But they could also be loaded from resources, build manually, …)\n\nimport bdv.ui.keymap.AbstractKeymapManager;\nimport bdv.ui.keymap.Keymap;\n\nvar defaultKeymap = new Keymap( \"Default\", descriptions.createDefaultKeyconfig() );\n\n/**\n * Manages a collection of {@link Keymap}.\n */\npublic class KeymapManager extends AbstractKeymapManager&lt; KeymapManager &gt;\n{\n    @Override\n    protected List&lt; Keymap &gt; loadBuiltinStyles()\n    {\n        return Collections.singletonList( defaultKeymap );\n    }\n\n    @Override\n    public void saveStyles()\n    {\n        // not implemented.\n        // Here we would save user defined keymaps to YAML files, for example.\n    }\n}\n\nWe create a KeyMapManager instance and add it to the Preferences dialog (via KeymapSettingsPage).\n\nimport bdv.ui.keymap.KeymapSettingsPage;\n\nvar keymapManager = new KeymapManager();\npreferencesDialog.addPage(\n        new KeymapSettingsPage( \"Keymap\", keymapManager, new KeymapManager(), descriptions ) );\n\nThe KeyMapManager (via its base class) exposes the user-selected keymap. We set that for our actions object. We also add a listener that refreshes actions keybinding when that keymap changes.\n\nvar keymap = keymapManager.getForwardSelectedKeymap();\nactions.updateKeyConfig( keymap.getConfig(), false );\nkeymap.updateListeners().add(\n    () -&gt; actions.updateKeyConfig( keymap.getConfig(), false )\n);\n\ntrue\n\n\nThat’s it. The user can now use the Preferences dialog to define custom keymaps with shortcuts to their liking, and switch between different keymaps. (Use command-comma or control-comma to show the preferences dialog).\nYou can find the full example on github.\n\n\n\n\nKeeping the list of existing actions (that is, the CommandDescriptions) up to date is tedious. Actions that should appear in the config dialog may be scattered through your own code and dependencies. This can be somewhat automated with CommandDescriptionProviders. These are scijava @Plugins that can be discovered at runtime.\n\nimport org.scijava.plugin.Plugin;\nimport org.scijava.ui.behaviour.io.gui.CommandDescriptionProvider;\n\nvar DEMO_SCOPE = new CommandDescriptionProvider.Scope( \"tpietzsch.keymap\" );\nvar DEMO_CONTEXT = \"demo\";\n\n/*\n * Command descriptions for all provided commands\n */\n@Plugin( type = CommandDescriptionProvider.class )\npublic static class MyActionDescriptions extends CommandDescriptionProvider\n{\n    public MyActionDescriptions()\n    {\n        super( DEMO_SCOPE, DEMO_CONTEXT );\n    }\n\n    @Override\n    public void getCommandDescriptions( final CommandDescriptions descriptions )\n    {\n        descriptions.add( \"Action A\", new String[] { \"SPACE\" }, \"trigger Action A\" );\n        descriptions.add( \"Action B\", new String[] { \"B\", \"shift B\" }, \"trigger Action B\" );\n    }\n}\n\nFor discovery, we use a CommandDescriptionsBuilder\n\nimport org.scijava.Context;\nimport org.scijava.plugin.PluginService;\nimport org.scijava.ui.behaviour.io.gui.CommandDescriptionsBuilder;\n\nvar context = new Context( PluginService.class );\nvar builder = new CommandDescriptionsBuilder();\ncontext.inject( builder );\n\nbuilder.discoverProviders( DEMO_SCOPE );\n\nNote the use of DEMO_SCOPE here. The same scope is also given in the MyActionDescriptions constructor. The discoverProviders() method takes an optional scope argument, and will only discover CommandDescriptionProvider that match this scope. If no scope is given, all CommandDescriptionProvider on the classpath will be discovered. For example within Fiji, that would include actions from Mastodon and BigDataViewer.\nUnfortunately, the @Plugin annotations do not work for classes defined in JShell (used by this notebook). As a workaround, we can add MyActionDescriptions manually.\n\nbuilder.addManually( new MyActionDescriptions(), DEMO_CONTEXT );\n\nAfter we add everything we need to the builder, we can get the Descriptions.\n\nvar descriptions = builder.build();\n\nYou can find the full example on github.\n\n\n\nAction definitions in BigDataViewer and Mastodon are organized in the following way.\nA set of related actions is collected into a MyActions (for example) class. Action names and default shortcuts are defined as public static final constants, because they are used both for defining the actions, and for creating action Descriptions.\nThe actions contained in MyActions are described in a public static inner class Descriptions extends CommandDescriptionProvider.\nIn the Descriptions constructor, we give a scope for the respective library / tool. Ideally, the scope should be defined public static somewhere so that is can easily used outside the component to discover its actions. For example, BigDataViewer uses this scope. If another tool (BigStitcher, BigWarp, etc.) wants to include BDV shortcuts into its customizable keymaps, they can be easily discovered like that.\n\nimport org.scijava.plugin.Plugin;\nimport org.scijava.ui.behaviour.io.gui.CommandDescriptionProvider;\n\nfinal var DEMO_SCOPE = new CommandDescriptionProvider.Scope( \"tpietzsch.keymap-idiom\" );\nfinal var DEMO_CONTEXT = \"demo\";\n\npublic class MyActions\n{\n    // define action name constants\n    public static final String ACTION_A = \"Action A\";\n    public static final String ACTION_B = \"Action B\";\n    public static final String PREFERENCES = \"Preferences\";\n\n    // define default shortcut constants\n    public static final String[] ACTION_A_KEYS = { \"SPACE\" };\n\n    public static final String[] ACTION_B_KEYS = { \"B\", \"shift B\" };\n    public static final String[] PREFERENCES_KEYS = { \"meta COMMA\", \"ctrl COMMA\" };\n\n\n    /*\n     * Command descriptions for all provided commands\n     */\n    @Plugin( type = CommandDescriptionProvider.class )\n    public static class Descriptions extends CommandDescriptionProvider\n    {\n        public Descriptions()\n        {\n            super( DEMO_SCOPE, DEMO_CONTEXT );\n        }\n\n        @Override\n        public void getCommandDescriptions( final CommandDescriptions descriptions )\n        {\n            descriptions.add( ACTION_A, ACTION_A_KEYS, \"trigger Action A\" );\n            descriptions.add( ACTION_B, ACTION_B_KEYS, \"trigger Action B\" );\n            descriptions.add( PREFERENCES, PREFERENCES_KEYS, \"Show the Preferences dialog.\" );\n        }\n    }\n\n    \n    /**\n     * Install into the specified {@link Actions}.\n     */\n    public static void install( final Actions actions, final MainPanel mainPanel, final PreferencesDialog preferencesDialog )\n    {\n        actions.runnableAction( () -&gt; mainPanel.setText( \"Action A triggered\" ),\n                ACTION_A, ACTION_A_KEYS );\n        actions.runnableAction( () -&gt; mainPanel.setText( \"Action B triggered\" ),\n                ACTION_B, ACTION_B_KEYS );\n        actions.runnableAction( () -&gt; preferencesDialog.setVisible( !preferencesDialog.isVisible() ),\n                PREFERENCES, PREFERENCES_KEYS );\n    }\n}\n\nMyActions contains one install method that installs all actions into a provided Actions argument. Ideally, MyActions is stateless, and install method is static.\nThe remaining arguments to install are whatever is needed to create the actions. In the example, the mainPanel is needed to create “Action A” and “Action B”, and the preferencesDialog is needed to create the action to show/hide it.\nSo, MyActions.install(...) is called to install into a provided Actions. Usually every frame/panel in the application should have an Actions instance, which is linked to the KeymapManager so that keymap updates propagate correctly.\nAnd that’s it… This is currently the recommended way to structure and bundle action definitions. You can find the full example on github.\nSee BigDataViewer’s NavigationActions as an example “in the wild”. For behaviours (mouse gestures, etc.) the structure is the same. See BigDataViewer’s TransformEventHandler2D for example."
  },
  {
    "objectID": "blog/2022-08-08-keymaps/2022-08-08-keymaps.html#introduction",
    "href": "blog/2022-08-08-keymaps/2022-08-08-keymaps.html#introduction",
    "title": "User-configurable Keymaps",
    "section": "",
    "text": "In BigDataViewer 10.4 we added a Preferences dialog. This makes settings more user accessible, that previously could only be made through editing config files. In particular, users can now easily override BigDataViewer keybindings to their liking.\nIt is also possible to define and switch between multiple sets of keybindings. For example, in Mastodon, we have predefined keymaps that have * basic BDV key bindings, but many shortcuts remapped to navigate along a cell lineage, or * full BDV key bindings, at the expense of more complicated shortcuts for cell lineage navigation.\nOn top of these users can define their own completely customised keymaps.\nThis is all based on ui-bahaviour, which several tools (BDV-based and otherwise) already use for managing shortcuts. While developing the Mastodon Preferences dialog, and now carrying over to BigDataViewer, a pattern has emerged of how we wire up the shortcut and action definitions. It would be great if this would become a blueprint for actions in other tools, because a) that will make the code easier to understand and b) facilitate reuse of action definitions across projects.\nWe work towards the recommended pattern, from scratch, in a series of examples that you can also find on github.\n\n%%loadFromPOM\n&lt;repository&gt;\n    &lt;id&gt;scijava.public&lt;/id&gt;\n    &lt;url&gt;https://maven.scijava.org/content/groups/public&lt;/url&gt;\n&lt;/repository&gt;\n&lt;dependency&gt;\n    &lt;groupId&gt;sc.fiji&lt;/groupId&gt;\n    &lt;artifactId&gt;bigdataviewer-core&lt;/artifactId&gt;\n    &lt;version&gt;10.4.3&lt;/version&gt;\n&lt;/dependency&gt;\n&lt;dependency&gt;\n    &lt;groupId&gt;org.scijava&lt;/groupId&gt;\n    &lt;artifactId&gt;ui-behaviour&lt;/artifactId&gt;\n    &lt;version&gt;2.0.7&lt;/version&gt;\n&lt;/dependency&gt;"
  },
  {
    "objectID": "blog/2022-08-08-keymaps/2022-08-08-keymaps.html#setting-up-shortcuts-through-ui-behaviour",
    "href": "blog/2022-08-08-keymaps/2022-08-08-keymaps.html#setting-up-shortcuts-through-ui-behaviour",
    "title": "User-configurable Keymaps",
    "section": "",
    "text": "Lets look at a basic example of integrating ui-beahviour in a AWT/Swing application.\nWe need a minimal application to play with: MainPanel is a JPanel containing (only) a single JLabel displaying the text \"hello\". The displayed text can be changed by the setText(String) method. We will use this to define different mock “actions”.\n\n/*\n#hide\n*/\nimport java.awt.BorderLayout;\nimport java.awt.Dimension;\nimport javax.swing.JFrame;\nimport javax.swing.JLabel;\nimport javax.swing.JPanel;\nimport javax.swing.border.EmptyBorder;\n\n\npublic class MainPanel extends JPanel\n{\n    private final JLabel label;\n\n    public MainPanel()\n    {\n        setLayout( new BorderLayout() );\n        setBorder( new EmptyBorder( 0, 20, 0, 0 ) );\n        setFocusable( true );\n\n        label = new JLabel( \"hello\" );\n        add( label, BorderLayout.CENTER );\n    }\n\n    public void setText( final String text )\n    {\n        label.setText( text );\n    }\n}\n\nLet’s instantiate a MainPanel and show it in a JFrame.\n\nvar frame = new JFrame( \"Keymaps Demo\" );\nvar panel = new MainPanel();\nframe.add( panel );\nframe.setPreferredSize( new Dimension( 200, 100 ) );\nframe.pack();\nframe.setVisible( true );\n\n\n\n\nMainPanel showing text “hello”\n\n\n\n/*\n#hide\n*/\nimport javax.swing.JComponent;\nimport javax.swing.SwingUtilities;\n\nTo set up ui-behaviour for the panel, we first need an instance of InputActionBindings\n\nimport org.scijava.ui.behaviour.util.InputActionBindings;\n\nvar bindings = new InputActionBindings();\n\nInputActionBindings bind inputs to actions.\nThis is of course exactly what AWT/Swing’s Key Bindings framework (InputMap, ActionMap) does. InputActionBindings adds very little over that; basically only more convenient InputMap chaining.\nSide note: The initial purpose of ui-behaviour was to offer a similar framework for mouse clicks, scrolls, drags, etc. Modeled after InputMap and ActionMap, there are InputTriggerMap and BehaviourMap. Analogous to InputActionBindings there is TriggerBehaviourBindings.\nAnyway, we connect the InputActionBindings instance to our MainPanel as follows.\n\nSwingUtilities.replaceUIActionMap(\n    panel,\n    bindings.getConcatenatedActionMap() );\nSwingUtilities.replaceUIInputMap(\n    panel, JComponent.WHEN_ANCESTOR_OF_FOCUSED_COMPONENT,\n    bindings.getConcatenatedInputMap() );\n\nInputActionBindings manages a chain of InputMap/ActionMap pairs. An Actions object encapsulates one such pair, and feeds new action definitions into it. We create a new Actions (the constructor arguments don’t matter for now) …\n\nimport org.scijava.ui.behaviour.io.InputTriggerConfig;\nimport org.scijava.ui.behaviour.util.Actions;\n\nvar actions = new Actions( new InputTriggerConfig(), \"demo\" );\n\n… and we add the pair to our InputActionBindings under the name “actions”.\n\nactions.install( bindings, \"actions\" );\n\n(We could use the name later to remove, replace, or temporarily block the InputMap/ActionMap pair.)\nThe actions instance is now connected to the panel via bindings. We can finally use it to add new shortcuts.\n\nactions.runnableAction(\n    () -&gt; panel.setText( \"Action A triggered\" ),\n    \"Action A\",\n    \"SPACE\", \"A\" );\n\nThe actions.runnableAction method takes the following arguments\npublic void runnableAction(\n    final Runnable runnable,\n    final String name,\n    final String... defaultKeyStrokes )\n\nA Runnable to run when the action is triggered.\nA unique name for the action (this will be used as the actions key in the underlying InputMap/ActionMap.\nZero or more keystrokes that should trigger the action.\n\nHere for example, the Runnable sets the text “Action A triggered” in the panel label. It is added under the name “Action A”, and triggered by the “SPACE” key, or the “A” key by default. The syntax for key strokes is described here.\nLet’s add a few more actions.\n\nactions.runnableAction(\n    () -&gt; panel.setText( \"Action B triggered\" ),\n    \"Action B\",\n    \"B\", \"shift B\" );\nactions.runnableAction(\n    () -&gt; panel.setText( \"Action C triggered\" ),\n    \"Action C\",\n    \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\", \"0\" );\n\nNow we can use these defined shortcuts to run these three actions (which will change the text label to “Action A/B/C triggered”.  You can find the full example on github."
  },
  {
    "objectID": "blog/2022-08-08-keymaps/2022-08-08-keymaps.html#making-shortcuts-configurable",
    "href": "blog/2022-08-08-keymaps/2022-08-08-keymaps.html#making-shortcuts-configurable",
    "title": "User-configurable Keymaps",
    "section": "",
    "text": "Another goal of ui-behaviour is to make mouse and key bindings easily configurable by the user (for example through config files).\nThis is the purpose of the Actions constructor arguments\nvar action = new Actions( new InputTriggerConfig(), \"demo\" );\nThe first argument is a InputTriggerConfig, and after that one or more String contexts are given (more on that later).\nThe InputTriggerConfig contains is basically a map from action names to key bindings. When adding a new action, for example like this:\nactions.runnableAction(\n    () -&gt; mainPanel.setText( \"Action B triggered\" ),\n    \"Action B\",\n    \"B\", \"shift B\" );\nthen actions will first look into its InputTriggerConfig to check whether any key binding is associated with the respective action name (“Action B”). If nothing is defined in the InputTriggerConfig then (and only then) the specified default key bindings will be used (\"B\" and \"shift B\").\n\n\nSo far, we just used a new, empty InputTriggerConfig, meaning we just get the specified defaults, which is exactly what we want for prototyping. If the project becomes more mature, and we want to change the config from outside, we can load the InputTriggerConfig from a config file.\n\nimport org.scijava.ui.behaviour.io.yaml.YamlConfigIO;\n\nReader reader = new FileReader( \"config.yaml\" );\nvar config = new InputTriggerConfig( YamlConfigIO.read( reader ) );\n\nThe config.yaml file looks like this:\n---\n- !mapping\naction: Action A\ncontexts: [demo]\ntriggers: [SPACE, A]\n- !mapping\naction: Action B\ncontexts: [demo]\ntriggers: [N]\nThe format should be more or less self-explanatory.\nThe loaded config should now map the String \"Action A\" to the Set of Strings {\"SPACE\", \"A\"}, and \"Action B\" to {\"N\"}. We could set up actions with the loaded config in the constructor, and then define the same actions as in the previous example.\nAlternatively, we can just update the existing Actions with the new config.\n\nactions.updateKeyConfig(config, false);\n\nThe config contains bindings for “Action A” and “Action B”. These will override the specified default bindings. So “Action A” will be triggered by the “SPACE” or “A” keys, and “Action B” will be triggered by “N”.\nThe config doesn’t specify anything for “Action C”, so that will be triggered by the programmatically specified defaults, that is, “1”, “2”, etc.\n\n\n\nBesides the InputTriggerConfig, the Actions constructor also requires one ore more String... context arguments.\nThe idea is that the same action (or at least action name) might occur in different contexts, that is, different tools, different windows of the same tool, etc. For example, an action named “Undo” could occur in many contexts and it would be nice to be able to assign different shortcuts, depending on context.\nTherefore, an InputTriggerConfig does not directly map action to shortcuts, but rather maps (action, context) pairs to shortcuts, where action and context are both Strings. So, for example, (\"Undo\", \"bdv\") can map to a different shortcut than (\"Undo\", \"paintera\").\nThe context arguments given in the Actions constructor specify which subsets of key bindings defined in the InputTriggerConfig should be considered. In the above example, we have\nvar actions = new Actions( config, \"demo\" )\nThis actions will pick up bindings for (\"Undo\", \"demo\") from the config, but not (\"Undo\", \"bdv\") for example.\n\n\n\nThere is a special trigger \"not mapped\" that can be used to specify that a particular action should not be associated to any shortcut. For example, if we add\n- !mapping\naction: Action C\ncontexts: [demo]\ntriggers: [not mapped]\nto the config.yaml file, then “Action C” will be disabled, that is, the programmatic defaults “1”, “2”, etc., will not be used.\nYou can find the full example on github."
  },
  {
    "objectID": "blog/2022-08-08-keymaps/2022-08-08-keymaps.html#configuring-shortcuts-through-the-ui",
    "href": "blog/2022-08-08-keymaps/2022-08-08-keymaps.html#configuring-shortcuts-through-the-ui",
    "title": "User-configurable Keymaps",
    "section": "",
    "text": "Being able to define shortcuts through a config file is useful. The config files can be edited, and distributed between different users or computers.\nEven more comfortable is to be able to modify shortcuts directly through the UI, at runtime.\n\n\nFor this, we use bdv.ui.settings.SettingsPanel. This panel implements a typical Preferences layout (like it’s used in Eclipse, for example) with a tree of preferences sections on the left, the selected section on the right, and Apply, Ok, Cancel buttons on the bottom.\nThe following PrefererencesDialog contains only the SettingsPanel, and a method addPage() to adds new sections (bdv.ui.settings.SettingsPage) to the preferences tree.\n\n/*\n#hide\n*/\nimport java.awt.Frame;\nimport java.awt.event.WindowAdapter;\nimport java.awt.event.WindowEvent;\n\nimport javax.swing.JDialog;\nimport javax.swing.WindowConstants;\n\n\nimport bdv.ui.settings.SettingsPage;\nimport bdv.ui.settings.SettingsPanel;\n\npublic class PreferencesDialog extends JDialog\n{\n    private final SettingsPanel settingsPanel;\n\n    public PreferencesDialog( final Frame owner )\n    {\n        super( owner, \"Preferences\", false );\n        settingsPanel = new SettingsPanel();\n        settingsPanel.onOk( () -&gt; setVisible( false ) );\n        settingsPanel.onCancel( () -&gt; setVisible( false ) );\n\n        setDefaultCloseOperation( WindowConstants.HIDE_ON_CLOSE );\n        addWindowListener( new WindowAdapter()\n        {\n            @Override\n            public void windowClosing( final WindowEvent e )\n            {\n                settingsPanel.cancel();\n            }\n        } );\n\n        getContentPane().add( settingsPanel, BorderLayout.CENTER );\n        pack();\n    }\n\n    public void addPage( final SettingsPage page )\n    {\n        settingsPanel.addPage( page );\n        pack();\n    }\n}\n\nLet’s instantiate a PreferencesDialog for our example, and add a keyboard shortcut (command-comma or control-comma) to show it.\n\nvar preferencesDialog = new PreferencesDialog( frame );\nactions.runnableAction(\n    () -&gt; preferencesDialog.setVisible( !preferencesDialog.isVisible() ),\n    \"Preferences\",\n    \"meta COMMA\", \"ctrl COMMA\" );\n\nNext, we want to add a preferences section for configuring shortcuts. There is bdv.ui.keymap.KeymapSettingsPage that we can readily use. In the end this will give us something like this:  What remains to be done is to fill the settings page with a list of configurable actions.\n\n\n\nSpecifially, we need to supply the KeymapSettingsPage with a list of existing actions, with short textual descriptions. This is done by creating a CommandDescriptions object and adding the configurable actions.\n\nimport org.scijava.ui.behaviour.io.gui.CommandDescriptions;\n\nvar descriptions = new CommandDescriptions();\n\ndescriptions.setKeyconfigContext( \"demo\" );\n\ndescriptions.add( \"Action A\", new String[] { \"SPACE\" }, \"trigger Action A\" );\ndescriptions.add( \"Action B\", new String[] { \"B\", \"shift B\" }, \"trigger Action B\" );\n\nFor each action, we add its name and default shortcuts in the same way we did when creating the action, and a short description (this is just for showing to the user, so can be left empty if you’re lazy…).\nThe other thing we need to supply to the KeymapSettingsPage is a KeymapManager. KeymapManager maintains a set of named Keymaps (some built-in, some user-defined). A Keymap is a simple container for a InputTriggerConfig, adding just a name and support for listeners to be notified when the InputTriggerConfig changes.\nOur KeymapManager extends the existing AbstractKeymapManager base class. The only thing that needs to be done is providing one or more default Keymaps. We can build a default keymap from the above descriptions. (But they could also be loaded from resources, build manually, …)\n\nimport bdv.ui.keymap.AbstractKeymapManager;\nimport bdv.ui.keymap.Keymap;\n\nvar defaultKeymap = new Keymap( \"Default\", descriptions.createDefaultKeyconfig() );\n\n/**\n * Manages a collection of {@link Keymap}.\n */\npublic class KeymapManager extends AbstractKeymapManager&lt; KeymapManager &gt;\n{\n    @Override\n    protected List&lt; Keymap &gt; loadBuiltinStyles()\n    {\n        return Collections.singletonList( defaultKeymap );\n    }\n\n    @Override\n    public void saveStyles()\n    {\n        // not implemented.\n        // Here we would save user defined keymaps to YAML files, for example.\n    }\n}\n\nWe create a KeyMapManager instance and add it to the Preferences dialog (via KeymapSettingsPage).\n\nimport bdv.ui.keymap.KeymapSettingsPage;\n\nvar keymapManager = new KeymapManager();\npreferencesDialog.addPage(\n        new KeymapSettingsPage( \"Keymap\", keymapManager, new KeymapManager(), descriptions ) );\n\nThe KeyMapManager (via its base class) exposes the user-selected keymap. We set that for our actions object. We also add a listener that refreshes actions keybinding when that keymap changes.\n\nvar keymap = keymapManager.getForwardSelectedKeymap();\nactions.updateKeyConfig( keymap.getConfig(), false );\nkeymap.updateListeners().add(\n    () -&gt; actions.updateKeyConfig( keymap.getConfig(), false )\n);\n\ntrue\n\n\nThat’s it. The user can now use the Preferences dialog to define custom keymaps with shortcuts to their liking, and switch between different keymaps. (Use command-comma or control-comma to show the preferences dialog).\nYou can find the full example on github."
  },
  {
    "objectID": "blog/2022-08-08-keymaps/2022-08-08-keymaps.html#making-action-descriptions-discoverable",
    "href": "blog/2022-08-08-keymaps/2022-08-08-keymaps.html#making-action-descriptions-discoverable",
    "title": "User-configurable Keymaps",
    "section": "",
    "text": "Keeping the list of existing actions (that is, the CommandDescriptions) up to date is tedious. Actions that should appear in the config dialog may be scattered through your own code and dependencies. This can be somewhat automated with CommandDescriptionProviders. These are scijava @Plugins that can be discovered at runtime.\n\nimport org.scijava.plugin.Plugin;\nimport org.scijava.ui.behaviour.io.gui.CommandDescriptionProvider;\n\nvar DEMO_SCOPE = new CommandDescriptionProvider.Scope( \"tpietzsch.keymap\" );\nvar DEMO_CONTEXT = \"demo\";\n\n/*\n * Command descriptions for all provided commands\n */\n@Plugin( type = CommandDescriptionProvider.class )\npublic static class MyActionDescriptions extends CommandDescriptionProvider\n{\n    public MyActionDescriptions()\n    {\n        super( DEMO_SCOPE, DEMO_CONTEXT );\n    }\n\n    @Override\n    public void getCommandDescriptions( final CommandDescriptions descriptions )\n    {\n        descriptions.add( \"Action A\", new String[] { \"SPACE\" }, \"trigger Action A\" );\n        descriptions.add( \"Action B\", new String[] { \"B\", \"shift B\" }, \"trigger Action B\" );\n    }\n}\n\nFor discovery, we use a CommandDescriptionsBuilder\n\nimport org.scijava.Context;\nimport org.scijava.plugin.PluginService;\nimport org.scijava.ui.behaviour.io.gui.CommandDescriptionsBuilder;\n\nvar context = new Context( PluginService.class );\nvar builder = new CommandDescriptionsBuilder();\ncontext.inject( builder );\n\nbuilder.discoverProviders( DEMO_SCOPE );\n\nNote the use of DEMO_SCOPE here. The same scope is also given in the MyActionDescriptions constructor. The discoverProviders() method takes an optional scope argument, and will only discover CommandDescriptionProvider that match this scope. If no scope is given, all CommandDescriptionProvider on the classpath will be discovered. For example within Fiji, that would include actions from Mastodon and BigDataViewer.\nUnfortunately, the @Plugin annotations do not work for classes defined in JShell (used by this notebook). As a workaround, we can add MyActionDescriptions manually.\n\nbuilder.addManually( new MyActionDescriptions(), DEMO_CONTEXT );\n\nAfter we add everything we need to the builder, we can get the Descriptions.\n\nvar descriptions = builder.build();\n\nYou can find the full example on github."
  },
  {
    "objectID": "blog/2022-08-08-keymaps/2022-08-08-keymaps.html#recommended-pattern-for-defining-actions",
    "href": "blog/2022-08-08-keymaps/2022-08-08-keymaps.html#recommended-pattern-for-defining-actions",
    "title": "User-configurable Keymaps",
    "section": "",
    "text": "Action definitions in BigDataViewer and Mastodon are organized in the following way.\nA set of related actions is collected into a MyActions (for example) class. Action names and default shortcuts are defined as public static final constants, because they are used both for defining the actions, and for creating action Descriptions.\nThe actions contained in MyActions are described in a public static inner class Descriptions extends CommandDescriptionProvider.\nIn the Descriptions constructor, we give a scope for the respective library / tool. Ideally, the scope should be defined public static somewhere so that is can easily used outside the component to discover its actions. For example, BigDataViewer uses this scope. If another tool (BigStitcher, BigWarp, etc.) wants to include BDV shortcuts into its customizable keymaps, they can be easily discovered like that.\n\nimport org.scijava.plugin.Plugin;\nimport org.scijava.ui.behaviour.io.gui.CommandDescriptionProvider;\n\nfinal var DEMO_SCOPE = new CommandDescriptionProvider.Scope( \"tpietzsch.keymap-idiom\" );\nfinal var DEMO_CONTEXT = \"demo\";\n\npublic class MyActions\n{\n    // define action name constants\n    public static final String ACTION_A = \"Action A\";\n    public static final String ACTION_B = \"Action B\";\n    public static final String PREFERENCES = \"Preferences\";\n\n    // define default shortcut constants\n    public static final String[] ACTION_A_KEYS = { \"SPACE\" };\n\n    public static final String[] ACTION_B_KEYS = { \"B\", \"shift B\" };\n    public static final String[] PREFERENCES_KEYS = { \"meta COMMA\", \"ctrl COMMA\" };\n\n\n    /*\n     * Command descriptions for all provided commands\n     */\n    @Plugin( type = CommandDescriptionProvider.class )\n    public static class Descriptions extends CommandDescriptionProvider\n    {\n        public Descriptions()\n        {\n            super( DEMO_SCOPE, DEMO_CONTEXT );\n        }\n\n        @Override\n        public void getCommandDescriptions( final CommandDescriptions descriptions )\n        {\n            descriptions.add( ACTION_A, ACTION_A_KEYS, \"trigger Action A\" );\n            descriptions.add( ACTION_B, ACTION_B_KEYS, \"trigger Action B\" );\n            descriptions.add( PREFERENCES, PREFERENCES_KEYS, \"Show the Preferences dialog.\" );\n        }\n    }\n\n    \n    /**\n     * Install into the specified {@link Actions}.\n     */\n    public static void install( final Actions actions, final MainPanel mainPanel, final PreferencesDialog preferencesDialog )\n    {\n        actions.runnableAction( () -&gt; mainPanel.setText( \"Action A triggered\" ),\n                ACTION_A, ACTION_A_KEYS );\n        actions.runnableAction( () -&gt; mainPanel.setText( \"Action B triggered\" ),\n                ACTION_B, ACTION_B_KEYS );\n        actions.runnableAction( () -&gt; preferencesDialog.setVisible( !preferencesDialog.isVisible() ),\n                PREFERENCES, PREFERENCES_KEYS );\n    }\n}\n\nMyActions contains one install method that installs all actions into a provided Actions argument. Ideally, MyActions is stateless, and install method is static.\nThe remaining arguments to install are whatever is needed to create the actions. In the example, the mainPanel is needed to create “Action A” and “Action B”, and the preferencesDialog is needed to create the action to show/hide it.\nSo, MyActions.install(...) is called to install into a provided Actions. Usually every frame/panel in the application should have an Actions instance, which is linked to the KeymapManager so that keymap updates propagate correctly.\nAnd that’s it… This is currently the recommended way to structure and bundle action definitions. You can find the full example on github.\nSee BigDataViewer’s NavigationActions as an example “in the wild”. For behaviours (mouse gestures, etc.) the structure is the same. See BigDataViewer’s TransformEventHandler2D for example."
  },
  {
    "objectID": "blog/2022-09-14-how-to-display-imglib2-data/2022-09-14-how-to-display-imglib2-data.html",
    "href": "blog/2022-09-14-how-to-display-imglib2-data/2022-09-14-how-to-display-imglib2-data.html",
    "title": "How to display ImgLib2 data in a notebook",
    "section": "",
    "text": "How to display ImgLib2 data in a notebook?\n\nRender ImgLib2 data into notebook objects\n\nIn this notebook, we will explore how to store, process and visualize data with ImgLib2 in a notebook.\nFirst let’s add the necessary dependencies. We will use ImageJ to load example images and to generate RenderedImage outputs that we can use to render in the notebook. Then, we will import ImgLib2 and the modules to share data between ImgLib2 and ImageJ and the imglib2-realtransform module that includes various transformations.\n\n%mavenRepo scijava.public https://maven.scijava.org/content/groups/public\n\n%maven net.imglib2:imglib2:6.0.0\n%maven jitk:jitk-tps:3.0.3\n%maven net.imagej:ij:1.53t\n%maven net.imglib2:imglib2-ij:2.0.0-beta-46\n%maven net.imglib2:imglib2-realtransform:3.1.2\n\nLet’s open one of ImageJ’s example images and show it in the notebook. This uses Spencer Park’s image renderer:\n\nimport ij.*;\n\nvar imp = IJ.openImage(\"https://mirror.imagej.net/ij/images/clown.jpg\");\nimp.getBufferedImage();\n\n\n\n\n\n\n\n\nIf we want to work with this image in ImgLib2, we need to provide it as an ImgLib2 interface:\n\nimport net.imglib2.*;\nimport net.imglib2.img.imageplus.*;\n\nvar imp = IJ.openImage(\"https://mirror.imagej.net/ij/images/clown.jpg\");\n// for later use without the compiler losing its mind, we must provide type information\n// for the ImagePlus wrapper, so let's not use var here\nRandomAccessibleInterval&lt;?&gt; rai = ImagePlusImgs.from(imp);\nrai;\n\nIntImagePlus [320x200]\n\n\nThere is no default renderer for ImgLib2 interfaces available to the notebook kernel, so we see a default String representation of the result (when rendering this cell the first time). So let’s register some simple renderers that use ImgLib2’s ImageJ bridge and Spencer Park’s image renderer to render ImgLib2 data into the notebook. We add a version that renders the first 2D slice of a RandomAccessibleInterval and a second version that renders a default interval 512x512+0+0 of the 2D slice at position 0 in all other dimensions of an infinite RandomAccessible.\n\nimport io.github.spencerpark.jupyter.kernel.display.common.*;\nimport io.github.spencerpark.jupyter.kernel.display.mime.*;\nimport net.imglib2.img.display.imagej.*;\nimport net.imglib2.view.*;\n\ngetKernelInstance().getRenderer().createRegistration(RandomAccessibleInterval.class)\n        .preferring(MIMEType.IMAGE_PNG)\n        .supporting(MIMEType.IMAGE_JPEG, MIMEType.IMAGE_GIF)\n        .register((rai, context) -&gt; Image.renderImage(\n                ImageJFunctions.wrap(rai, rai.toString()).getBufferedImage(),\n                context));\n\ngetKernelInstance().getRenderer().createRegistration(RandomAccessible.class)\n        .preferring(MIMEType.IMAGE_PNG)\n        .supporting(MIMEType.IMAGE_JPEG, MIMEType.IMAGE_GIF)\n        .register((ra, context) -&gt; Image.renderImage(\n                ImageJFunctions.wrap(\n                        Views.interval(\n                                ra,\n                                new FinalInterval(\n                                        Arrays.copyOf(\n                                                new long[]{512, 512},\n                                                ra.numDimensions()))),\n                        ra.toString()).getBufferedImage(),\n                context));\n\nNow let’s try the same again:\n\nvar imp = IJ.openImage(\"https://mirror.imagej.net/ij/images/clown.jpg\");\n// for later use without the compiler losing its mind, we must provide type information\n// for the ImagePlus wrapper, so let's not use var here\nRandomAccessibleInterval&lt;?&gt; rai = ImagePlusImgs.from(imp);\nrai;\n\n\n\n\n\n\n\n\nOk, great! Let’s try the ‘infinite’ version:\n\nvar ra = Views.extendBorder(rai);\nra;\n\n\n\n\n\n\n\n\nWonderful! We can of course still render a String representation or alternative encodings with the injected display methods of the kernel:\n\ndisplay(rai, \"text/plain\");\ndisplay(ra, \"text/plain\");\ndisplay(rai, \"image/jpeg\");\ndisplay(ra, \"image/gif\");\n\nIntImagePlus [320x200]\n\n\nnet.imglib2.view.ExtendedRandomAccessibleInterval@7b93c33\n\n\n\n\n\n\n\n\n\nnet.imglib2.view.ExtendedRandomAccessibleInterval@7b93c33\n\n\n83cb29e1-36d5-4c3d-957c-4f0cc021af97\n\n\nYou may have noticed that the output of this cell ends with an obscure identifier. We see this, because we did not catch the output of the display method which provides an identifier for the output object that it generates. This identifier can be used to update the contents of this object. We can use this to render simple animations, e.g. to slice through a 3D volume. Let’s try this with a 3D volume from the ImageJ example images:\n\nvar imp = IJ.openImage(\"https://mirror.imagej.net/ij/images/flybrain.zip\");\nRandomAccessibleInterval&lt;?&gt; rai = ImagePlusImgs.from(imp);\nvar refSlice = display(Views.hyperSlice(rai, 2, rai.dimension(2) / 2), \"image/jpeg\");\nvar refLabel = display(\"slice \" + rai.dimension(2) / 2);\nfor (int z = 0; z &lt; rai.dimension(2); ++z) {\n    var slice = Views.hyperSlice(rai, 2, z);\n    updateDisplay(refSlice, slice, \"image/jpeg\");\n    updateDisplay(refLabel, \"slice \" + z);\n    Thread.sleep(100);\n}\n// for static notebook export\nupdateDisplay(refSlice, Views.hyperSlice(rai, 2, rai.dimension(2) / 2), \"image/jpeg\");\n\n\n\n\n\n\n\n\nslice 56\n\n\nOf course, you can only see the animation if you actually run the notebook cell. In a future iteration, we are planning to implement an animated GIF generator for offline animations, but not this time. Let’s see what else we can do with these renderers.\nFirst, let’s apply some transformations to images. Already in the above border extension example as well as in the slicing animation, we have used ImgLib2’s default behavior to apply transformations lazily, i.e. only when a ‘pixel’ is actually queried (e.g. to render it into a RenderedImage raster), the transformations are applied. Transformations can be applied to both coordinates and values. Lets apply some transformations to values:\n\nimport net.imglib2.converter.*;\nimport net.imglib2.type.numeric.*;\n\nvar imp = IJ.openImage(\"https://mirror.imagej.net/ij/images/clown.jpg\");\nRandomAccessibleInterval&lt;ARGBType&gt; rai = ImagePlusImgs.from(imp);\ndisplay(Converters.argbChannel(rai, 1));\ndisplay(\"red\");\ndisplay(Converters.argbChannel(rai, 2));\ndisplay(\"green\");\ndisplay(Converters.argbChannel(rai, 3));\ndisplay(\"blue\");\n\ndisplay(\n        Converters.&lt;ARGBType, ARGBType&gt;convert2(\n                rai,\n                (in, out) -&gt; {\n    \n                    final int argb = in.get();\n                    final double grey = 0.3 * ARGBType.red(argb) + 0.6 * ARGBType.green(argb) + 0.1 * ARGBType.blue(argb);\n                    out.set(ARGBType.rgba(255 - grey, grey, grey, 255));\n                },\n                ARGBType::new));\ndisplay(\"grey to red-cyan ramp\");\n\n\n\n\n\n\n\n\nred\n\n\n\n\n\n\n\n\n\ngreen\n\n\n\n\n\n\n\n\n\nblue\n\n\n\n\n\n\n\n\n\ngrey to red-cyan ramp\n\n\nb677ba7f-39df-4995-9861-d1c75f28d437\n\n\nAnd now some integer coordinate transformations:\n\ndisplay(Views.invertAxis(rai, 0));\ndisplay(\"flip axis 0\");\n\ndisplay(Views.permute(rai, 0, 1));\ndisplay(\"permute axes\");\n\ndisplay(Views.extendMirrorSingle(rai));\ndisplay(\"mirror extension without repeated border pixels\");\n\ndisplay(Views.subsample(Views.shear(Views.extendPeriodic(rai), 0, 1), 3, 1));\ndisplay(\"extend periodically, shear axis 1 into axis 0, subsample by (3, 1)\");\n\n\n\n\n\n\n\n\nflip axis 0\n\n\n\n\n\n\n\n\n\npermute axes\n\n\n\n\n\n\n\n\n\nmirror extension without repeated border pixels\n\n\n\n\n\n\n\n\n\nextend periodically, shear axis 1 into axis 0, subsample by (3, 1)\n\n\n2e864958-c2a5-4cf2-91cf-c74e2788bbfc\n\n\nWhile most trivial integer transformations such as flipping axes work on intervals, you probably noticed that we had to extend the image to infinity in order to shear it, so ImgLib2 can provide values for coordinates outside of the source interval. For real coordinate transformations we will also need to interpolate values at non-integer coordinates. Finally, in order to render the result, we have to read it from a raster. Let’s do this:\n\nimport net.imglib2.interpolation.randomaccess.*;\nimport net.imglib2.realtransform.*;\n\nvar imp = IJ.openImage(\"https://mirror.imagej.net/ij/images/clown.jpg\");\nRandomAccessibleInterval&lt;ARGBType&gt; rai = ImagePlusImgs.from(imp);\nvar ra = Views.extendValue(rai, new ARGBType(0xff00ff00)); // &lt; green background\nvar interpolated = Views.interpolate(ra, new ClampingNLinearInterpolatorFactory&lt;&gt;()); // n-linear interpolation\n/**\n * This would be\n * var interpolated = Views.interpolate(ra, new NLinearInterpolatorFactory&lt;&gt;());\n * if you have no concern about value overflows\n */\nvar affine = new AffineTransform2D();\nvar transformed = Views.interval(RealViews.affine(interpolated, affine), rai); // shortcut for affines\nvar refImage = display(transformed, \"image/jpeg\");\nvar refLabel = display(\"\", \"text/html\");\n\nfinal int steps = 20;\nfor (int i = 0; i &lt; steps; ++i) {\n    affine.translate(-rai.dimension(0) / 2, -rai.dimension(1) / 2);\n    affine.rotate(Math.PI / 6.0 / steps);\n    affine.scale(1.0 + 0.7 / steps);\n    affine.translate(rai.dimension(0) / 2, rai.dimension(1) / 2);\n    \n    updateDisplay(refImage, Views.interval(transformed, rai), \"image/jpeg\");\n    updateDisplay(\n            refLabel,\n            String.format(\"\"\"\n                            &lt;p&gt;affine transformation matrix:&lt;/p&gt;\n                            &lt;table&gt;\n                            &lt;tr&gt;&lt;td&gt;%.2f&lt;/td&gt;&lt;td&gt;%.2f&lt;/td&gt;&lt;td&gt;%.2f&lt;/td&gt;&lt;/tr&gt;\n                            &lt;tr&gt;&lt;td&gt;%.2f&lt;/td&gt;&lt;td&gt;%.2f&lt;/td&gt;&lt;td&gt;%.2f&lt;/td&gt;&lt;/tr&gt;\n                            &lt;/table&gt;\"\"\",\n                    affine.get(0, 0), affine.get(0, 1), affine.get(0, 2),\n                    affine.get(1, 0), affine.get(1, 1), affine.get(1, 2)), \"text/html\");\n    Thread.sleep(100);\n}\n\n\n\n\n\n\n\n\naffine transformation matrix:\n\n\n\n\n1.72\n-0.99\n-16.22\n\n\n0.99\n1.72\n-231.50\n\n\n\n\n\nAffine transformation are probably the most well known and simple real coordinate transformations, but there are many more. Let’s try a ThinplateSplineTransform and format text output with markdown:\n\nvar refImage = display(rai, \"image/jpeg\");\nvar refLabel = display(\"\", \"text/markdown\");\n\nint steps = 20;\ndouble stretch = 40;\nfor (int i = 0; i &lt; steps; ++i) {\n    final double offset = stretch * i / steps;\n    final double[][] p = {\n            {0, rai.dimension(0), 0, rai.dimension(0), rai.dimension(0) * 0.25, rai.dimension(0) * 0.75, rai.dimension(0) * 0.25, rai.dimension(0) * 0.75},\n            {0, 0, rai.dimension(1), rai.dimension(1), rai.dimension(1) * 0.25, rai.dimension(1) * 0.25, rai.dimension(1) * 0.75, rai.dimension(1) * 0.75}\n    };\n    final double[][] q = {\n            {0, rai.dimension(0), 0, rai.dimension(0),\n            rai.dimension(0) * 0.25 + offset , rai.dimension(0) * 0.75 - offset, rai.dimension(0) * 0.25 + offset, rai.dimension(0) * 0.75 - offset},\n            {0, 0, rai.dimension(1), rai.dimension(1),\n            rai.dimension(1) * 0.25 + offset, rai.dimension(1) * 0.25 + offset, rai.dimension(1) * 0.75 - offset, rai.dimension(1) * 0.75 - offset}\n    };\n    final var transform = new ThinplateSplineTransform(p, q);\n    final var warped = new RealTransformRandomAccessible&lt;&gt;(interpolated, transform);\n    String text = \"\"\"\nthinplate spline transformation controls points:\n            \n| | p&lt;sub&gt;x&lt;/sub&gt; | p&lt;sub&gt;y&lt;/sub&gt; | q&lt;sub&gt;x&lt;/sub&gt; | q&lt;sub&gt;y&lt;/sub&gt; |\n| --- | ---: | ---: | ---: | ---: |\n\"\"\";\n    for (int j = 0; j &lt; p[0].length; ++j)\n        text += String.format(\"\"\"\n| %d | %.2f | %.2f | %.2f | %.2f |\n\"\"\",\n                j, p[0][j], p[1][j], q[0][j], q[1][j]);                \n\n    updateDisplay(refImage, Views.interval(warped, rai), \"image/jpeg\");\n    updateDisplay(refLabel, text, \"text/markdown\");\n\n    Thread.sleep(100);\n}\n\n\n\n\n\n\n\n\nthinplate spline transformation controls points:\n\n\n\n\npx\npy\nqx\nqy\n\n\n\n\n0\n0.00\n0.00\n0.00\n0.00\n\n\n1\n320.00\n0.00\n320.00\n0.00\n\n\n2\n0.00\n200.00\n0.00\n200.00\n\n\n3\n320.00\n200.00\n320.00\n200.00\n\n\n4\n80.00\n50.00\n116.00\n86.00\n\n\n5\n240.00\n50.00\n204.00\n86.00\n\n\n6\n80.00\n150.00\n116.00\n114.00\n\n\n7\n240.00\n150.00\n204.00\n114.00"
  },
  {
    "objectID": "blog/2023-12-21-How-to-add-your-project-to-ecosystem-page/2023-12-21-How-to-add-your-project-to-ecosystem-page.html",
    "href": "blog/2023-12-21-How-to-add-your-project-to-ecosystem-page/2023-12-21-How-to-add-your-project-to-ecosystem-page.html",
    "title": "How to add your project to the Ecosystem page",
    "section": "",
    "text": "In this blogpost you will learn how you can list your project that leverage BDV or ImgLib2 on the Community Ecosystem webpage. First copy the template.qmd file found here  and edit it to your liking.\nThe header reads:\n---\ntitle : \"TEMPLATE software/plugin\"\ncategories: [ Fiji/ImageJ , BigDataViewer, imglib2]\nexecute:\necho: false\nabout:\nid: Aheading\ntemplate: jolla\nimage-shape: rounded\nimage-width: 15em\nlinks:\n- text: Contact\nicon: envelope\nhref: mailto:anemail@adress.com\n- text: Documentation\nicon: github\nhref: https://github.com/.../README.md\n- text: Publication\nicon: book\nhref: https://doi.org/....\n- text: Tutorial\nicon: youtube\nhref: https://www.youtube.com/watch?t...\n- text: Fiji-imageJ\nicon: image\nhref: https://imagej.net/plugins/..\n---\n\nFirst, these are the attributes you need to change\ntitle : \"TEMPLATE software/plugin\"\n\ncategories: [ Fiji/ImageJ , BigDataViewer, imglib2]\n\nlinks:\n- text: Contact\nicon: envelope\nhref: mailto:anemail@adress.com\n…\nThe links are shown on the bottom of the page to link to relevant project resources. If you would like to add change an icon e.g. icon: envelope you can find icons more here : https://icons.getbootstrap.com\nFurthermore, to add a logo or suitable picture you need to add \n![](name_of_imagefile){ \"here you set size limitations or alignment\"}\\\nfor example ![](Template.png){fig-align=\"left\" width=20% height=20%}\\\nor e.g. ![](Template.png){width=275}\nThis file needs to be in folder of the project (each project should get its own folder, ideally with same name as “title” ). You can find more info regarding adding figures in quarto here: https://quarto.org/docs/authoring/figures.html\nThen in the next section fill in relevant information about your project:\nFirst sentence will appear also on the ecosystem page...  \n\nshort description of your software \ne.g. text plus main features:\n\n* 1 \n* 2\n* 3\nFinally notice community manager OR make a pull request.\nDone ! :)"
  },
  {
    "objectID": "blog/2024-02-27-n5-tutorial-basic/index.html",
    "href": "blog/2024-02-27-n5-tutorial-basic/index.html",
    "title": "N5 API Basics",
    "section": "",
    "text": "This tutorial for Java developers covers the most basic functionality of the N5 API for storing large, chunked n-dimensional image data and structured metadata. The N5 API and documentation refer to n-dimensional images as “datasets”, terminology inherited from HDF5. We will use this terminology in this tutorial. If you are used to work with Python and Numpy, an n-dimensional image or dataset is what you know as an ndarray. We will learn about:"
  },
  {
    "objectID": "blog/2024-02-27-n5-tutorial-basic/index.html#readers-and-writers",
    "href": "blog/2024-02-27-n5-tutorial-basic/index.html#readers-and-writers",
    "title": "N5 API Basics",
    "section": "Readers and writers",
    "text": "Readers and writers\nN5Readers and N5Writers form the basis of the N5 API and allow you to read and write data, respectively. We generally recommend using an N5Factory to create readers and writers:\n\n\n// N5Factory can make N5Readers and N5Writers\nvar factory = new N5Factory();\n\n// trying to open a reader for a container that does not yet exist will throw an error \n// var n5Reader = factory.openReader(\"my-container.n5\");\n\n// creating a writer creates a container at the given location\n// if it does not already exist\nvar n5Writer = factory.openWriter(\"my-container.n5\");\n\n// now we can make a reader\nvar n5Reader = factory.openReader(\"my-container.n5\");\n\n// test if the container exists\nn5Reader.exists(\"\"); // true\n\n// \"\" and \"/\" both refer to the root of the container\nn5Reader.exists(\"/\"); // true\n\n\nThe N5 API gives you access to a number of different storage formats: HDF5, Zarr, and N5’s own format. N5Factory’s convenience methods try to infer the storage format from the extension of the path you provide:\n\n\nfactory.openWriter(\"my-container.h5\").getClass();   // HDF5 Format N5Writer\nfactory.openWriter(\"my-container.n5\").getClass();   // N5 Format   N5Writer\nfactory.openWriter(\"my-container.zarr\").getClass(); // Zarr Format N5Writer\n\n\nIn fact, it is possible to read with N5Writers since every N5Writer is also an N5Reader, so from now on we’ll just be using the n5Writer.\n\n\n\n\n\n\nTry it!\n\n\n\nWe use the the N5 storage format for the rest of the tutorial, but it will work just as well over either an HDF5 file or Zarr container."
  },
  {
    "objectID": "blog/2024-02-27-n5-tutorial-basic/index.html#groups",
    "href": "blog/2024-02-27-n5-tutorial-basic/index.html#groups",
    "title": "N5 API Basics",
    "section": "Groups",
    "text": "Groups\nN5 containers form hierarchies of groups - think “nested folders on your file system.” It’s easy to create groups and test if they exist:\n\n\nn5Writer.createGroup(\"foo\");\nn5Writer.createGroup(\"foo/bar\");\nn5Writer.createGroup(\"lorum/ipsum/dolor/sit/amet\");\n\nn5Writer.exists(\"lorum/ipsum\");      // true\nn5Writer.exists(\"not/a/real/group\"); // false\n\n\nThe list method lists groups that are children of the given group:\n\n\nn5Writer.list(\"\");     // [lorum, foo]\nn5Writer.list(\"foo\");  // [bar]\n\n\nand deepList recursively lists every descendent of the given group:\n\n\nArrays.toString(n5Writer.deepList(\"\"));\n\n[lorum, lorum/ipsum, lorum/ipsum/dolor, lorum/ipsum/dolor/sit, lorum/ipsum/dolor/sit/amet, foo, foo/bar]\n\n\n\nNotice that these methods only give information about what groups are present and do not provide information about metadata or datasets.\n\n\n\n\n\n\nNote\n\n\n\nSome storage / access systems (AWS-S3) separate permissions for reading and listing, meaning it may be possible to access data but not list."
  },
  {
    "objectID": "blog/2024-02-27-n5-tutorial-basic/index.html#datasets",
    "href": "blog/2024-02-27-n5-tutorial-basic/index.html#datasets",
    "title": "N5 API Basics",
    "section": "Datasets",
    "text": "Datasets\nN5 stores datasets (n-dimensional arrays) in particular groups in the hierarchy.\n\n\n\n\n\n\nWarning\n\n\n\nDatasets must be terminal (leaf) nodes in the container hierarchy - i.e. a dataset can not contain another group or dataset. (Is this strictly true? May be confusing with names like multiscale “datasets”)\n\n\nWe recommend using code from n5-ij or n5-imglib2 to write datasets. The examples in this post will use the latter.\nThe N5Utils class in n5-imglib2 has many useful methods, but in this post, we’ll cover simple methods for reading and writing. First, N5Utils.save writes a dataset and required metadata to the container at a group that you specify. The group will be created if it does not already exist. The parameters will be discussed in more detail below.\n\n\n// the parameters\nvar img = demoImage(64,64); // the image to write- size 64 x 64\nvar groupPath = \"data\"; \nvar blockSize = new int[]{32,32};\nvar compression = new GzipCompression();\n\n// save the image\nN5Utils.save(img, n5Writer, groupPath, blockSize, compression);\n\n\nYou can write in parallel by providing an ExecutorService to this variant of N5Utils.save\n\n\nvar exec = Executors.newFixedThreadPool(4); // with 4 parallel threads\nN5Utils.save(img, n5Writer, groupPath, blockSize, compression, exec);\n\n\nReading the dataset from the container is also easy with N5Utils.open :\n\n\nvar loadedImg = N5Utils.open(n5Writer, groupPath);\nUtil.getTypeFromInterval(loadedImg).getClass();      // FloatType\nArrays.toString(loadedImg.dimensionsAsLongArray());  // [64, 64]\n\n\n\n\n\n\n\n\nOverwriting data is possible\n\n\n\nThis save method DOES NOT perform any checks prior to writing data and will overwrite data that exists in the specified location. Be sure to check and take appropriate action if it is possible that data could already be at a particular location and container to avoid data loss or corruption.\n\n\nThis example shows that data can be over written:\n\n\n// overwrite our previous data\nvar img = ArrayImgs.unsignedBytes(2,2);\nN5Utils.save(img, n5Writer, groupPath, blockSize, compression);\n\n// load the new data, the old data are no longer accessible\nvar loadedImg = N5Utils.open(n5Writer, groupPath);\nArrays.toString(loadedImg.dimensionsAsLongArray());  // [2, 2]\n\n\n\nParameter details\n\ngroupPath\nis the location inside the container that will store the dataset. You can store an dataset at the root of a container by specifying \"\" or \"/\" as the groupPath. In this case, the container will only be able to store one dataset (see the warning above).\n\n\nblockSize\nis a very important parameter. HDF5, N5, and Zarr all break up the datasets they store into equally sized blocks or “chunks”. The block size parameter specifies the size of these blocks.\nFor the example above, we stored an image of size 64 x 64 using blocks sized 32 x 32. As a result, N5 uses four blocks to store the entire image:\n\n\n\nCode\nprintBlocks(\"my-container.n5/data\");\n\n\nmy-container.n5/data/1/1 is 1762 bytes\nmy-container.n5/data/1/0 is 2012 bytes\nmy-container.n5/data/0/1 is 1763 bytes\nmy-container.n5/data/0/0 is 2020 bytes\n\n\n\nQuiz: How many blocks would there be if the block size was 64 x 8?\n\n\nClick here to show the answer.\n\nThere would be eight blocks.\nOne block covers the first dimension, but it takes 8 blocks to cover the second dimension (\\(8 \\times 8 = 64\\)). Also demonstrated by the code below:\n\n\n// remove the old data\nn5Writer.remove(groupPath);\n\n// rewrite with a different block size\nvar blockSize = new int[]{64,8};\nN5Utils.save(img, n5Writer, groupPath, blockSize, compression);\n\n// how many blocks are there?\nprintBlocks(\"my-container.n5/data\");\n\nmy-container.n5/data/0/1 is 837 bytes\nmy-container.n5/data/0/7 is 847 bytes\nmy-container.n5/data/0/3 is 839 bytes\nmy-container.n5/data/0/6 is 844 bytes\nmy-container.n5/data/0/0 is 968 bytes\nmy-container.n5/data/0/4 is 846 bytes\nmy-container.n5/data/0/2 is 840 bytes\nmy-container.n5/data/0/5 is 847 bytes\n\n\n\n\n\n\n\n\n\n\nTry it!\n\n\n\nN5 lets you store your image in a single file if you want - just provide a block size that is equal to or larger than the image size.\n\n\n\n\ncompression\nEach block is compressed independently, using the specified compression. Use RawCompression to store blocks without compression.\n\n\n// rewrite without compression\nvar groupPath = \"dataNoCompression\"; \nvar blockSize = new int[]{32,32};\nvar compression = new RawCompression();\nN5Utils.save(img, n5Writer, groupPath, blockSize, compression);\n\n// what size are the blocks?\n\n\n\n\n\nCode\nprintBlocks(\"my-container.n5/dataNoCompression\");\n\n\nmy-container.n5/dataNoCompression/1/1 is 4108 bytes\nmy-container.n5/dataNoCompression/1/0 is 4108 bytes\nmy-container.n5/dataNoCompression/0/1 is 4108 bytes\nmy-container.n5/dataNoCompression/0/0 is 4108 bytes\n\n\n\nNotice that blocks were previously ~1700-2000 bytes and are now ~4100 without compression.\nThe available compression options at the time of this writing are:\n\nBloscCompression\nBzip2Compression\nGzipCompression\nLz4Compression\nRawCompression\nXzCompression\nZstandardCompression"
  },
  {
    "objectID": "blog/2024-02-27-n5-tutorial-basic/index.html#metadata",
    "href": "blog/2024-02-27-n5-tutorial-basic/index.html#metadata",
    "title": "N5 API Basics",
    "section": "Metadata",
    "text": "Metadata\nN5 can also store rich structured metadata in addition to array data. This tutorial will discuss basic, low-level metadata operations. Advanced operations and metadata standards may be described in a future tutorial.\n\nBasics\nN5Writers have a setAttribute method for writing metadata to the storage backend. It takes three arguments:\n&lt;T&gt; void setAttribute(String groupPath, String attributePath, T attribute)\n\ngroupPath : the group in which to store this metadata\nattributePath : the name of this attribute\nattribute : the metadata attribute to be stored. Can be an arbitrary type (denoted T).\n\n\n\n\n\n\n\nNote\n\n\n\nThere are differences between an attribute “name” and an attribute “path”, but attribute “paths” are an advanced topic and will be covered elsewhere.\n\n\nSimilarly, N5Readers have a getAttribute method:\n&lt;T&gt; T getAttribute(String groupPath, String attributePath, Class&lt;T&gt; clazz)\nThe last argument (Class&lt;T&gt;) lets you specify the type that getAttribute should return. An N5Exception will be thrown if the requested type can not be created from the requested attribute. If an attribute does not exist, null will be returned (see the last example of this section). Consider these examples:\n\n\n// create a group inside the container (think: \"folder\")\nvar groupName = \"put-data-in-me\";\nn5Writer.createGroup(groupName);\n\n// attributes have names and values\n// make an attribute called \"date\" with a String value\nvar attributeName = \"date\";\nn5Writer.setAttribute(groupName, attributeName, \"2024-Jan-01\");\n\n// Ask the N5 API to make a double array from the data attribute\n// it will try and fail, so an exception will be thrown\ntry {\n    var nothing = n5Writer.getAttribute(groupName, attributeName, double[].class);\n} catch( N5Exception e ) {\n    System.out.println(\"Error: could not get attribute as double[]\");\n}\n\n// get the value of the \"date\" attribute as a String\nString date = n5Writer.getAttribute(groupName, attributeName, String.class);\ndate\n\nError: could not get attribute as double[]\n\n\n2024-Jan-01\n\n\n\nSometimes it is possible to interpret an attribute as multiple different types:\n\n\nn5Writer.setAttribute(groupName, \"a\", 42);\nvar num = n5Writer.getAttribute(groupName, \"a\", double.class); // 42.0\nvar str = n5Writer.getAttribute(groupName, \"a\", String.class); // \"42\"\n\n\n\n\nRich metadata\nIt possible to save attributes of arbitrary types, enabling you to struture your metadata into classes that are easy to save and load directly. For example, if we define a metadata class FunWithMetadata:\n\n\n\nCode\nclass FunWithMetadata {\n    String name;\n    int number;\n    double[] data;\n    \n    public FunWithMetadata(String name, int number, double[] data) {\n        this.name = name;\n        this.number = number;\n        this.data = data;\n    }\n    public String toString(){\n        return String.format( \"FunWithMetadata{%s(%d): %s}\", \n            name, number, Arrays.toString(data));\n    }\n};\n\n\n\nthen make an instance and save it:\n\n\nvar metadata = new FunWithMetadata(\"Dorothy\", 2, new double[]{2.72, 3.14});\nn5Writer.setAttribute(groupName, \"metadata\", metadata);\n\n// get attribute as an instance of FunWithMetdata\nn5Writer.getAttribute(groupName, \"metadata\",  FunWithMetadata.class);\n\nFunWithMetadata{Dorothy(2): [2.72, 3.14]}\n\n\n\nTo retrieve all the metadata in a group as JSON:\n\n\n// get attribute as an instance of JsonElement\nn5Writer.getAttribute(groupName, \"/\", JsonElement.class);\n\n{\"date\":\"2024-Jan-01\",\"a\":42,\"metadata\":{\"name\":\"Dorothy\",\"number\":2,\"data\":[2.72,3.14]}}\n\n\n\n\n\nRemoving metadata\nYou can remove attributes by their name as well. To return the element that was removed, just provide the class for that element (this mirrors the remove method for Lists in Java.\n\n\n// set attributes\nn5Writer.setAttribute(groupName, \"sender\", \"Alice\");\nn5Writer.setAttribute(groupName, \"receiver\", \"Bob\");\n\n// notice that they're set\nn5Writer.getAttribute(groupName, \"sender\", String.class);   // Alice\nn5Writer.getAttribute(groupName, \"receiver\", String.class); // Bob\n\n// remove \"sender\"\nn5Writer.removeAttribute(groupName, \"sender\");\n\n// remove \"receiver\" and store result in a variable\nvar receiver = n5Writer.removeAttribute(groupName, \"receiver\", String.class); // Bob\n\nn5Writer.getAttribute(groupName, \"sender\", String.class);   // null\nn5Writer.getAttribute(groupName, \"receiver\", String.class); // null\n\n\n\n\nWorking with Dataset Metadata\nMetadata used to describe datasets can be get and set the same as all other metadata. However there are special DatasetAttributes methods to safely work with dataset metadata. N5Reader.getDatasetAttributes and N5Writer.setDatasetAttributes ensure the metadata is always a valid representation of dataset metadata. Setting DatasetAttributes however should only be done when the dataset is initially saved. This ensure the required metadata is tightly coupled with the data. For example, setting dataset metadata should be done through the N5Writer.createDataset methods (or indirectly through the N5Utils.save methods mentioned above)\n\n\nvar arrayMetadata = n5Writer.getDatasetAttributes(\"data\");\narrayMetadata.getDimensions();\narrayMetadata.getBlockSize();\narrayMetadata.getDataType();\narrayMetadata.getCompression();\n\n\n\n\n\n\n\n\nWarning\n\n\n\nThe attributes that N5 uses to read datasets can be set with setAttribute, and modifying them could corrupt your data. Do not manually set these attributes unless you absolutely know what you’re doing!\n\ndimensions\nblockSize\ndataType\ncompression\n\nThe attributes that describe datasets are also accessible using getAttribute, try running:\nn5Writer.getAttribute(\"data\", \"dimensions\", long[].class);\nthough using getDatasetAttributes().getDimensions() are generally recommended."
  },
  {
    "objectID": "blog/2024-02-27-n5-tutorial-basic/index.html#what-to-try-next",
    "href": "blog/2024-02-27-n5-tutorial-basic/index.html#what-to-try-next",
    "title": "N5 API Basics",
    "section": "What to try next",
    "text": "What to try next\n\nHow to work with the N5 API and ImgLib2"
  },
  {
    "objectID": "imglib1/iterating-through-pixel-data.html",
    "href": "imglib1/iterating-through-pixel-data.html",
    "title": "ImgLib1: Iterating through pixel data",
    "section": "",
    "text": "{% include warning/deprecated old=“ImgLib1” new=“ImgLib2” %}\nThe architecture of Imglib aims at completely separating the image - which can be seen as a data container - from the concrete basic data type it encapsulates. In practice, this means that you can write “blind” algorithms, which can safely ignore whether they operate on a uint8 image, a RGB image or a uint16 stack of 15 slices.\nThis in turn imposes a certain gymnastic when accessing the underlying data is involved. Here, we will make a brief introduction on how to do this with Imglib. We assume you want to use Imglib in a Java plugin, and that you are already familiar with Java itself.",
    "crumbs": [
      "ImgLib1: Iterating through pixel data"
    ]
  },
  {
    "objectID": "imglib1/iterating-through-pixel-data.html#the-image-objects",
    "href": "imglib1/iterating-through-pixel-data.html#the-image-objects",
    "title": "ImgLib1: Iterating through pixel data",
    "section": "The Image objects",
    "text": "The Image objects\nLet us suppose we want to access the data in an arbitrary image img. The a priori data type is unknown, which translates in declaring the variable img using generics:\nImage&lt;T&gt; img;\nwhere T is a type variable, representing the ’generic type of your image.\nThe mpicbg.imglib.image.Image is the mother object for your actual image; it contains all the information needed to display it and operate on it.\nImglib is built such that it is possible to have different ways to store the same underlying data in an Image, or storage strategies. This is done through the mpicbg.imglib.container.Container implementations, which is not the subject of this tutorial. Every Image object has a field that implements the Container interface, and deals with data storage.\nThe responsibility of retrieving, iterating over and modifying the data is implemented in a separate object hierarchy, all inheriting from the mpicbg.imglib.cursor.Cursor interface. As for data storage, multiple strategies are implemented for iterating. The goal of this page is to play with some of them and demonstrate their capabilities.",
    "crumbs": [
      "ImgLib1: Iterating through pixel data"
    ]
  },
  {
    "objectID": "imglib1/iterating-through-pixel-data.html#the-cursor-model",
    "href": "imglib1/iterating-through-pixel-data.html#the-cursor-model",
    "title": "ImgLib1: Iterating through pixel data",
    "section": "The Cursor model",
    "text": "The Cursor model\n\nCreating a plain cursor\nYou can create a plain cursor that will iterate over the pixels of an image very simply, by calling the createCursor() method over an Image object:\nfinal Image&lt;T&gt; img;\nfinal Cursor&lt;T&gt; cursor = img.createCursor();\n\n// we set all pixels to a certain value\nfinal T value;\n\n// Cursor implements java.lang.Iterable&lt;T&gt;\nfor ( final T pixel : cursor )\n    pixel.set( value ); \n\ncursor.close();\nNote that the cursor object has a type variable  identical to img’s type.\n\n\nIterating using a plain cursor\nWhat can we do with it? Briefly, it behaves like a specialized iterator. To move over the data we will use:\n\npublic void fwd() to move to the next position;\npublic boolean hasNext() to report if we finished iterating over all the data;\npublic void reset() to put back the cursor before the first data element;\npublic void close() to mark this cursor has not being use anymore.\n\nOther methods are available, but these four ones are enough to build a basic loop iterating over all the data. Here is an example that does so, using the bat cochlea example within ImageJ.\nimport ij.plugin.PlugIn;\nimport ij.IJ;\nimport ij.ImagePlus;\nimport mpicbg.imglib.cursor.Cursor;\nimport mpicbg.imglib.image.Image;\nimport mpicbg.imglib.image.ImagePlusAdapter;\nimport mpicbg.imglib.type.numeric.RealType;\n \npublic class Example_Cursors&lt;T extends RealType&lt;T&gt;&gt; implements PlugIn {\n \n    public void run(String arg) {\n\n        // Open the bat-cochlea example\n                String name = \"https://imagej.net/ij/images/bat-cochlea-volume.zip\";\n        ImagePlus imp = IJ.openImage(name);\n        imp.show();\n\n        // Convert it to Imglib image\n        Image&lt;T&gt; img = ImagePlusAdapter.wrap(imp);  \n        \n        // Create a plain cursor for it\n        Cursor&lt;T&gt; cursor = img.createCursor();\n\n        // Iterate over all the image\n        int pixel_count = 0;\n        while (cursor.hasNext()) {\n            cursor.fwd();\n            pixel_count++;\n        }\n        cursor.close();\n\n        IJ.write(\"Iterated over \"+pixel_count+\" pixels.\");\n    }\n}\nNote that this plugin does not do anything useful at all. However, it shows that such a cursor will iterate over all the data, not caring if there are multiple slices or frames. It reports having moved across 2 124 276 pixels, which is indeed the result of the product of all the dimension of the images: 121 × 154 × 114.\nNow, we could do something useful with the data itself, using the publicgetType() method that returns a mpicbg.imglib.type.Type object, responsible for making operations on the data itself. That is the subject of another tutorial, we limit ourselves here to iterate over the data.\n\n\nThe plain cursor perks\nIn the preceding example, we know that every pixel has been traversed by the cursor. However, we do not know in which order. In the general case, where no assumption is made on the storage strategy, it is not possible to predict what will be the traversal order. Imglib just ensures that the traversal is made in an optimized fashion.\nSo with a plain cursor iterating, you don’t know how it is made, but you are sure that it is the best way.",
    "crumbs": [
      "ImgLib1: Iterating through pixel data"
    ]
  },
  {
    "objectID": "imglib1/iterating-through-pixel-data.html#the-localizable-cursor",
    "href": "imglib1/iterating-through-pixel-data.html#the-localizable-cursor",
    "title": "ImgLib1: Iterating through pixel data",
    "section": "The localizable cursor",
    "text": "The localizable cursor\nAnother limitation of the plain cursor exemplified above, is that it does not report where it is at a given iteration step. If you need this information, you must create another cursor type from the image, called a LocalizableCursor. This is made through the call:\nLocalizableCursor&lt;T&gt; loc_cursor = img.createLocalizableCursor();\nIt adds the following method to the plain cursor:\n\npublic int[] getPosition() returns an array specifying the current position for each dimension; Warning: this methods creates a new int[] array every time and is therefor inefficient if called very often\npublic int getPosition( int dim ) returns the index of the position for the specified dimension number;\npublic void getPosition( int[] position ) store the position in the given array.\n\nIt does not allow to specify the position, it just reports its current position, whatever way it changes from one iteration to another. Just to demonstrate its usage, let us write a plugin that crawls through an image, and report the position of the brightest pixel (whatever this means).\nimport ij.plugin.PlugIn;\nimport ij.IJ;\nimport ij.ImagePlus;\nimport mpicbg.imglib.cursor.LocalizableCursor;\nimport mpicbg.imglib.image.Image;\nimport mpicbg.imglib.image.ImagePlusAdapter;\nimport mpicbg.imglib.type.numeric.RealType;\nimport mpicbg.imglib.algorithm.math.MathLib;\n\npublic class Localizable_Cursors&lt;T extends RealType&lt;T&gt;&gt; implements PlugIn {\n \n    public void run(String arg) {\n \n        // Open the M51 galaxy example\n                String name = \"https://imagej.net/ij/images/m51.tif\";\n        ImagePlus imp = IJ.openImage(name);\n        imp.show();\n \n        // Convert it to Imglib image\n        final Image&lt;T&gt; img = ImagePlusAdapter.wrap( imp );  \n \n        // Create a localizable cursor for it\n        final LocalizableCursor&lt;T&gt; loc_cursor = img.createLocalizableCursor();\n \n        // Create a Type variable to store the max value.\n        // We create it from the Image object so that they have compatible types\n                // As we cannot initialize it with the minimum value we have to init it with\n                // the first value later\n        T max = null; // consequently, it has the type &lt;T&gt;\n \n                // create an int[] array with correct dimensionality\n        final int[] max_position = img.createPositionArray();\n \n        // Iterate over all the image\n        while ( loc_cursor.hasNext() ) \n                {\n            loc_cursor.fwd();\n            T current_value = loc_cursor.getType();\n                        if ( max == null )\n                                 max = current_value.clone();\n \n                        // RealType implements java.lang.Comparable\n            if ( current_value.compareTo( max ) &gt; 0 ) \n                        {\n                                // save the max position, giving a pre-instantiated array is the fastest way \n                loc_cursor.getPosition( max_position );\n                                // we cannot simply copy references, this would cause a mess\n                max.set( current_value ); \n            }\n        }\n        loc_cursor.close();\n \n        // Make a nice string for position\n        String pos_str = MathLib.printCoordinates( max_position );\n                // every Type has a .toString() method (as has every Cursor)\n        IJ.write( \"Maximal pixel value of \" + max + \" found at position \" + pos_str );\n    }\n}\nEven for a dummy plugin, this is far from perfect. Indeed, it reports the position of the first maximum, in case there is multiple pixels that have the same maximal value. Since in the general case we do not know in which order the data is traversed, this might be of importance.",
    "crumbs": [
      "ImgLib1: Iterating through pixel data"
    ]
  },
  {
    "objectID": "imglib1/iterating-through-pixel-data.html#imposing-the-iteration-order",
    "href": "imglib1/iterating-through-pixel-data.html#imposing-the-iteration-order",
    "title": "ImgLib1: Iterating through pixel data",
    "section": "Imposing the iteration order",
    "text": "Imposing the iteration order\nNow of course, you would want to determine the way in which the data is traversed. There, a third kind of cursor comes at help, which extends the preceding ones. It is the LocalizableByDimCursor cursor. Is is created as before:\nLocalizableByDimCursor&lt;T&gt; locdim_cursor = img.createLocalizableByDimCursor();\nIt is flexible and complete, and have even options to specify how to create neighborhood and deal with neighborhood close to the image borders. We will just limit ourselves to its basic features, which are:\n\nThe ability to set the absolute current position:\n\npublic void setPosition( int position[] )\npublic void setPosition( int position, int dim )\npublic void setPosition( LocalizableCursor&lt;?&gt; cursor )\n\n\n\n\nThe ability to move relatively from the current position:\n\npublic void fwd( int dim )\npublic void bck( int dim )\npublic void move( int steps, int dim )\npublic void moveRel( int position[] )\n\n\nWe can use them to create a very basic Z maximal projection plugin, that will create a 2D image from a 3D stack by taking the maximal pixel value along the Z dimension for all X,Y. The following version is devoid of subtleties.\nimport ij.plugin.PlugIn;\nimport ij.IJ;\nimport ij.ImagePlus;\nimport ij.WindowManager;\nimport mpicbg.imglib.cursor.LocalizableByDimCursor;\nimport mpicbg.imglib.cursor.LocalizableCursor;\nimport mpicbg.imglib.image.Image;\nimport mpicbg.imglib.image.ImagePlusAdapter;\nimport mpicbg.imglib.image.display.imagej.ImageJFunctions;\nimport mpicbg.imglib.type.numeric.RealType;\n \npublic class LocalizableByDim_Cursors&lt;T extends RealType&lt;T&gt;&gt; implements PlugIn {\n \n    public void run(String arg) {\n \n        // Open the Confocal series example\n                final String name = \"https://imagej.net/ij/images/mri-stack.zip\";\n        final ImagePlus imp = IJ.openImage(name);\n        imp.show();\n \n        // Convert it to Imglib image. It must be a 3D image.\n        final Image&lt;T&gt; img = ImagePlusAdapter.wrap(imp);  \n        final int z_size = img.getDimension( 2 ); // Z is the 3rd dimension, with index 2\n \n        // Create a Type variable to store the max value, and another \n        // to deal with current pixel.\n        T max;\n        T current_value;\n \n        // Create a new 2D image of the same type\n        // 2D images have still 3 dimensions, but the 3rd one has 1 size\n        final Image&lt;T&gt; proj = img.createNewImage(new int[] {img.getDimension(0), img.getDimension(1), 1});\n        proj.setName(\"Z max. proj. of \"+img.getName());\n \n        // Create a positionable cursor for the input\n        final LocalizableByDimCursor&lt;T&gt; input_cursor = img.createLocalizableByDimCursor();\n \n        // .. and a localizable one for the output\n        final LocalizableCursor&lt;T&gt; output_cursor = proj.createLocalizableCursor();\n \n        // Now we will iterate through all X and Y positions, using the output\n        // cursor to dictate to the input cursor where to go.\n        while (output_cursor.hasNext()) \n                {\n             output_cursor.fwd();\n             input_cursor.setPosition(output_cursor); // The output dictate the position of the input\n \n             //Now we crawl through Z to compute the max value along this column.\n             max = null;\n                         // Go to (X,Y,0), in this case this call is not necessary but good for illustration\n                         input_cursor.setPosition( 0, 2 ); // Set the dimension 2 (ie: Z) at position 0\n             for ( int i=1; i&lt;z_size; ++i )\n                         {\n                current_value = input_cursor.getType();\n                                if ( max == null )\n                                        max = current_value.clone();\n                else if ( current_value.compareTo(max) &gt; 0 ) \n                    max.set( current_value );\n                                // move forward in z direction\n                input_cursor.fwd( 2 );\n             }\n \n             // Then we set the ouput value with the max we have found\n             output_cursor.getType().set(max);\n        }\n \n        // Done iterating\n        output_cursor.close();\n        input_cursor.close();\n \n        // Display result in ImageJ\n        ImagePlus imp_result = ImageJFunctions.copyToImagePlus(proj);\n        imp_result.show();\n    }\n}",
    "crumbs": [
      "ImgLib1: Iterating through pixel data"
    ]
  },
  {
    "objectID": "imglib1/iterating-through-pixel-data.html#moving-outside-of-images---outside-strategies",
    "href": "imglib1/iterating-through-pixel-data.html#moving-outside-of-images---outside-strategies",
    "title": "ImgLib1: Iterating through pixel data",
    "section": "Moving outside of images - Outside Strategies",
    "text": "Moving outside of images - Outside Strategies",
    "crumbs": [
      "ImgLib1: Iterating through pixel data"
    ]
  },
  {
    "objectID": "imglib1/iterating-through-pixel-data.html#comparing-performances",
    "href": "imglib1/iterating-through-pixel-data.html#comparing-performances",
    "title": "ImgLib1: Iterating through pixel data",
    "section": "Comparing performances",
    "text": "Comparing performances",
    "crumbs": [
      "ImgLib1: Iterating through pixel data"
    ]
  },
  {
    "objectID": "imglib1/iterating-through-pixel-data.html#advanced-dimension-independent-iterating",
    "href": "imglib1/iterating-through-pixel-data.html#advanced-dimension-independent-iterating",
    "title": "ImgLib1: Iterating through pixel data",
    "section": "Advanced dimension independent iterating",
    "text": "Advanced dimension independent iterating",
    "crumbs": [
      "ImgLib1: Iterating through pixel data"
    ]
  },
  {
    "objectID": "imglib1/using-in-a-plugin.html",
    "href": "imglib1/using-in-a-plugin.html",
    "title": "Using ImgLib1 in an ImageJ plugin",
    "section": "",
    "text": "{% include warning/deprecated old=“ImgLib1” new=“ImgLib2” %}\nThe Imglib library makes extensive use of {% include wikipedia title=‘Generics in Java’ text=‘Java generics’%}. Generics appeared in Java from version 1.5, and they introduce new semantic items that can be puzzling if you never used them before. The programming techniques associated are quite new to the ImageJ world, and using Imglib inside your plugins will change their typical layout.\nThis short page does not aim at being an introduction on generics, but rather is a quick and dirty introduction on how to tune your java files to use Imglib. The deep meaning of semantics is skipped, and we will try to provide a quick template to start with. However, we will attempt to be quite pedestrian when ImageJ itself is involved, and try to display the code and the commands needed to generate a plugin from scratch.",
    "crumbs": [
      "Using ImgLib1 in an ImageJ plugin"
    ]
  },
  {
    "objectID": "imglib1/using-in-a-plugin.html#importing-imglib",
    "href": "imglib1/using-in-a-plugin.html#importing-imglib",
    "title": "Using ImgLib1 in an ImageJ plugin",
    "section": "Importing imglib",
    "text": "Importing imglib\nWe will work on a dummy plugin that takes an image and sum the pixel value over all pixels. As an exercise, we choose to use imglib classes internally. It will turn out to be quite convenient, even for a dummy plugin.\nA plugin skeleton looks like this:\nimport ij.IJ;\n\nimport ij.plugin.PlugIn;\n\npublic class Pixel_Summation implements PlugIn {\n  \n  public void run(String arg) {\n    IJ.write(\"Ciao, bella.\");\n  }\n} \nIf you work from within the Script Editor, you can save it anywhere and Compile & Run it with Run&gt;Compile & Run.\nOtherwise you have to save this in a file named Pixel_Summation.java in the Fiji plugins folder. You can either {% include bc path=‘Help | Update Menus’%} and find the new plugin in the Plugins menu, or compile it from the command line with:\n./fiji --javac plugins/Pixel_Summation.java\n(assuming that you are in the Fiji source tree).\nNow we want to import the imglib library, and use its Image class as an internal field. We write:\nimport ij.IJ;\n\nimport ij.plugin.PlugIn;\n\nimport mpicbg.imglib.image.Image;\n\npublic class Pixel_Summation implements PlugIn {\n  \n  protected Image img;\n\n  public void run(String arg) {\n    IJ.write(\"Ciao, bella.\");\n  }\n} \nFiji will already know where to pick up imglib.jar.\nNow, there is already quite a few things we can stumble on:\n\nIf you put this code in Eclipse IDE, for instance, it will generate a warning about unused fields, and a warning about Image being a raw type. We will come back to that later.\nIf you try to compile this code using javac from the command line, it will fail unless you use a java 1.6 compiler, for the imglib.jar is compiled with this java version.\n\nBut anyway, let us move on.",
    "crumbs": [
      "Using ImgLib1 in an ImageJ plugin"
    ]
  },
  {
    "objectID": "imglib1/using-in-a-plugin.html#converting-from-imageplus-to-imglib",
    "href": "imglib1/using-in-a-plugin.html#converting-from-imageplus-to-imglib",
    "title": "Using ImgLib1 in an ImageJ plugin",
    "section": "Converting from ImagePlus to Imglib",
    "text": "Converting from ImagePlus to Imglib\nAs we use this plugin from within Fiji, we will receive images in form of an ImagePlus. Since we want to use Imglib internally, we need to convert it. This is done using the class ImagePlusAdapter that has various static utilities to do so.\nThis is how a minimally converted class would look like:\nimport ij.IJ;\nimport ij.ImagePlus;\nimport ij.WindowManager;\n\nimport ij.plugin.PlugIn;\n\nimport mpicbg.imglib.image.Image;\nimport mpicbg.imglib.image.ImagePlusAdapter;\n\nimport mpicbg.imglib.type.numeric.RealType;\n\npublic class Pixel_Summation&lt;T extends RealType&lt;T&gt;&gt; implements PlugIn {\n  \n  protected Image&lt;T&gt; img;\n\n  public void run(String arg) {\n      ImagePlus imp = WindowManager.getCurrentImage();\n      img = ImagePlusAdapter.wrap(imp);\n  }\n}\nNote that we use generics that provide compile-time type-safety, we cannot leave the field img be an image of unknown type. We must explicitly state that it is going to be an image containing a certain generic type:\nprotected Image&lt;T&gt; img;\nWe must also detail what T can be. This is done by modifying the class signature. We add a type variable to it, that specifies what the plugin operates on:\npublic class Pixel_Summation&lt;T extends RealType&lt;T&gt;&gt; implements PlugIn {\nThis is like saying: “this plugin operates on T”, whatever T is. In our specific case, T can’t be anything. If you inspect the source of Image, you will see that we need to use a subclass of mpicbg.imglib.type.Type (we can’t have images made of koalas, yet).\nHere, we want to access the real pixel value (note that complex values are more general, so if you implement an algorithm on complex types, it will work on real ones, too, but not vice versa), so we will use RealType. It defines an interesting method getReal() that will allow us to retrieve a float representation of the pixel value.",
    "crumbs": [
      "Using ImgLib1 in an ImageJ plugin"
    ]
  },
  {
    "objectID": "imglib1/using-in-a-plugin.html#making-something-out-of-it",
    "href": "imglib1/using-in-a-plugin.html#making-something-out-of-it",
    "title": "Using ImgLib1 in an ImageJ plugin",
    "section": "Making something out of it",
    "text": "Making something out of it\nNow that we vanquished the semantics, we would like to wrap up this tutorial by doing something with the plugin. In Imglib, we iterate over the data within an image using Cursors. They are the subject of another tutorial, we will not present them thoroughly. But briefly:\n\nA plain cursor can be generated by the createCursor() method of an Image instance. It will have the same type variable as that of the Image object it originates from.\n\n\n\nIt is made to iterate through the underlying data, and in the above particular case, it will do it in a memory-optimized fashion. You want to use the hasNext() and fwd() methods of the cursor.\n\n\n\nThe actual data can be retrieved using the getType() method, that will return - oh surprise - an object of class T.\n\n\n\nSince in our case T extends RealType, we can use the getRealFloat() or getRealDouble() method to convert to a basic java float or double, respectively.\n\nWhich leads to:\nimport ij.IJ;\nimport ij.ImagePlus;\nimport ij.WindowManager;\n\nimport ij.plugin.PlugIn;\n\nimport mpicbg.imglib.cursor.Cursor;\n\nimport mpicbg.imglib.image.Image;\nimport mpicbg.imglib.image.ImagePlusAdapter;\n\nimport mpicbg.imglib.type.numeric.RealType;\n\npublic class Pixel_Summation&lt;T extends RealType&lt;T&gt;&gt; implements PlugIn {\n  \n  protected Image&lt;T&gt; img;\n\n  public void run(String arg) {\n      ImagePlus imp = WindowManager.getCurrentImage();\n      img = ImagePlusAdapter.wrap(imp);  \n      Cursor&lt;T&gt; cursor = img.createCursor();\n      float sum = 0f;\n      float val;\n      T type; // This is the generic type of the image. \n          // Note we actually don't have squat idea about what it is actually at the present time,\n          // but our plugin will still work whatever it will be.\n      while (cursor.hasNext()) {\n          cursor.fwd();\n          type = cursor.getType();\n          val = type.getRealFloat();\n          sum = sum + val;\n      }\n      IJ.write(\"Sum on all pixels: \"+sum);\n  }\n} \nAnd this is it!\nYou can test this plugin on all possible image types ImageJ supports, and it will still yield a result. And you did not have to write code for each particular data type.",
    "crumbs": [
      "Using ImgLib1 in an ImageJ plugin"
    ]
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "ImgLib2 and BigDataViewer projects",
    "section": "",
    "text": "This is the joint landing page for ImgLib2 and BigDataViewer projects!"
  },
  {
    "objectID": "contribute/guidelines_for_imglib2.html",
    "href": "contribute/guidelines_for_imglib2.html",
    "title": "Contributing Guidelines ImgLib2",
    "section": "",
    "text": "Thank you for considering contributing to the ImgLib2 open source project! By contributing, you are helping to improve and grow the software for everyone in the community. We appreciate your time and effort.\n\n\n\nGovernance\n\nCode of Conduct\n\nGetting Started\n\nPrerequisites & Setting up the Development Environment\n\nMaking Contributions\n\nCreating Issues\nWorking on Issues\nSubmitting Pull Requests\n\nCode Guidelines\nTesting\nDocumentation\nCommunity\nLicense\n\n\n\n\nFounders: Stephan Saalfeld, Stephan Preibisch Leads: Tobias Pietzsch, Stephan Preibisch, Stephan Saalfeld – Pietzsch leads on day to day issues. Pietzsch, Preibisch and Saalfeld vote on primary decisions, with Pietzsch’s vote breaking ties. Maintainers: Tobias Pietzsch, Curtis Rueden, Stephan Preibisch, Stephan Saalfeld\nAnd the team role definitions: Founder - Created the project. Does not imply any current participation or responsibility. Lead - Has decision-making authority: timing of releases, inclusion of features, etc. Maintainer - Merges patch submissions. Cuts releases.\n\n\n\nBefore contributing, please review our Code of Conduct. We aim to foster an inclusive and respectful community where everyone feels safe to participate.\n\n\n\nNeed a quick start? Install OpenJDK and maven:\nsudo apt install openjdk-16-jdk maven\nThen check out BigDataViewer vistools:\ngit clone https://github.com/bigdataviewer/bigdataviewer-vistools.git\nThen start JShell in the BigDataViewer vistools project directory:\ncd bigdataviewer-vistools\nmvn compile com.github.johnpoth:jshell-maven-plugin:1.3:run\nThen try out this code snippet:\nimport bdv.util.*;\nimport net.imglib2.position.FunctionRealRandomAccessible;\nimport net.imglib2.type.numeric.integer.IntType;\nimport net.imglib2.util.Intervals;\n\nBdvFunctions.show(\n  new FunctionRealRandomAccessible&lt;IntType&gt;(\n    2,\n    (x, y) -&gt; {\n      int i = 0;\n      double v = 0,\n        c = x.getDoublePosition(0),\n        d = x.getDoublePosition(1);\n      for (; i &lt; 64 && v &lt; 4096; ++i) {\n        final double e = c * c - d * d;\n        d = 2 * c * d;\n        c = e + 0.2;\n        d += 0.6;\n        v = Math.sqrt(c * c + d * d);\n        ++i;\n      }\n      y.set(i);\n    },\n    IntType::new),\n  Intervals.createMinMax(-1, -1, 1, 1),\n  \"\",\n  BdvOptions.options().is2D()).setDisplayRange(0, 64);\n\n\n\nPlease see the general guidlines on how to contribute to an existing plugin or library: https://imagej.net/develop/improving-the-code\n\n\nIf you find a bug, have a feature request, or encounter any issues, please search our ImgLib2 issue tracker and to see if it has already been reported. If not, feel free to create a new issue and provide as much detail as possible.\n\n\n\nIf you want to work on an existing issue, please follow these steps:\n\nComment on the issue to express your interest in working on it.\nFork the repository and create a new branch for your work.\nMake your changes and commit them with clear commit messages.\nEnsure your code follows our Code Guidelines.\nUpdate the documentation if necessary.\nRun tests to ensure your changes don’t break existing functionality.\n\n\n\n\n\nPush your changes to your forked repository.\nCreate a pull request (PR) from your branch to our main repository’s appropriate branch.\nProvide a detailed description of your changes in the PR.\nReference any related issues using keywords (e.g., “Closes #123”).\nBe ready to address feedback and make necessary changes.\n\n\n\n\n\n\nUse consistent code formatting and style throughout the project.\nFollow naming conventions for variables, functions, and classes.\nEnsure your code is well-documented.\nWrite meaningful commit messages.\n\n\n\n\nExplain how to run tests and provide information about the testing framework used.\n\n\n\nIf your changes introduce new features or modify existing ones, please update the documentation accordingly. This includes code comments, README files, and any additional documentation files.\n\n\n\nJoin in our community discussions on imagesc.zulipchat.com for discussions. For more general questions of broad interest and announcements the image.sc forum can be used advantageously. We welcome your feedback and ideas.\n\n\n\nBy contributing to this project, you agree that your contributions will be licensed under the project’s license ImgLib2 license a BSD 2-Clause “Simplified” License. If you’re not comfortable with this, please consider refrain from contributing."
  },
  {
    "objectID": "contribute/guidelines_for_imglib2.html#table-of-contents",
    "href": "contribute/guidelines_for_imglib2.html#table-of-contents",
    "title": "Contributing Guidelines ImgLib2",
    "section": "",
    "text": "Governance\n\nCode of Conduct\n\nGetting Started\n\nPrerequisites & Setting up the Development Environment\n\nMaking Contributions\n\nCreating Issues\nWorking on Issues\nSubmitting Pull Requests\n\nCode Guidelines\nTesting\nDocumentation\nCommunity\nLicense"
  },
  {
    "objectID": "contribute/guidelines_for_imglib2.html#governance",
    "href": "contribute/guidelines_for_imglib2.html#governance",
    "title": "Contributing Guidelines ImgLib2",
    "section": "",
    "text": "Founders: Stephan Saalfeld, Stephan Preibisch Leads: Tobias Pietzsch, Stephan Preibisch, Stephan Saalfeld – Pietzsch leads on day to day issues. Pietzsch, Preibisch and Saalfeld vote on primary decisions, with Pietzsch’s vote breaking ties. Maintainers: Tobias Pietzsch, Curtis Rueden, Stephan Preibisch, Stephan Saalfeld\nAnd the team role definitions: Founder - Created the project. Does not imply any current participation or responsibility. Lead - Has decision-making authority: timing of releases, inclusion of features, etc. Maintainer - Merges patch submissions. Cuts releases."
  },
  {
    "objectID": "contribute/guidelines_for_imglib2.html#code-of-conduct",
    "href": "contribute/guidelines_for_imglib2.html#code-of-conduct",
    "title": "Contributing Guidelines ImgLib2",
    "section": "",
    "text": "Before contributing, please review our Code of Conduct. We aim to foster an inclusive and respectful community where everyone feels safe to participate."
  },
  {
    "objectID": "contribute/guidelines_for_imglib2.html#getting-started",
    "href": "contribute/guidelines_for_imglib2.html#getting-started",
    "title": "Contributing Guidelines ImgLib2",
    "section": "",
    "text": "Need a quick start? Install OpenJDK and maven:\nsudo apt install openjdk-16-jdk maven\nThen check out BigDataViewer vistools:\ngit clone https://github.com/bigdataviewer/bigdataviewer-vistools.git\nThen start JShell in the BigDataViewer vistools project directory:\ncd bigdataviewer-vistools\nmvn compile com.github.johnpoth:jshell-maven-plugin:1.3:run\nThen try out this code snippet:\nimport bdv.util.*;\nimport net.imglib2.position.FunctionRealRandomAccessible;\nimport net.imglib2.type.numeric.integer.IntType;\nimport net.imglib2.util.Intervals;\n\nBdvFunctions.show(\n  new FunctionRealRandomAccessible&lt;IntType&gt;(\n    2,\n    (x, y) -&gt; {\n      int i = 0;\n      double v = 0,\n        c = x.getDoublePosition(0),\n        d = x.getDoublePosition(1);\n      for (; i &lt; 64 && v &lt; 4096; ++i) {\n        final double e = c * c - d * d;\n        d = 2 * c * d;\n        c = e + 0.2;\n        d += 0.6;\n        v = Math.sqrt(c * c + d * d);\n        ++i;\n      }\n      y.set(i);\n    },\n    IntType::new),\n  Intervals.createMinMax(-1, -1, 1, 1),\n  \"\",\n  BdvOptions.options().is2D()).setDisplayRange(0, 64);"
  },
  {
    "objectID": "contribute/guidelines_for_imglib2.html#making-contributions",
    "href": "contribute/guidelines_for_imglib2.html#making-contributions",
    "title": "Contributing Guidelines ImgLib2",
    "section": "",
    "text": "Please see the general guidlines on how to contribute to an existing plugin or library: https://imagej.net/develop/improving-the-code\n\n\nIf you find a bug, have a feature request, or encounter any issues, please search our ImgLib2 issue tracker and to see if it has already been reported. If not, feel free to create a new issue and provide as much detail as possible.\n\n\n\nIf you want to work on an existing issue, please follow these steps:\n\nComment on the issue to express your interest in working on it.\nFork the repository and create a new branch for your work.\nMake your changes and commit them with clear commit messages.\nEnsure your code follows our Code Guidelines.\nUpdate the documentation if necessary.\nRun tests to ensure your changes don’t break existing functionality.\n\n\n\n\n\nPush your changes to your forked repository.\nCreate a pull request (PR) from your branch to our main repository’s appropriate branch.\nProvide a detailed description of your changes in the PR.\nReference any related issues using keywords (e.g., “Closes #123”).\nBe ready to address feedback and make necessary changes."
  },
  {
    "objectID": "contribute/guidelines_for_imglib2.html#code-guidelines",
    "href": "contribute/guidelines_for_imglib2.html#code-guidelines",
    "title": "Contributing Guidelines ImgLib2",
    "section": "",
    "text": "Use consistent code formatting and style throughout the project.\nFollow naming conventions for variables, functions, and classes.\nEnsure your code is well-documented.\nWrite meaningful commit messages."
  },
  {
    "objectID": "contribute/guidelines_for_imglib2.html#testing",
    "href": "contribute/guidelines_for_imglib2.html#testing",
    "title": "Contributing Guidelines ImgLib2",
    "section": "",
    "text": "Explain how to run tests and provide information about the testing framework used."
  },
  {
    "objectID": "contribute/guidelines_for_imglib2.html#documentation",
    "href": "contribute/guidelines_for_imglib2.html#documentation",
    "title": "Contributing Guidelines ImgLib2",
    "section": "",
    "text": "If your changes introduce new features or modify existing ones, please update the documentation accordingly. This includes code comments, README files, and any additional documentation files."
  },
  {
    "objectID": "contribute/guidelines_for_imglib2.html#community",
    "href": "contribute/guidelines_for_imglib2.html#community",
    "title": "Contributing Guidelines ImgLib2",
    "section": "",
    "text": "Join in our community discussions on imagesc.zulipchat.com for discussions. For more general questions of broad interest and announcements the image.sc forum can be used advantageously. We welcome your feedback and ideas."
  },
  {
    "objectID": "contribute/guidelines_for_imglib2.html#license",
    "href": "contribute/guidelines_for_imglib2.html#license",
    "title": "Contributing Guidelines ImgLib2",
    "section": "",
    "text": "By contributing to this project, you agree that your contributions will be licensed under the project’s license ImgLib2 license a BSD 2-Clause “Simplified” License. If you’re not comfortable with this, please consider refrain from contributing."
  }
]